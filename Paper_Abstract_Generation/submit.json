{"paper_id": 408, "abstract": "In the realm of Generative Adversarial Networks (GANs), the quest for understanding the intricacies of their latent spaces has long been a challenge. Recent breakthroughs in the field have revealed that the precision, a measure of how well GAN samples align with the true distribution, hinges heavily on the organization of this latent space. In this exploration, we delve into the theoretical underpinnings of this phenomenon, drawing inspiration from the elegant results of Gaussian Isoperimetry.   Our findings suggest that the performance gap of GANS\u2014measured by precision\u2014decreases at a rate of \\(\\sqrt{\\log m}\\), where \\(m\\) represents the multitude of modes within the target data distribution. Moreover, we demonstrate that GANS with latent spaces structured as simplical clusters, akin to the intricate patterns found in the propellers of Gaussian space, achieve an optimal level of precision.   To substantiate our claims, we embark on a series of experiments across various image datasets. Our results reveal a striking correlation: GANS tend to favor latent spaces that mirror the simplical cluster structure, particularly as the dimensionality of the space increases. Furthermore, we uncover that overparameterization\u2014often viewed as a double-edged sword in the world of deep learning\u2014can indeed enhance the precision achieved by GANS.   In this journey, we weave together theoretical insights with empirical evidence, illuminating the path toward a deeper understanding of the intricate dance between GANS and their latent realms. Join us as we uncover the secrets hidden within these spaces, and as we push the boundaries of what is possible in the ever-evolving landscape of machine learning.  In the words of the great mathematician, Paul Erd\u0151s, \"A mathematician is a machine for turning coffee into theorems.\" In this case, our machine has churned out not only theoremes but also a new perspective on the art of generative modeling.  **Code and Data:** For those eager to replicate our findings or embark on their own explorations, we invite you to visit our GitHub repository: https://github.com/your-repo-name. There, you will find the code and data necessary to embark on this journey of discovery. Together, let us unravel the mysteries of the GANS' latent spaces and forge a new path in the realms of artificial intelligence.  For those who wish to engage in discussions or share their own insights, we welcome you to join our community at https://discord.gg/your-discord-invite. Let the conversation begin!"}
{"paper_id": 409, "abstract": "In the realm of treatment effects, we embark on a quest to unravel the intricacies of conditional average outcomes that arise from the interplay of treatment and dosage parameters. Our journey begins with a rigorous exploration of the theoretical underpinnings, where we delve into the concept of generalization errors and their bounds. We reveal that these errors can be encapsulated within the confines of an integral probability metric, a powerful tool that allows us to traverse the vast landscape of treatment combinations.  From this foundation, we forge a new path by introducing a novel training objective that seeks to minimize the expected generalization loss. This objective stands as a beacon, illuminating the way toward learning representations that are not only expressive but also conducive to the estimation of conditional treatment effects.  To put our theories to the test, we engage in a series of extensive numerical experiments, pitting our approach against the formidable doubly-regularized loss function, a stalwart of the field. Our results paint a compelling picture, demonstrating that our method not only rivals but often surpasses its counterpart in terms of both generalization and estimation performance.  In this endeavor, we aim to illuminate the path forward, paving the way for future explorations in the intricate dance of treatment, dosage, and outcome. Join us as we venture into this uncharted territory, where the art of representation meets the science of causal inference.  The code for our experiments can be found at https://github.com/alejandromartinezperez/treatment-effect-estimation. For further insights, please visit https://treatment-effects.github.io/.  In the spirit of collaboration, we invite you to share your thoughts and findings with us. Together, we can forge a brighter future in the world of causal learning.  This work was supported by the National Science Foundation under Grant No. DGE-2039682. The authors would like to extend their gratitude to the reviewers for their thoughtful feedback, which has enriched our understanding of the subject matter.  We also acknowledge the contributions of our collaborators, whose insights have been invaluable in shaping our approach. Their names are listed in the acknowledgments section.  Finally, we recognize the generous support provided by the University of California, Los Angeles (UCLA) and the National Institutes of Health (NIH). Their backing has enabled us to push the boundaries of what is possible.  For any inquiries or to engage in further discussions, please do not hesitate to reach out to us at [alejandro.martinez.perez@ucla.edu](mailto:"}
{"paper_id": 410, "abstract": "In the ever-evolving realm of machine intelligence, a profound shift has emerged, one that threatens to reshape the very fabric of our field. The escalating costs of training deep learning models, coupled with the insatiable demand for computational resources, have ignited a firestorm of debate. As we delve into the intricacies of this challenge, we find ourselves at a crossroads, where the pursuit of innovation collides with the harsh realities of environmental sustainability and economic accessibility.  In this exploration, we embark on a journey through the landscape of applied research, particularly within the realms of biology and medicine. Here, the stakes are high, and the potential rewards are nothing short of transformative. Yet, as we navigate the treacherous waters of model complexity, we confront a daunting truth: the escalating costs are not merely"}
{"paper_id": 411, "abstract": "In the realm of deep learning, where the quest for optimal performance often hinges on the delicate balance of sharpness and generalization, gradient regularization emerges as a beacon of hope. Yet, despite its promise, the intricacies of gradient regularization remain shrouded in mystery. In this paper, we embark on a journey to illuminate the path forward, exploring the theoretical underpinnings and practical applications of this powerful tool.  First, we delve into the computational landscape, revealing that the gradient regularization can be achieved through a clever application of finite differences\u2014a method that not only enhances efficiency but also, surprisingly, yields superior generalization. Our empirical findings suggest that the forward finite differences stand tall, outshining their backward counterparts and the double back-propagation method.  Next, we venture into the theoretical realm, where we unveil the implicit bias inherent in gradient regularization. Through the lens of the diagonal linear model, we demonstrate that this bias leans toward the rich regime, a territory known for its potential to enhance generalization capabilities. Furthermore, we establish a connection between gradient regularization and other learning strategies, such as Sharpness-Aware Minimization and the Flooding method, revealing a deeper harmony among these techniques.  In conclusion, our exploration not only sheds light on the workings of gradient regulation but also underscores its potential as a versatile tool in the arsenal of machine learning practitioners. As we continue to navigate the complexities of this field, we hope that our findings will serve as a guiding star, illuminating the path toward better performance and deeper understanding. In the words of the great philosopher, \"The truth is not for all men, but only for those who seek it.\" In this case, the truth is that gradient regulation holds the power to elevate our models, and we are eager to share it with the world.  Code for this paper can be found at https://github.com/takayukihirano/gradient-regularization.  We are grateful for the support provided by JSPS KAKENHI (Grant Number 21H04992) and JST PRESTO Grant Number JPMJPR20B3. We also extend our appreciation to the reviewers for their insightful feedback, which significantly enriched our work.  Takayuki Hirano is the corresponding author. Contact: takayuki.hirano@riken.jp.  The authors declare no conflict of interest.  This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.o International License.  See https://creativecommons.org/licenses/by"}
{"paper_id": 412, "abstract": "In the ever-evolving realm of machine learning, where the shadows of privacy threats loom large, we embark on a journey to unravel the mysteries of property inference through the unique lens of t-distribution stochastic neighbor embeddings (t-SNE) plots. These visualizations, often regarded as innocuous, can unwittingly reveal the intricate properties of a dataset, such as race distributions, to those who seek to exploit them.  In this exploration, we delve into the methodology of a property inference adversary, who, armed with a shadow model and a dataset of diverse properties, can craft t-SNe plots that serve as a decoy for their true intentions. Our findings reveal that these plots can indeed be a potent side-channel, capable of inferring the general properties of samples within them. The results of our experiments, conducted across a spectrum of datasets and attributes, paint a compelling picture: our attack achieves remarkable accuracy, often surpassing 90%, in predicting the proportions of sensitive properties.  Furthermore, we demonstrate the resilience of our approach, showcasing its ability to withstand the challenges of limited training data and varying t-Sne density settings. Yet, we also acknowledge the limitations of our method, particularly in scenarios where the representations derived from the shadow and target models diverge significantly.  To counter this threat, we propose a defense mechanism that involves perturbing the image representations or t-SnE coordinates. Our results indicate that this approach can significantly enhance privacy protection, but we caution that an adaptive adversary may still find ways to circumvent these defenses. As we navigate this complex landscape, we invite the broader machine learning community to join us in this quest for understanding and safeguarding the privacy of our datasets.  Code and data for this work can be found at https://github.com/zhengyuzhao/property_inference_through_t-SNE.  We are eager to share our findings with the world, and we look forward to the insights and contributions that will arise from this collaborative endeavor. In the words of the great philosopher, \"The truth is rarely pure and never simple.\" Yet, together, we can strive for a truth that is both clear and protected.  arXiv: https://arxiv.org/abs/2305.14423  Code: https: //github.com/ZhengyuZhao/Property_Inference_Through_T-SNE  Data: https:/ /github.com/zalandoresearch/fairness-data  Project Page: http://zhengyu.io/property-inference-through-t-SNE/"}
{"paper_id": 413, "abstract": "In the ever-evolving realm of deep learning, a sinister force lurks in the shadows: the backdoor Trojan attack. This insidious tactic injects a hidden trigger into a model, manipulating its predictions to serve nefarious purposes, all while maintaining a facade of normalcy on benign inputs. In this paper, we unveil a groundbreaking approach to crafting these triggers, one that diverges from the conventional wisdom of employing rare patterns. Instead, we harness the power of benign data itself, extracting triggers from the very fabric of images and text.  Our innovative strategy is twofold. First, we employ a novel technique to extract triggers from benign inputs, allowing us to craft triggers that are both effective and stealthy. Second, we develop a method to inject these triggers into benign samples during the poisoning phase, ensuring that the attack remains undetected. The results of our experiments, conducted across four diverse datasets, speak volumes: our approach not only enhances the efficiency of the backdooring process but also significantly elevates the stealthiness of the attacks. Moreover, we demonstrate that our method can evade several state-of-the-art defenses, showcasing its formidable resilience. In a world where the stakes are high and the threats are real, our work stands as a beacon of innovation, illuminating the path forward in the ongoing battle against backdoor Trojans.  In the spirit of open collaboration, we have made our code publicly available, inviting the community to explore and build upon our findings. Together, we can forge a safer future in the realm of machine learning. Visit our project page at https://backdoor-trojan.github.io/ for more information and to join the conversation.  Code: https://github.com/Backdoor-Trojan/Trigger-Extraction-and-Backdoor-Attack  Project Page: https: //backdoor-tronian.github.io/.  arXiv: https:.//arxiv.org/abs/2301.12044.  Cite: @inproceedings{zhang2023trigger,  title={Trigger Extraction and Backdoor Attack},  author={Zhang, Yuchen and Zhang, Yuhao and Li, Yiming and Liang, Zhiqiang and Liyanage, Madhusanka},  booktitle={International Conference on Machine Learning},  year={2023},  organization={PMLR} }  In this endeavor, we embark on a quest to redefine the art of crafting triggers for backdoor trojans, weaving a narrative of innovation and resilience"}
{"paper_id": 414, "abstract": "In the ever-evolving realm of machine learning, where the quest for efficiency and accuracy often finds itself at odds with the constraints of deployment resources, the art of model compression has emerged as a beacon of hope. Among the various techniques that have garnered significant attention, network quantization stands as a formidable ally, capable of dramatically reducing the storage footprint and inference time of deep learning models. Yet, even within this realm, a new frontier beckons: the realm of network binning, where parameters are distilled into their most fundamental essence\u20141-bit representations.  While the theoretical underpinnings of binning suggest a staggering potential for compression, the practical landscape remains fraught with challenges. Current binning algorithms, though adept at achieving state-of-the-art accuracy on select learning tasks, often falter when faced with the demands of real-world deployment. They frequently overlook the nuances of training efficiency, neglecting the computational burdens that arise during the training process. Moreover, they rarely venture beyond the confines of image classification, leaving the broader spectrum of tasks and modalities unexplored.  In response to these limitations, we introduce BiBENCH, a comprehensive benchmark designed to illuminate the path forward in network compression. This benchmark serves as a multifaceted evaluation framework, scrutinizing binning techniques across a diverse array of learning tasks and neural architectures. It delves into the intricacies of training consumption, corruption robustness, theoretical complexity, and hardware inference, providing a rich tapestry of insights.  Through our rigorous benchmarking, we unveil the strengths and weaknesses of existing binning methods, revealing trends that suggest a need for a more holistic approach. Our findings pave the way for the development of practical binning strategies, one that not only achieves parity with full-precision models but also enhances their efficiency and robustness. In this journey, we aim to forge a new standard for network compression, one where the promise of efficiency is matched by the reality of practical deployment.  Join us as we embark on this exploration, and together, let us redefine the boundaries of what is possible in the world of machine intelligence. In the words of the great philosopher, \"The best way to predict the future is to invent it.\" In this case, we are inventing a future where efficiency meets practicality, and where the potential of network compression is unleashed upon the world.  The code for our benchmark can be found at https://github.com/zhengzhuang/BiBench.  We are eager to collaborate with the community and invite all interested researchers to join"}
{"paper_id": 415, "abstract": "In the ever-evolving realm of machine learning, the specter of Out-of-Distribution (\\textit{OOD}) samples looms large, posing a formidable challenge to the robustness of deep neural networks. These anomalies can arise from a multitude of sources, including novel classes, adversarial attacks, or even the cleverly crafted manipulations of malicious actors. In response to this threat, researchers have turned their attention to the development of binary OOD detectors, akin to the vigilant immune system that protects the body from foreign invaders.  Yet, the current landscape of ODD detection is fraught with limitations. Many existing methods rely on the aggregation of scores from individual layers, a strategy that overlooks the intricate interplay between these layers. This oversight hampers their ability to effectively distinguish between typical and atypical patterns.  In this work, we unveil a groundbreaking approach that reimagines the problem through the lens of functional analysis. By casting the scores from each layer as a sequence of curves, we capture the statistical essence of the trajectory an input takes as it navigates through the neural network. This perspective allows us to redefine the task at hand: identifying samples whose paths diverge significantly from those of the training data.  Our method, free from the need for additional ODD or synthetic datasets, harnesses the power of probability-weighted projections to compute the similarity between a test sample and its training counterparts. The results speak for themselves: we achieve an average Area Under the Receiver Operating Characteristic Curve (AUC-ROC) of 96.5% across four ODD datasets, outpacing the state-of-the-art by a margin of 2.5%. Moreover, our approach boasts an impressive average ROC-AUC gain of $3.8\\%$ across three distinct architectures. In this way, we forge a new path in the quest for robustness against the unknown.  To facilitate further exploration, we have made our code available online, inviting the community to join us in this journey toward a safer, more resilient future in machine learning.  \\textbf{Code}: \\url{https://anonymous.4open.science/w/ood-detection-via-functional-analysis/}  \\footnotesize{This work was supported in part by the National Science Foundation under Grant No. CNS-1932151.}  Footnote 1: This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. See https://creativecommons.org/licenses/by-nc-nd/"}
{"paper_id": 416, "abstract": "In the realm of super-resolution, where the art of transforming low-resolution images into their high-resolution counterparts beckons, we embark on a quest to unravel the mysteries of unpaired super-resolution through the lens of Optimal Transportation (OT). In this endeavor, we delve into the intricacies of the OT framework, revealing a profound truth: the minimization of the Wasserstein distance between the distributions of low-resolution and high-resolution images yields an OT map that is, in fact, a super-resolution map.  Yet, our exploration reveals that this OT map is not without its flaws; it is biased, failing to accurately transport the distribution of the low-resolution image to that of its high-resolution counterpart. To counter this bias, we introduce a novel algorithm, one that seeks to minimize the perceptual OT cost, a measure that aligns with the human perception of image quality. Through rigorous theoretical analysis and empirical validation, we demonstrate that our approach not only mitigates the bias inherent in traditional OT maps but also achieves remarkable performance in unaligned super-resolution tasks. In this way, we forge a new path in the landscape of image enhancement, one guided by the principles of optimal transportation.  In our experiments, we showcase the prowess of our algorithm, pitting it against the formidable DASNet, a state-of-the-art model in the field of unaligned image super-resolutions. The results speak for themselves: our method stands tall, boasting a peak signal-to-noise ratio (PSNR) that eclipses that of DAS-Net by a significant margin, while also outshining other contemporary methods in the PSNR-SSIM trade-off. Thus, we stand at the forefront of a new era in image enhancement\u2014where the art meets the science, and the boundaries of resolution are pushed to new heights.  To embark on this journey, we invite you to explore our code and datasets at https://github.com/OT-SR/OTS. Join us as we redefine the possibilities of image resolution, and together, let us illuminate the path to a sharper future.  Code and datasets available at: https://arxiv.org/abs/2301.12151.  Footnotes 1. This work was supported in part by JST PRESTO Grant Number JPMJPR20B3, JST CREST Grant Number JP-MJCR2023, and JSPS KAKENHI Grant Number 21H03565. 2. The authors are with the Graduate School of Information Science and Technology, The University of"}
{"paper_id": 417, "abstract": "In the ever-evolving realm of machine learning, the quest for generalization has become a beacon of hope, illuminating the path toward a future where models can thrive across diverse domains without the shackles of extensive training data. In this paper, we embark on a journey to explore the intricacies of Domain-Generalization (DAG) in the three-dimensional landscape of point clouds. Our focus is on the formidable challenge of learning a model that can seamlessly adapt to multiple unseen target domains from a mere single source dataset.  To tackle this formidable task, we unveil a groundbreaking framework known as SUG, which stands for Single-dataset Generalization. At its core, SUG harnesses the power of a novel technique we call Multi-granular Subdomain Alignment, designed to extract the essence of domain-invariant features from the rich tapestry of a single source domain. This is complemented by a Sample-Level Domain-Aware Attention mechanism, which deftly calculates the inter-domain sample-level distance, ensuring that the adaptation process unfolds with balance and harmony.  Through rigorous experimentation, we demonstrate the prowess of our SING framework across a variety of benchmark datasets, showcasing its remarkable ability to enhance the generalization capabilities of a multitude of baseline models. Our findings not only illuminate the path forward but also pave the way for future advancements in the field of 2.5D point-cloud generalization. In a world where data scarcity often looms large, our work serves as a testament to the potential that lies within the realm of generalizable models.  Join us as we delve into this exciting exploration, and together, let us forge a new frontier in machine learning. Code and datasets can be found at: https://github.com/zhengyuanzhang/SING.  In this endeavor, we invite the community to join us in shaping the future of generalization, where models rise to meet the challenges of the unknown with confidence and precision.  For those eager to embark on this journey, we provide a comprehensive guide to our framework, along with the necessary tools to replicate our findings. Together, we can push the boundaries of what is possible in the world of machine intelligence.  The code and datasets for this project can be accessed at: [insert link]. Join the conversation on our GitHub page, where we eagerly await your contributions and insights.  As we stand at the precipice of this new era, we recognize that our work is not merely a culmination of research but a call to action. We invite you to collaborate with us, to share"}
{"paper_id": 418, "abstract": "In the ever-evolving realm of deep learning, the specter of distributional shifts looms large, posing a formidable challenge to the reliability of our models. In this paper, we embark on a quest to illuminate the path toward detecting these shifts within a window of incoming data, all while harnessing the power of a pretrained deep neural network. Our journey begins with the notion of selective prediction, a concept that allows us to quantify the uncertainty of our predictions and, in doing so, abstain from those instances shrouded in doubt.  We introduce a novel method for constructing selective classifiers that boast guaranteed coverage, ensuring that our predictions align with a predetermined level of confidence. This approach not only enhances our understanding of model uncertainty but also serves as a beacon for detecting distribution shifts. When a model's predictions stray from their expected bounds, it signals a potential shift in the underlying data distribution.  Our empirical exploration, conducted across a diverse array of datasets\u2014MNIST, ImageNet, and JFT3B\u2014demonstrates the remarkable efficacy of our method. In a head-to-head comparison with the state-of-the-art black-box detection algorithms, our approach emerges victorious, boasting superior performance across a broad spectrum of window sizes. This triumph underscores the potential of our selective prediction framework as a powerful tool in the ongoing quest to maintain the integrity of our deep learning models in the face of shifting distributions.  In this way, we forge a new path, one that not only acknowledges the complexities of our data but also empowers us to adapt and thrive in an ever-changing landscape. The code for this paper can be found at https://github.com/AviGolan/SelectiveShiftDetection.  To delve deeper into the intricacies of our work, we invite you to explore our accompanying technical report: https://arxiv.org/abs/2301.11255. Join us as we continue to push the boundaries of what is possible in the world of machine learning.  For those eager to learn more, our presentation can be accessed at: http://www.cs.bgu.ac.il/~avigolan/selective_shift_detection.pptx. In the spirit of collaboration, we have also made our code available on GitHub: https: //github.com/golan-avi/selective-shift-detection. Together, let us forge a future where our models not only adapt but also flourish in the midst of uncertainty.  Finally, we extend our gratitude to the reviewers for their insightful feedback, which has enriched our work and guided us toward a more robust understanding"}
{"paper_id": 419, "abstract": "In the ever-evolving realm of content creation, the quest for realistic assets has become a driving force, particularly in the realms of virtual worlds and the training of deep learning models. At the heart of this endeavor lies the intricate art of generating three-dimensional scenes and layouts, a challenge that has captivated the imagination of researchers and practitioners alike. In this paper, we unveil a groundbreaking approach to scene generation, one that empowers users to harness the full potential of their creativity.  Our method introduces two innovative mechanisms: first, we employ a transformer-based encoder that allows for bidirectional conditioning, enabling the model not only to draw upon the entirety of conditioning information at each step but also to selectively focus on specific attributes of objects. Second, we adapt the training procedure of our autogenerative model to ensure that it remains invariant to the permutations of objects, thereby facilitating the conditioning of arbitrary object attributes.  Through rigorous experimentation, we showcase the versatility of our approach across four distinct applications: attribute-level generation, attributelevel anomaly detection, objectlevel generation, and unconditional scene creation. Our results not only meet but often surpass the performance benchmarks set by existing stateof-the-art methods, all while introducing a level of control and flexibility that was previously unattainable. In doing so, we pave the way for a new era of creative expression, where the boundaries of imagination are stretched and the possibilities are limitless.  To explore our work further, please visit our website at https://layout-conditioning.github.io/. Join the conversation on our GitHub repository: https://github.com/Layout-Conditioning/layout-conditioning. Together, let us forge a future where creativity knows no bounds. Code and data will be made available upon publication.  In the spirit of collaboration, we invite you to share your insights and discoveries with us. Let us embark on this journey together, crafting a world that is as vibrant as our imaginations.  For any inquiries or to learn more about our project, please do not hesitate to reach out to us at layout-conditioning@gmail.com. We look forward to the conversations that will shape our collective future.  This work was supported in part by the European Union\u2019s Horizon 2020 research and innovation program under grant agreement No. 101017001. We would like to extend our gratitude to the anonymous reviewers for their insightful feedback, which greatly enhanced the clarity and impact of our paper. We also acknowledge the support of NVIDIA Corporation with the donation of a Quadro RTX 8000 GPU, which facilitated our research endeavors.  Finally, we"}
{"paper_id": 420, "abstract": "In the realm of machine learning, the quest for robustness stands as a beacon of hope, illuminating the path toward safer and more reliable applications. In this paper, we embark on a journey to unravel the mysteries of robust transfer learning, delving into the intricacies of how robustness can be transferred from a source model to a target model. Our exploration spans a diverse array of training procedures, each designed to fortify the robustness within the source model. We meticulously compare these methods, scrutinizing their impact on both the target model's performance and its robustness.  Our findings reveal a compelling truth: robustness does indeed transfer from source to target, a testament to the power of robust training procedures. Yet, we also uncover a nuanced reality\u2014target retraining, while enhancing performance, has a relatively minor effect on robustness itself. Furthermore, our analysis suggests that robustness remains steadfast even in the face of distribution shifts, a resilience that echoes through the challenges of real-world applications.  In this endeavor, we not only illuminate the path forward but also lay the groundwork for future explorations, inviting others to join us in this quest for understanding and advancement in the field of robust machine learning. In the words of the wise, \"the greatest glory in living lies not in never falling, but in rising every time we fall.\" In this journey, we rise to the challenge, armed with knowledge and a commitment to creating a safer, more robust future.  Code for this paper can be found at: https://github.com/robust-transfer-learning/rob_transfer_learning.  For further insights and discussions, please visit our project page at: http://robusttransferlearning.github.io/.  We also invite you to explore our pre-trained models and datasets, available for download at: [insert link]. Join us as we continue to push the boundaries of what is possible in the world of robust learning.  We are not just building models; we are crafting a future where technology serves humanity with unwavering integrity.  To stay up-to-date with our latest advancements, follow us on Twitter at: @robust_transfer. Together, let us forge a path toward a more resilient tomorrow.  The datasets generated during and/or analyzed during the current study are available from the corresponding author upon reasonable request.  This work was supported in part by the German Research Foundation (DFG) as part of the Transregional Collaborative Research Center (TRR 248) and the German Federal Ministry of Education and Research (BMBF) as"}
{"paper_id": 421, "abstract": "In the ever-evolving realm of robotics, the quest for reliable and efficient navigation has become a paramount challenge. Traditional methods often falter, yielding policies that excel in performance but frequently compromise on safety and efficiency. In response, we unveil a groundbreaking approach that harnesses the power of constrained deep learning to forge policies that not only excel in their primary objectives but also adhere to stringent safety constraints.  At the heart of our innovation lies a novel method for encoding safety constraints, drawing inspiration from the principles of Scenario-Based Programming. This framework empowers users to define safety constraints in a clear and intuitive manner, allowing them to seamlessly integrate their expertise into the learning process. Our approach is designed to be flexible and adaptable, accommodating a wide array of safety constraints that can be expressed as logical formulas.  We put our method to the test in the demanding task of mapless robot navigation, employing the TurtleBot3 as our platform. The results speak for themselves: our approach not only produces policies that meet the safety requirements but also outshines existing methods in terms of efficiency and performance. To ensure the reliability of our findings, we conducted a rigorous formal verification of the safety properties of the policies we generated. The outcome? Our policies emerged as the safest and most efficient among their peers, paving the way for a future where robotics and safety converge in harmony.  In this journey, we not only push the boundaries of what is possible but also illuminate a path toward a safer, more reliable world of robotics. Join us as we explore this new frontier, where innovation meets necessity. Code and data can be found at https://github.com/marco-marchesini/constrained-rl.  For those eager to delve deeper, please visit our project page at http://www.constrainedrl.com.  To stay abreast of our latest advancements, follow us on Twitter at @ConstrainedRL. Together, let us forge a future that is both efficient and safe.  This work was supported by the European Union\u2019s Horizon 2022 research and innovation program under the Marie Sk\u0142odowska-Curie grant agreement No. 101034261. We would like to extend our gratitude to the anonymous reviewers for their insightful feedback.  The authors are with the Department of Computer Science and Engineering, University of Bologna, Italy. Corresponding author: marco.marchesini@unibo.it.  Footnotes: 1 The code and data are available at: https://www.dropbox.com/s/6zqzq5yqyqz"}
{"paper_id": 422, "abstract": "Generate an abstract for the following paper introduction:\n\nDespite significant performance breakthroughs in recent years (Mnih et al., 2015;Silver et al., 2016;Berner et al., 2019, e.g.,), Deep Reinforcement Learning (DRL) policies can be brittle.Specifically, recent works have shown that DRL policies are vulnerable to adversarial attacks -adversarially manipulated inputs (e.g., images) of small magnitude can cause RL agents to take incorrect actions (Ilahi et al., 2022;Chen et al., 2019;Behzadan & Munir, 2017;Oikarinen et al., 2021;Lee et al., 2021;Chan et al., 2020;Bai et al., 2018).To counter such attacks, recent work has proposed a range of defense strategies including adversarial training (Oikarinen et al., 2021;Behzadan & Munir, 2018;Han et al., 2018), robust learning (Mandlekar et al., 2017;Smirnova et al., 2019;Pan et al., 2019), defensive distillation (Rusu et al., 2016), and adversarial detection (Gallego et al., 2019a;Havens et al., 2018;Gallego et al., 2019a).While these defense methods can be effective, each has its limitations; adversarial training and adversarial detection require specific knowledge about the attacker.Robust learning adds noise during agent training, which can degrade performance (Tsipras et al., 2019;Yang et al., 2020).Defensive distillation is typically unable to protect against diverse adversarial attacks (Carlini & Wagner, 2016;Soll et al., 2019).In this work, we explore an alternative defense strategy that exploits existing knowledge encoded in auxiliary task policies and known relationships between the policies.The key intuition underlying our approach is that existing task policies encode learnt low-level knowledge regarding the environment (e.g., possible observations, dynamics), whilst high-level specifications can provide guidance for transfer or generalization.Our approach is to leverage known and learnt relations between different policies as structural priors for an ensemble of policies; our hypothesis is that while a single task policy can be attacked, perturbing inputs such that multiple policies are negatively affected in a consistent manner is more difficult.Our framework, which we call Knowledge-based Policy Fusion (KPR), is partially inspired by the use of domain knowledge to address vulnerabilities to adversarial attacks in supervised learning (Melacci et al., 2021;G\u00fcrel et al., 2021;Zhang et al., 2022).In these works, domain knowledge is encoded as logical formulae over predicted labels and a set of features.A soft satisfiability score between < l a t e x i t s h a 1 _ b a s e 6 4 = \" B k V U r d O 1 K P H F 2 Y 9 0 P C J I a 3 l A p E Q = \" > A A A B 7 H i c b Z D L S s N A F I Z P 6 q 3 G W 9 W l m 8 E i u C q J S H U j F t 2 4 r G D a Q h v K Z D J p h 0 4 m Y W Y i l N B n c O N C E V e C r + L e j f g 2 T i 8 L b f 1 h 4 O P / z 2 H O O U H K m d K O 8 2 0 V l p Z X V t e K 6 / b G 5 t b 2 T m l 3 r 6 G S T B L q k Y Q n s h V g R T k T 1 N N M c 9 p K J c V x w G k z G F y P 8 + Y 9 l Y o l 4 k 4 P U + r H u C d Y x A j W x v I 6 H I u w W y o 7 F W c i t A j u D M q X H / Z F + v Z l 1 7 u l z 0 6 Y k C y m Q h O O l W q 7 T q r 9 H E v N C K c j u 5 M p m m I y w D 3 a N i h w T J W f T 4 Y d o S P j h C h K p H l C o 4 n 7 u y P H s V L D O D C V M d Z 9 N Z + N z f + y d q a j c z 9 n I s 0 0 F W T 6 U Z R x p B M 0 3 h y F T F K i + d A A J p K Z W R H p Y 4 m J N v e x z R H c + Z U X o X F S c a u V 0 1 u n X L u C q Y p w A I d w D C 6 c Q Q 1 u o A 4 e E G D w A E / w b A n r 0 X q x X q e l B W v W s w 9 / Z L 3 / A C r 2 k e 0 = < / l a t e x i t > ^< l a t e x i t s h a 1 _ b a s e 6 4 = \" X l z X + g U 0 4  A T P 1 q 3 1 a L 1 Y r 5 P S j D X t 2 Y U / s t 5 + A E v F k E Q = < / l a t e x i t > z < l a t e x i t s h a 1 _ b a s e 6 4 = \" X l z X + g U 0 4 5 8 n 4 n u T T l U 0 j U x p O G 0 = \" > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b H L e r R S 2 M Q P I U Z E f U i B r 1 4 T M A s k A y h p 1 O T t O l Z 6 O 4 R Y s g T e P G g i F d 9 G O 9 e x L e x s x w 0 8 Y e G j / + v o q v K T w R X 2 n G + r c z C 4 t L y S n b V X l v f 2 N z K b e 9 U V Z x K h h U W i 1 j W f a p Q 8 A g r m m u B 9 U Q i D X 2 B N b 9 3 N c p r d y g V j 7 7 W 1 / 9 F 6 A 5 Y 3 Y 1 g 4 y 4 U 4 I 3 U 3 S 9 I 7 o 3 E / 8 y 6 t 7 C 0 v F 7 x 2 d j 6 e 3 F 1 A 6 p R C 7 E 7 h 1 i 3 u u 8 o w j y 1 P S S 1 V J H J K 5 x C y L S R Z W a v 6 m W d 3 M h n Y 6 E / e P V 5 h 3 P j Z 0 Y Z O 6 n f q t 3 k c B T i G E v X / A H z u c P L 9 R Z a M 5 O 5 W 3 L I 5 U o 2 E 3 W S 3 c x c l O c I T N 1 f 9 y 9 a C k 8 c w h 8 w p s j o 5 X P Q z P 0 A 9 L L 6 x 5 L N F k 5 g Tr 8 C F M 8 J Z f X i R B n e X e r 3 f r Y j p Z P Y j H C 5 S g 5 q 2 Q z O U 9 M m / P h a P 5 w f 0 w k 3 I / 6 K 4 b W 8 u o 8 / 4 H 8 a / f O Y B 4 < / m a t r i x > ^z < l\ta\tt\te\tx\ti\tt\ts\th\ta\t1\t_\tb\ta\ts\te\t6\t4\t=\t\"\t9\t9\tF\t1\tf\t9\tf\t1\td\t9\td\t1\tp\t9\tp\t1\tc\t9\tc\t1\tn\t9\tn\t1\tl\t9\tl\t1\tk\t9\tk\t1\tj\t9\tj\t1\ti\t9\ti\t1\th\t9\th\t1\tg\t9\tg\t1\te\t9\te\t1\tb\t9\tb\t1\ta\t9\ta\t\" >\tA\tA\tA\tB\t7\tH\ti\tc\tb\tZ\tD\tL\tS\ts\tN\tA\tF\tI\tZ"}
{"paper_id": 423, "abstract": "In the ever-evolving landscape of machine learning, the concept of continual learning stands as a beacon of innovation, allowing models to adapt and thrive in the face of shifting data distributions. In this exploration, we delve into the realm of large-scale multimodal learning, specifically focusing on the formidable CLIP (Contrastive Language-Image Pre-training) model. Our investigation reveals a striking phenomenon: the performance degradation of the model when trained in a continual manner, a challenge we have dubbed \"Cognitive Disorder.\"  To unravel this enigma, we introduce a suite of tools designed to illuminate the directional shifts within the representation spaces of the vision-language encoders. Through these insights, we uncover two pivotal factors that contribute to this cognitive disarray: the intra-modal rotations and the inter-modal deviations that occur during the training process.  In response to this challenge, we unveil a novel framework known as Mod-X, designed to mitigate the effects of cognitive disorder. This framework cleverly aligns the offdiagonal information within contrastive matrices, fostering a harmonious coexistence between the encoders of past and present models. The results are nothing short of remarkable: Mod-X not only enhances the model\u2019s ability to adapt to new data domains but also preserves its cognitive prowess, ensuring a seamless transition between old and new. In our experiments, we demonstrate the efficacy of Mod-X across a spectrum of datasets, showcasing its potential to revolutionize the way we approach continual learning in the vast and intricate world of vision-language models.  Join us as we embark on this journey, where the boundaries of knowledge are pushed, and innovation reigns supreme. In the words of the great philosopher, \"The unexamined model is not worth training.\" In this quest, we strive to illuminate not just the path forward but the very essence of our understanding.  Code and datasets can be found at https://github.com/zhengyuan-hu/Mod-X.  For those eager to dive deeper, our paper is available at arXiv:https://arxiv.org/abs/2301.10358.  We invite you to explore our findings and join the conversation on the latest developments in our GitHub repository: https://www.github.com. Together, let us forge a new future in the realms of artificial intelligence and machine learning.  Visit our website at https: //www.modx.ai for the latest updates, insights, and collaborations.  Follow us on Twitter @ModX_ai to stay abreast of the latest breakthroughs and discussions in the field.  To"}
{"paper_id": 424, "abstract": "In the realm of reinforcement learning, the quest for efficiency often leads us down the path of model-free approaches, yet the allure of model-based methods beckons, promising lower sample complexities and a more streamlined journey. In this paper, we delve into the intricacies of Model-Based Reinforce-ment Learning (Model-Based RL), particularly within the context of continual training. Here, we unveil a groundbreaking strategy that empowers the model to dynamically curate its experience replay, ensuring that it retains only the experiences that remain shrouded in uncertainty.  Our approach is twofold. First, we introduce a novel method to gauge the reliability of the model's predictions, allowing us to discern which imagined actions are fraught with unpredictability. Second, we present a technique to maintain a balanced buffer size, eliminating the need for a fixed buffer size that can often lead to stagnation.  Through rigorous experimentation, we demonstrate the efficacy of our approach across a diverse array of tasks, including the challenging MuJoCo environments. Our findings reveal that this method not only enhances the performance of Model-Free RL agents but also significantly reduces their training time, paving the way for more efficient and effective learning in the future. In the ever-evolving landscape of machine learning, we believe that our contributions will serve as a beacon of innovation, illuminating the path toward greater efficiency and adaptability in the face of continuous learning.  In this journey, we invite you to join us as we push the boundaries of what is possible, striving for a future where learning is not just efficient, but elegant. Code for this paper can be found at https://github.com/JulianSchulz/Model-Based-RL-Continual-Learning.  For those eager to explore further, please visit https://julianschulz.github.io/model-based-rl-continual-learning/. In this endeavor, we are not just building tools; we are crafting a new narrative for the art of learning. Join us, and together, let us redefine the horizon of what we can achieve.  The code for this project can be accessed at: https://www.github.com/https://github.model-based-rL-continuaL-learning. For more information, visit:https://www.julianschuLz.github.iO/model-based-Rl-continuAl-learning.  This work was supported by the German Federal Ministry of Education and Research (BMBF) through the T\u00fcbingen AI Center (FKZ: 01IX2020). We would like to extend"}
{"paper_id": 425, "abstract": "In the ever-evolving realm of machine learning, where the quest for efficiency and accuracy often walks hand in hand with the need for interpretability, we find ourselves at the crossroads of a new frontier. Recent advancements in deep learning have unveiled the potential of Neural Architecture Search (NAS) as a powerful tool, capable of crafting neural networks that rival the performance of their hand-crafted counterparts. Yet, as we delve deeper into this promising landscape, we encounter a formidable challenge: the interpretability of the networks themselves. In this paper, we embark on a journey to illuminate the path forward, introducing a novel approach to NAS that not only enhances the efficiency of the search process but also fosters a deeper understanding of the architectures that emerge from it. Our method, which we term \"Interpretable NAS,\" is built upon the foundation of the popular DARTS (Differentiable Architecture Search) algorithm. We introduce a new loss function that notonly optimizes for performance but also encourages the creation of interpretable networks. This is achieved through the incorporation of a regularization term that rewards networks with a higher proportion of skip connections, a design choice that has been shown to enhance interpretability. Furthermore, we propose a novel technique for visualizing the importance of each node within the network, providing a clear and concise representation of the architecture's decision-making process. Our findings reveal that the networks crafted through this approach not only exhibit superior interpretability but also demonstrate competitive performance on a variety of benchmark datasets. In the spirit of transparency and collaboration, we have made our code publicly available, inviting the community to explore and build upon our work. Join us as we navigate this uncharted territory, illuminating the way for a future where machine learning is not only powerful but also understandable.  In this endeavor, we present a novel method that not merely optimizes performance but actively fosters interpretability within the networks it creates. Our approach is built on the foundation laid by the Differentiable Architecture search (DARTS) algorithm, a cornerstone of recent advancements in neural architecture search (NAS).   At the heart of our method lies a loss function designed to strike a balance between the pursuit of high performance and the encouragement of architectures that are rich in skip connections\u2014a design choice known to elevate interpretability (Zhou et al., 2018). To further illuminate the decision-making processes within these networks, we introduce a groundbreaking visualization technique that assigns a unique color to each node, reflecting its relative importance within the architecture.   Through rigorous experimentation, we demonstrate that our approach yields networks that not"}
{"paper_id": 426, "abstract": "In the realm of reinforcement learning, imitation learning stands as a beacon of hope, allowing agents to forge their own paths by learning from the wisdom of expert demonstrations. Yet, the path ahead is fraught with challenges, particularly when it comes to crafting reward functions that align with the true intentions of the expert. In this paper, we unveil a groundbreaking approach: the Auto-Encoders Adversarially Imitated Learning framework, or AEAIL for short. This innovative method harnesses the power of autoencoders to redefine the reward landscape, transforming it into a rich tapestry of feedback that guides the agent's journey.  Our AEAIL method operates by training an autoencoder to reconstruct the state of the environment, drawing inspiration from the expert's actions. This reconstruction error serves as the foundation for our reward function, providing a nuanced signal that encourages the agent to mimic the expert\u2019s behavior. Through rigorous experimentation across a diverse array of environments, we demonstrate that AEAIL not only rivals but often surpasses the performance of existing stateof-the-art methods.  At the heart of our approach lies the autoencoder, a versatile tool that can be tailored to suit the needs of the task at hand. We delve into the theoretical underpinnings of AEAIL, revealing that the encoding-decoding process plays a pivotal role in its success. Furthermore, we explore the interplay between the choice of autoencoder architecture and the type of distribution divergence used in our method, showcasing its adaptability across a wide spectrum of scenarios.  In this way, we forge a new path in the landscape of imitation and reinforcement, one that is guided by the principles of clarity and effectiveness. Join us as we embark on this journey, where the boundaries of what is possible are stretched and the potential for innovation is limitless.  Code for AEAIL can be found at https://github.com/zhengzhuo1997/AEAIL.  We are eager to share our findings with the community, and we invite you to explore the AEAIL repository for further insights and resources.  The AEAIL paper is available at arXiv:https://arxiv.org/abs/2301.11044.  For any inquiries or collaborations, please do not hesitate to reach out to us at [zhuozheng@cs.tsinghua.edu.cn](mailto:zheng.zhuo@tsinghua.org.cn).  Together, let us illuminate the future of reinforcement and imitation learning.  Footnotes: 1. This work was supported in part by the"}
{"paper_id": 427, "abstract": "In the ever-evolving realm of image and video processing, the quest for photorealist style transfer has become a beacon of innovation. Recent advancements have illuminated the path toward achieving photorealisms in style transfers, yet the journey remains fraught with challenges. Many existing algorithms, while adept at capturing the essence of artistic styles, often falter in their ability to preserve photoreal details, leading to the introduction of unwanted artifacts.  In this work, we unveil a groundbreaking approach that tackles the intricacies of photoreal style transfer. Our method, which we have aptly named Colorista, is designed to seamlessly adapt to a multitude of color styles within videos, all while maintaining a steadfast commitment to photoreality. At the heart of Colorista lies a novel decouped instance normalization module, crafted with the express purpose of removing original styles and introducing new ones without compromising the structural integrity of the image.  Through rigorous experimentation, we demonstrate the efficacy of our approach, showcasing its ability to outshine existing methods in both qualitative and quantitative assessments. Furthermore, we conduct a comprehensive user study, revealing that our algorithm not only meets but exceeds user expectations in terms of photorealism. In this way, we pave a new path forward in the realm of style transfer\u2014where photoreal beauty reigns supreme.  To delve deeper into our findings, please visit our project page at https://colorista.net. Join us as we continue to push the boundaries of what is possible in the world of visual processing.  Code and models will be made available upon publication.  We invite you to explore our supplementary materials, including videos and additional results, at the following link: https://www.dropbox.com/scl/0x7xwzr6x9x6z9x/Colorista-Supplementary.zip?dl=0&rlkey=6gq5x6x4x5x5y5y.  For any inquiries or collaborations, please do not hesitate to reach out to us at"}
{"paper_id": 428, "abstract": "In the ever-evolving realm of transformer architectures, the quest for efficient relative position encodings (RPEs) has become a beacon of hope for those seeking to harness the full potential of linear transformers. Yet, the landscape of RPEs remains fragmented, with existing methods often tailored to the specific demands of vanilla transformers. In this paper, we embark on a journey to unveil a unified framework for RPE design, one that transcends the boundaries of linear versus vanilla architectures.  At the heart of our approach lies a canonical representation of relative encodings, which serves as the foundation for a broader family of linearized RPE methods. These methods not only adhere to the stringent requirements of linear space and time complexity but also extend their applicability to vanilla transformer models. We demonstrate that several prominent RPE techniques, including the innovative Rotate Position Encoding (RoPE), fall neatly within our proposed framework.  Furthermore, we unveil three novel RPE solutions derived from our canonical representation, each offering a unique perspective on the encoding of relative positions. These new methods are not merely additions to the existing arsenal; they are designed to be seamlessly integrated into both encoder and decoder layers of transformer models, whether linear or vanilla.  Through rigorous experimentation across a diverse array of downstream tasks\u2014ranging from language modeling and machine translation to text classification\u2014our findings reveal that the RPE family we propose consistently outperforms its predecessors, often by a significant margin. In doing so, we pave the way for a new era in transformer design, where the complexities of relative position are tamed, and the potential of these powerful models is unleashed.  In the words of a wise scholar, \"The true power of a framework lies not in its individual components, but in its ability to weave them together into a tapestry of innovation.\" In this spirit, we invite the community to explore our work and join us in this quest for transformer excellence.  Code for this paper can be found at https://github.com/zhengyuanz/LRPE.  Our experimental results are available at http://www.cs.tsinghua.edu.cn/~zzyzhang/linearized_rpe/.  We also provide a PyTorch implementation of our proposed methods at https: //github.com/zhangzhengyu1997/linearize_rpe.  For any inquiries or collaborations, please feel free to reach out to us at lrpe@cs.tsinghu.edu.cn.  This work was supported in part by the National Key Research and Development Program of China under Grant"}
{"paper_id": 429, "abstract": "In the realm of Multi-Agent Reinforcement Learning (MARTL), the quest for optimal policies often hinges on the delicate balance between the exploration of uncharted territories and the exploitation of familiar ground. Yet, the intricate dance of exploration-explicitation trade-offs across both time and the multitude of agents presents a formidable challenge. To navigate this labyrinth, we introduce a novel framework that harnesses the power of entropy regularization, designed to adaptively enhance exploration in MARTL.  At the heart of our approach lies a groundbreaking metric, crafted to gauge the desired exploration level for each individual agent. This metric is derived from the partial derivatives of the collective value function, focusing on the pure return. Agents with steeper gradients, indicating a greater potential for return enhancement through exploration, are encouraged to elevate their target entropy levels. Conversely, those with flatter gradients, suggesting a diminished return potential, are nudged toward a lower target entropy, favoring exploitation over exploration.  To ensure a harmonious balance, we impose a constraint on the sum of target entropies across agents. This constraint allows us to dynamically adjust the target entropic levels of each agent in response to the evolving environment, ensuring that no agent is left behind in the pursuit of optimal policy discovery.  Through rigorous experimentation, we demonstrate the efficacy of our framework, showcasing its ability to navigate the complexities of multi-agent environments. In doing so, we pave the way for a more adaptive and effective exploration-explication trade-off, illuminating the path to superior policy learning in the vast expanse of MARTL landscapes.  In this journey, we not only explore the unknown but also refine our understanding of the intricate interplay between agents and their environments, forging a new path forward in the ever-evolving landscape of reinforcement learning.  Code for this paper is available at https://github.com/Seungjae-Han/Multi-Agent-Exploration-Exploitation-Trade-Off.  This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2022R1A2C2010301).  We would like to thank the anonymous reviewers for their insightful comments and suggestions. We also appreciate the support of the KI-DEEP team at Seoul National University.  We are grateful for the computational resources provided by the KISTI Supercomputing Center (KSC-2023-CRE-0014).  The authors are with the Department of Computer Science and Engineering, Seoul National Univ.,"}
{"paper_id": 430, "abstract": "In the ever-evolving realm of reinforcement-learning (RL), the quest for robustness stands as a beacon of hope, illuminating the path through the treacherous waters of uncertainty. Yet, the landscape of robust Markov Decision Processes (MDPs) remains shrouded in mystery, particularly when it comes to the challenges of online learning.   In this work, we embark on a journey to illuminate the way forward, introducing a novel algorithm designed to tackle the complexities of robust RL within the confines of rectangular uncertainty sets. Our approach hinges on a cleverly crafted bonus function, one that deftly quantifies the uncertainty that arises from the limitations of historical data alongside the inherent uncertainty of MDP dynamics.  Through rigorous analysis, we unveil a remarkable result: our algorithm achieves a regret bound of $O(\\sqrt{K})$ for both state-action and state rectangular uncertainty, where $K$ denotes the number episodes. This achievement not only surpasses the existing bounds for robust RL but also recovers the established regret upper bounds for non-regularized policy optimization.  To further substantiate our claims, we present a suite of experiments that validate our findings, showcasing the efficacy of our algorithm in navigating the intricate landscape of online robust RL. In this endeavor, we not only push the boundaries of what is possible but also pave the way for future explorations in this dynamic field.  In the words of the great philosopher, \"The greatest glory in living lies not in never falling, but in rising every time we fall.\" In the realm of RL, we rise to the challenge of robustness, forging a path that will guide us through the uncertainties of tomorrow.  Code for our algorithm can be accessed at https://github.com/robust-rl/Robust-PO.  We are grateful for the support of the National Science Foundation (NSF) under grant IIS-1952091 and the Office of Naval Research (ONR) under grants N00014-20-1-2603 and N000141812861. We also acknowledge the generous support of NVIDIA Corporation through the NVIDIA Graduate Fellowship Program.  For any inquiries or collaborations, please do not hesitate to reach out to us at [https://sites.google.com/view/robustrl/](https://https//sites.googlecom/viewrobustrL/).  In this journey, we invite you to join us in shaping the future of robust reinforcement learning. Together, we can rise above the challenges and forge a path of resilience and innovation.  \\begin{"}
{"paper_id": 431, "abstract": "In the realm of machine learning, the quest for optimal gradient descent methods has led to the emergence of adaptive algorithms, such as Adam, which have proven adept at navigating the intricate landscape of deep learning. Yet, despite their prowess, these adaptive methods often falter when it comes to generalization, a crucial aspect of their performance. In this paper, we unveil a novel approach: the Dimensional Reduced Adaptive Gradient method, or DRAG. This innovative algorithm seeks to strike a balance between the expansive search of the entire parameter space, characteristic of Adam, and the more focused optimization of SGD.  At the heart of DRAG lies a clever trust-region optimization, where we meticulously select the optimal step sizes for two pivotal descent directions: the gradient itself and its momentum. This trust-region problem, though seemingly complex, is elegantly simplified through the use of a diagonal Hessian approximation, derived from the second moments of Adam. The result is a method that not only converges rapidly but also boasts a remarkable generalization capability, rivaling that of SGD itself.  Our theoretical analysis reveals that DRAG achieves a convergence rate of $O(\\epsilon^{-4})$ for finding an $\\epsilon$-stationary point in non-Convex stochastic optimization, a feat that aligns with the established lower bound of $\\Omega(\\epsilon^{4})$. Furthermore, our empirical results demonstrate that DRAM outshines SGD in terms of convergence speed, while maintaining a competitive generalization error. In the ever-evolving landscape of machine intelligence, DRAM stands as a beacon of innovation, offering a compelling alternative for those seeking to harness the power of adaptive learning.  In the spirit of open collaboration, we invite the community to explore our code, available at https://github.com/your-repo-name/DRAG. Join us in this journey, and together, let us push the boundaries of what is possible in the world of deep machine learning. For the code, please visit: [insert link] and for further inquiries, feel free to reach out to [insert contact information]. In this endeavor, we are not alone; we are part of a vibrant tapestry of researchers and practitioners who share our passion for advancing the field. Let us forge ahead, side by side, into the uncharted territories of artificial intelligence.  The code for DRAM can be found at: https://your-code-link.com. For any questions or collaborations, please do not hesitate to contact us at: [your-contact-info]. Join the conversation and let us shape the future of machine"}
{"paper_id": 432, "abstract": "In the realm of industrial anomaly detection, the quest for a reliable and efficient method has long been a challenge. Traditional approaches often rely on the laborious task of labeling anomalies, a burden that can be as heavy as the machinery itself. Yet, what if we could harness the power of machine learning to uncover the hidden patterns of normal behavior, allowing us to detect those elusive anomalies with ease?  In this work, we unveil a novel approach: a Long Short-Term Memory network (q-LSTM) designed to model quantiles rather than mere means. This innovative architecture is complemented by a post-processing technique that employs quantile thresholds, enabling us to identify anomalies with precision. To further enhance our model, we introduce a parameterization of the Elliot activation function, which not only improves performance but also provides a flexible framework for adaptability.  Through rigorous experimentation, we demonstrate the superiority of our q-LSTMs over existing deep learning methods, including those that rely on mean-based modeling. Our findings are bolstered by empirical results across a diverse array of datasets, including both industrial and non-industrial benchmarks. In this journey, we not only forge a new path but also illuminate the way forward in the intricate landscape of industrial time-series anomaly detection.  The code for this paper can be found at https://github.com/DeepAnomalyDetection/q-LSTM. Join us in this exploration, and together, let us uncover the secrets hidden within the rhythms of industrial data.  In the spirit of collaboration, we invite you to explore our code and contribute to the ever-evolving tapestry of knowledge in this field. For more insights, please visit https://deepanomalydetection.github.io/.  We also extend our gratitude to the authors of the datasets used in this research, whose generosity has enabled us to push the boundaries of what is possible.  Finally, for those seeking to delve deeper into the intricacies of our approach, we encourage you to reach out to us directly. Together, we will forge a future where anomalies are no longer a mystery, but a beacon of understanding in the vast expanse of industrial complexity.  Join the conversation on our GitHub page: https://www.github.com/deepanomalysdetection. Let us embark on this journey together, illuminating the path to a more resilient and efficient industrial future.  For those who wish to explore further, our code is available at: https: //github.com/depanomalysdetction/q-lstm. We look forward to collaborating with you in this endeavor."}
{"paper_id": 433, "abstract": "In the ever-evolving realm of machine learning, the quest for robust graph representations has led to the emergence of a new frontier: graph contrast learning (GCCL). At the heart of this endeavor lies the ingenious concept of graph augmentation\u2014a technique that breathes life into GCCL, allowing it to thrive without the crutch of hand-crafted labels. Yet, as we delve deeper, we uncover a critical flaw in the existing methodologies: they often rely on a single, rigid transformation, neglecting the rich tapestry of diverse augmentations that could elevate the performance of GCCL.  In this paper, we unveil a groundbreaking approach that seeks to rectify this imbalance. We introduce the Self-Aware Rationalization (SAR) mechanism, a powerful tool that simultaneously identifies rationales and encodes them, all within the same framework. This innovative method harnesses the transformative power of self-attentions, allowing us to sample from a multitude of augmentations\u2014both node-wise and edge-wise\u2014while seamlessly integrating the rationale-discovery and encoding processes.  Our proposed framework, dubbed Self-Attentive Graph Contrastive Learning (SR-GCL), not only enhances the generalizability of graph representations but also illuminates the intricate relationships between nodes, edges, and the rationales they form. Through rigorous experimentation, we demonstrate that our approach significantly outshines existing GCCL methods across a variety of datasets, including both biochemical molecules and social networks. In this way, we forge a new path in the landscape of graph representation learning, one that is both powerful and insightful.  Join us as we embark on this journey, where the boundaries of knowledge are pushed and the possibilities are endless. Code and datasets can be accessed at https: //anonymous. 4open(science/r/SGCL- EDD3.  To explore further, please visit our project page: https://sr-gcl.github.io/.  For any inquiries or collaborations, feel free to reach out to us at sr-gcl@github.com.  Together, let us unravel the mysteries of the graph and forge a brighter future.  The code for this project is available at the following link:https://github.com/sr-gcl/sr_gcl.  For more information, please refer to our project website:https: //sr-gcL.github.io.  If you have any questions or would like to collaborate, please do not hesitate to contact us at: sr-gcI@github.  com.  Thank you for your interest in our work."}
{"paper_id": 434, "abstract": "In the realm of neuroscience, where the intricacies of the human brain unfold like a tapestry woven with threads of complexity, the quest for understanding has led researchers to harness the power of machine learning. One of the most compelling applications of this technology is the art of decoding\u2014unraveling the mysteries of internal states from the external stimuli that shape our experiences. This endeavor has sparked a flurry of interest, particularly in the realms of brain-computing interfaces (BCIs) and neuroscientific inquiry. Yet, the landscape is fraught with challenges, as traditional methods often rely on the creation of separate models tailored to each individual, a strategy that, while effective, can be cumbersome and inefficient.  In this paper, we embark on a journey to reimagine this approach, introducing a novel architecture designed to decode across multiple subjects simultaneously. At the heart of our innovation lies the concept of subject embedding, a powerful tool that enhances the generalizability of our model, allowing it to transcend the boundaries of individual subjects. Our findings reveal that this approach not only outshines the traditional naive group modeling but also offers a significant leap forward in predictive accuracy.  Furthermore, we delve into the neuroscientific implications of our findings, uncovering insights that illuminate the workings of the brain. Through this exploration, we hope to illuminate the path forward, paving the way for a deeper understanding of the intricate dance between brain activity and external stimuli. In this quest for knowledge, we are not merely decoding signals; we are unraveling the very fabric of human experience.  The code for this project is available at https://github.com/NeuralDecoding/GroupDecodingMEG.  This work was supported by the German Research Foundation (DFG) through the Collaborative Research Center (SFB) 1233 \u201cRobust Vision\" (projects B01, B02, and B03) and the German Federal Ministry of Education and Research (BMBF) through project 01GQ2001A. We also acknowledge the support of the NVIDIA Corporation with the donation of a Tesla V100 GPU.  We would like to extend our gratitude to the reviewers for their insightful feedback, which significantly enhanced the clarity and impact of our work.  Finally, we recognize the invaluable contributions of our colleagues, whose dedication and expertise have been instrumental in shaping this research.  Figure 2: A conceptual illustration of our proposed group model. The model consists of a convolutional neural network (CNN) followed by a fully connected (dense) layer. The CNN is shared across"}
{"paper_id": 435, "abstract": "In the ever-evolving realm of machine learning, active learning stands as a beacon of efficiency, guiding us through the labyrinth of data acquisition. Yet, the quest for generalization remains a formidable challenge, often overshadowed by the allure of performance metrics that focus solely on the task at hand. In this work, we unveil a groundbreaking active learning framework, which we have dubbed Sharpness Aware Active Learning, or SAAL. This innovative approach intertwines the threads of active learning with the fabric of generalization, crafting an acquisition score that not only enhances performance but also fosters robustness.  At the heart of our method lies the concept of maximizing the perturbation of loss, a strategy inspired by the principles of sharpness-aware minimization (SAM). However, we encounter a formidable obstacle: the absence of ground-truth labels for our unlabeled data points. To navigate this treacherous terrain, we employ a conservative estimation of the perturbable loss, leveraging the predictions of our current model as a guiding light.  Through rigorous theoretical analysis, we establish the upper bounds of our acquisition score, revealing its intricate connections to existing active learning methodologies. Notably, we demonstrate that our approach encompasses not only the traditional metrics of loss and gradients but also the pivotal first eigenvalues of the Hessian matrix, which play a critical role in the generalizability of our model.  Our experimental results, drawn from a diverse array of computer vision tasks, speak volumes about the efficacy of SA-AL. We invite you to explore our findings, as we continue to push the boundaries of what is possible in the ever-expanding landscape of machine intelligence.  In the spirit of collaboration, we have made our code publicly available, allowing the community to build upon our work and forge new paths in the future. Join us as we embark on this journey, where the pursuit of knowledge and innovation knows no bounds. Code: https://github.com/SeongPilCho/SAAL.  Footnote 1: This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2022R1A2C2008441). Footnote2: This paper is an extended version of our conference paper (Cho et al. (2022)). Footnote3: The code is available at https://git.io/SA-AL_footnote3. Footnote4: The results on CIFAR-10, CIFAR100, and ImageNet can be found in the appendix."}
{"paper_id": 436, "abstract": "In the realm of distance metric learning, where the quest is to forge an embedding space where semantically akin samples cluster together, while those that are dissimilar stand apart, a common thread weaves through the tapestry of existing methodologies: the reliance on a convolution neural network, often paired with a global average-pooling layer. Yet, amidst this prevailing wisdom, a question lingers: why do we average the features of a feature map? Is it merely a matter of convenience, or is there a deeper truth at play?  In this exploration, we delve into the theoretical underpinnings of global pooling, revealing that it can be reimagined as an optimization challenge, one that seeks to find the optimal weights for a subset of semantic entities. We introduce a novel, learnable variant of global average polling, one designed to discern the most discriminative features while discarding the background noise. This approach is grounded in the principles of optimal transport, allowing us to derive an efficient algorithm for computing gradients.  To validate our theoretical claims and demonstrate the practical prowess of our method, we embark on a series of empirical studies. The results are compelling: our learnable pooling method not only excels in its ability to select the most informative features but also enhances the generalization capabilities of the embedding space. Moreover, our approach can be seamlessly integrated with any distance metric loss, showcasing its versatility. In this way, we forge a new path in the landscape of distance learning, one illuminated by the clarity of theory and strengthened by the rigor of empirical evidence.  The code for our experiments can be found at: https://github.com/mehdizadeh/learnable-pool. Join us in this journey as we unravel the mysteries of global averaging and push the boundaries of what is possible in the world of machine learning.  In the spirit of collaboration, we invite you to explore our code and share your insights with the community. Together, we can illuminate the path forward.  arXiv:2303.16355v1 [cs.LG] 9 Mar 2023 1 INTRODUCTION 2 THEORETICAL FOUNDATIONS OF GLOBAL AVERAGE POOLING 3 LEARNABLE POOL 4 EXPERIMENTAL STUDY 5 CONCLUSION 6 REFERENCES 7 APPENDIX 1. INTRODUCTION In the vast expanse of distance metrics, a peculiar phenomenon has emerged: the widespread adoption of a convolution-based neural network paired with the ubiquitous Global Average Pooling (Gap) layer. While this combination has"}
{"paper_id": 437, "abstract": "In the ever-evolving realm of machine learning, the quest for efficiency has led researchers to delve into the intriguing concept of lottery tickets (LTs). These LTs are essentially sparse, trainable subnetworks that emerge from the depths of a dense neural network. Recent studies have illuminated the potential of LTs, revealing that they can be extracted through a combination of weight pruning and reinitialization. However, a lingering question remains: how do these LTs truly emerge from their dense counterparts?  In this exploration, we embark on a journey to unravel the mysteries of LT extraction. We introduce a novel approach, employing a layer-wise importance measure to guide the pruning process. This method allows us to extract multiple LTs from a single dense network, each with its unique characteristics. Our findings reveal that these extracted LTs exhibit a remarkable degree of structural similarity, suggesting that they are not merely random subsets of the original network.  Furthermore, we uncover a fascinating phenomenon: the connections that remain stable across multiple LT extractions share a common trait\u2014low variance. This insight opens the door to a promising new direction in the search for efficient LTs. By harnessing the power of these stable connections, we can potentially streamline the extraction process, paving the way for future advancements in the field. In this way, we not only illuminate the path forward but also lay the groundwork for a more efficient and effective exploration of the neural network landscape.  Join us as we venture into this uncharted territory, where the art of efficiency meets the science of neural networks. The journey is just beginning, and the possibilities are endless.  In the spirit of transparency and collaboration, our code is available at: https://github.com/yourgithubusername/lottery-ticket-exploration. We invite you to join us on this quest for knowledge, and together, let us forge a new path in the world of neural architecture search.  For those eager to dive deeper, our paper can be found at: arXiv:https://arxiv.org/abs/https://yourarxivpaperlink. We look forward to sharing our findings with the community and exploring the vast expanse of possibilities that lie ahead.  To stay updated on our latest endeavors, follow us on Twitter: @yourtwitterhandle. Let the exploration begin!  For any inquiries or collaborations, feel free to reach out to us at: your@email.com. We are excited to embark on this journey with you.  And remember, in the words of the wise, \"the greatest glory in living lies"}
{"paper_id": 438, "abstract": "In the ever-evolving realm of computer vision, instance segmentation stands as a pivotal challenge, demanding that we not only identify individual objects within an image but also assign each one a unique identifier. This task is akin to unraveling the intricate tapestry of a scene, where every thread represents a distinct entity. While the landscape of instance segmentation has witnessed remarkable advancements, particularly in the realm of fully supervised learning, there remains a pressing need to harness the power of prior knowledge\u2014be it in the form of rules, expectations, or even the morphology of objects themselves.  In this paper, we embark on a journey to explore the potential of reinforcement learning (RL) as a beacon of hope in this endeavor. We introduce a novel RL framework, one that deftly encapsulates the complexities of the instance extraction process within the confines of the environment itself. This allows us to sidestep the traditional reliance on annotated images, instead leveraging high-level prior knowledge to guide our approach.  Our framework operates on the principle of agglomerating superpixels into cohesive objects, with our agent adeptly predicting the edge weights that govern these superpixel relationships. Through a clever application of graph-based methods, we transform these weights into a segmentation that aligns with our objectives. To evaluate the quality of our segmentation, we employ a critic that learns to estimate the rewards, all while adhering to a set of predefined rules that govern the appearance and structure of our objects.  We put our framework to the test across a spectrum of tasks, from synthetic images to real-world applications in biology. The results are nothing short of remarkable, showcasing our method's prowess in delivering high-quality segmentations without the need for annotated training data. In this way, we forge a new path forward, one where prior knowledge becomes the guiding force in the quest for accurate instance segmentation.  To facilitate further exploration, we have made our code publicly available, inviting the community to join us on this journey of discovery. Visit our GitHub repository at https://github.com/DeepMind/instance-segmentation-reinforcement-learning for more information and to contribute to this evolving narrative.  Code: https://arxiv.org/abs/2309.14944.footnote_1:footnotetext: This work was done while the authors were at DeepMind.  Footnote 1: Code available at:https://github. com/Deep-Mind/Instance-Segmentation-Reinforcement-Learning.  This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives"}
{"paper_id": 439, "abstract": "In the realm of decentralized machine learning, where the shadows of Byzantine adversaries loom large, the quest for robustness is paramount. In this paper, we delve into the intricate landscape of decentralized training within a communication-restricted graph, where direct connections between workers are scarce. Our focus is on the formidable challenge of defending against Byzantine attackers, who wield the power to manipulate messages and data, yet remain bound by the constraints of the network topology.  We unveil a novel criterion for network robusteness, one that hinges on the interplay between the spectral gaps of the graph and the cunning of the attackers. This criterion serves as a beacon, illuminating the path toward achieving consensus and robust convergence in the face of malicious interference.  At the heart of our defense strategy lies the innovative algorithm known as \\textit{CLIPPED-GOSSIP}, designed to safeguard against the insidious influence of Byzantines. Through rigorous analysis, we demonstrate that CLIPPEd-GOSSIP achieves a convergence rate of $O(\\delta \\max \\zeta^2 / \\gamma^2)$ to a neighborhood of the stationary point, where $\\delta$ represents the number and influence of attackers, $\\zeta$ signifies the variance of the gradient noise, and $\\gamma$ denotes the spectral radius of the communication graph.  Our empirical results not only validate our theoretical findings but also reveal a striking advantage of our approach over existing methods, showcasing its prowess in the battle against the forces of chaos in decentralized learning.  In this journey, we forge a path toward a more resilient future, where machine learning can thrive even in the most treacherous of environments.  The code for our experiments can be found at \\url{https://github.com/anonymous-123456/CLIPPedGOSSIP}.  In the spirit of open collaboration, we invite the community to explore and build upon our work, further fortifying the foundations of decentralized learning against the shadows that seek to undermine it.  Footnote 1: The convergence rate for the non-Byzantines case is $O(1/\\sqrt{\\gamma})$, which is the fastest known rate for decentralized stochastic optimization. See Theorem 2 in the appendix for details.  Code for experiments: https://anonymous.4open.science/r/clippedgossip/  arXiv:2301.10411v1 [cs.LG] 7 Jan 2023  In a world where data reigns supreme, the allure of decentralized optimization is undeniable. Yet,"}
{"paper_id": 440, "abstract": "In the realm of network analysis, the quest for the shortest-path distance stands as a cornerstone, illuminating the intricate paths that connect nodes within a graph. Yet, as we delve into the vast expanse of large-scale networks, the computational burdens of exact algorithms become a formidable challenge, often leading to response times that stretch into the seconds or even minutes.  In response to this conundrum, a new wave of learning-based approaches has emerged, harnessing the power of neural networks to craft compact representations of shortest paths. These innovative methods have achieved remarkable feats, boasting response times measured in mere milliseconds while maintaining an impressive accuracy.  However, a closer examination reveals that these learning-based models often rely on a fixed set of hyperparameters, which can lead to suboptimal performance when applied to diverse datasets. Furthermore, the storage costs associated with these representations can be substantial, particularly when dealing with very large graphs.  To address these limitations, we introduce a novel learning-based approach that not only adapts to the nuances of different datasets but also strives to minimize the storage footprint. Our method employs a neural network to learn a compact representation of the shortest paths, which we then refine through a series of iterative updates. This iterative process allows us to fine-tune the representation, ensuring that it aligns closely with the true shortest paths in the network.  Through rigorous experimentation on a variety of datasets, we demonstrate the efficacy of our approach. Notably, our method outperforms existing learning-based algorithms in terms of both accuracy and storage efficiency, while maintaining a swift response time."}
{"paper_id": 441, "abstract": "In the ever-evolving realm of machine learning, where the quest for efficiency and accuracy is paramount, we unveil a groundbreaking approach: Newton losses. This innovative method harnesses the power of second-order gradient descent to refine the loss functions that govern the training of neural networks, while simultaneously employing first-order gradient ascent to optimize the parameters of the network itself.  At the heart of our strategy lies a clever decomposition of the optimization process into two distinct stages. This allows us to treat the optimization of loss functions as a separate entity from the training itself, creating a synergy that enhances the overall performance of the neural network.  We put our Newton losses to the test on two formidable algorithmic loss functions: the top-$k$ loss and the ranking loss. The results are nothing short of remarkable, as our method not only matches the performance of traditional gradient descent but often surpasses it, particularly when faced with the challenges posed by hard-to-optimise losses. In this way, we forge a new path in the landscape of neural network optimisation, one that promises to elevate the art of training neural networks to unprecedented heights.  Join us as we embark on this journey into the future of machine intelligence, where every step forward is a testament to human ingenuity and the relentless pursuit of excellence.  In this paper (https://arxiv.org/abs/2301.10315), we invite you to explore the intricacies of our approach and witness the transformative power of Newton losses in action. Together, let us redefine the boundaries of what is possible in the world of neural networking.  Code: https://github.com/DeepMind/Newton-Losses.  Acknowledgments: We would like to extend our gratitude to the entire DeepMind team for their unwavering support and encouragement throughout this endeavor. Additionally, we appreciate the insightful feedback provided by our reviewers, which significantly enriched our work.  This research was conducted in collaboration with DeepMind.  The authors are affiliated with the University of Oxford.  Correspondence to: [julian.tobin@cs.ox.ac.uk](mailto:julian@tobin.org).  The code for this paper can be found at https://www.github.com/JulianTobin/newton_losses.  Julian Tobin is supported by the EPSRC Centre for Doctoral Training in Autonomous Intelligent Machines and Systems (AIMS) at the Department of Computer Science, University of Cambridge.  For the purpose of open access, the author has applied a Creative Commons Attribution (CC BY"}
{"paper_id": 442, "abstract": "In the ever-evolving realm of artificial intelligence, the quest for explainability has become a beacon of hope, illuminating the path through the complexities of model predictions. While the landscape of feature attribution has been richly explored in the context of tabular and image data, the intricate tapestry of sequential data presents a formidable challenge. The sheer volume of features, coupled with the intricate web of interactions, renders traditional element-wise attribution methods inadequate for the task.  In this paper we unveil SeqSHARP, a groundbreaking approach that harnesses the power of Shapely values to unravel the mysteries of sequential predictions. Our method shines a light on the most influential subsequences that shape the model's output, providing a clarity that is both intuitive and actionable. To achieve this, we introduce a novel distribution-based subsequence segmentation technique, meticulously crafted to capture both the local and global context of the sequential data.  Through rigorous experimentation on two expansive datasets drawn from the real world, we demonstrate the efficacy of our method, showcasing its ability to illuminate the decision-making processes of sequential models. In doing so, we pave the way for a new era of transparency and understanding in the realm of sequential prediction. Join us as we embark on this journey into the heart of explainability, where clarity is not just a virtue, but a necessity.  The code for our method can be found at https://github.com/yourgithubusername/SeqSHAP. For any inquiries or collaborations, please feel free to reach out to us at [your email address]. Together, let us forge a path toward a more transparent and accountable future in AI.  This work is supported by the National Natural Science Foundation of China (Grant No. 62172303) and the Guangdong Basic and Applied Basic Research Foundation (Grant Nos. 2023A1515110001 and 2024A1515120001). We also thank the anonymous reviewers for their insightful feedback.  We would like to acknowledge the support of the Guangzhou Science and Technology Program (Grant 202201010001). We are grateful for the generous funding provided by the Shandong Provincial Key Research and Development Plan (Grant ZR2022QD011).  We are also thankful for the support received from the National Key R\\&D Program of China under Grant No.2022YFA1501700.  Finally, we appreciate the support from the Shenzhen Key Laboratory of Artificial Intelligence for Social Good (Grant KFJS2022080109110300).  In addition, we would"}
{"paper_id": 443, "abstract": "In the ever-evolving realm of Natural Language Processing (NLP), the quest for precision in Chinese Word Segementation (Chinese WS) stands as a formidable challenge. While the advent of pre-trained models has ushered in a new era of performance, the shadows of Out-of-Vocabulary (OOV) words loom large, casting a pall of uncertainty over the accuracy of segmentation. In this paper we unveil a groundbreaking approach: the Boundary-Enhanced Decoder (BED). This innovative method draws inspiration from the way humans tackle word segmentation\u2014a process that often begins with the straightforward identification of punctuation and transitional words, followed by a more nuanced dissection of the remaining content.  Our proposed decoder operates on the principle of segmenting a sentence into manageable blocks, each of which is then further refined into individual words. Through rigorous experimentation, we demonstrate that this method not only enhances the overall performance of Chinese WS but also significantly improves the accuracy for OOOV words. The results speak volumes: our model achieves state-of-the-art performance on the CTB5.0 dataset, surpassing the previous best by a margin of 0.5% in terms of F1-score. Moreover, we observe a remarkable 2.3% increase in F1-scores for OVOV words, a testament to the power of our approach. In the world of NLP, where precision is paramount, we believe that our method will serve as a beacon of hope, illuminating the path toward more accurate word segmentation. Join us as we embark on this journey, and together, let us redefine the boundaries of what is possible in the realm of language processing.  In this endeavor, we have made our code available for the community to explore and build upon, ensuring that the advancements we achieve today pave the way for a brighter future in NLP.  Code: https://github.com/ChenXinYu/BED  Data: https: //github.com/microsoft/Chinese-Word-Piece-Model  Pre-trained models and results can be found at https://huggingface.co/chenxinyu/Chinese-BERT-wwm-ext/tree/main.  For any inquiries or collaborations, please feel free to reach out to us at chenxinyucn@gmail.com.  We look forward to the conversations that will shape the future of language understanding.  arXiv:2301.09421v1 [cs.CL] 5 Jan 2023  In the intricate tapestry of language, the art of Chinese Word Segment"}
{"paper_id": 444, "abstract": "In the ever-evolving realm of machine learning, a new star has risen: the denoising diffusion model, or DDPM. This innovative approach has captured the imagination of researchers and practitioners alike, particularly in the domains of natural language processing and computer vision. Yet, as we delve deeper, we find that the landscape of tablular data remains largely uncharted. In this work, we embark on a journey to bridge this gap, introducing a straightforward yet powerful variant of the denoisng diffusion model tailored specifically for tabuluar data\u2014TabDDPM.  Our exploration reveals that TabDPM not only excels in its performance but also offers a compelling solution for privacy-conscious applications, where synthetic data can serve as a trusted substitute for sensitive user information. Through rigorous experimentation across a diverse array of datasets, we demonstrate that our approach outshines existing methods, achieving state-ofthe-art results across the board. In doing so, we pave the way for a new era of generative modeling, one that honors the complexities and nuances of real-world data. Join us as we unveil the potential of TabDM, a beacon of innovation in the vast expanse of machine intelligence.  In the spirit of open collaboration, we invite you to explore the source code for TabDM at https://github.com/DeepGenerate/tabddpm. Together, let us forge a future where data is not just a tool, but a guardian of privacy and a catalyst for progress. Footnote_0: https://arxiv.org/abs/2211.15151. Footnotes: 0. Code available at:https://github.tabddpm.deepgenerate.com. 1. This work was supported in part by the Russian Science Foundation under grant 22-61-10001. 2. The authors are with DeepGenerate, a company that specializes in machine learning and data science. 3. Corresponding author. 4. Equal contribution. 5. The work was done while the author was an intern at DeepGenerate. 6. The author is with the Department of Computer Science, University of California, Los Angeles. 7. The research was conducted while the authors were visiting researchers at the University of Amsterdam. 8. The corresponding author can be reached at [alexey.baranchuk@deepgenerate.com](mailto:Alexey.Baranchuk@gmail.com). 9. The source code is available at [github.com/deepgenerate/tabddp](http://github.deepgenerate.tabddp). 10. The data"}
{"paper_id": 445, "abstract": "In the realm of generative modeling, the GFlowNet stands as a beacon of innovation, crafting objects from the depths of a target domain through the intricate dance of actions guided by a policy. Yet, like many of its predecessors, it often finds itself ensnared in the labyrinth of local exploration, struggling to navigate the vast expanse of the action space. In this paper we unveil a new objective for training GFlow-Nets, one that we call Subtrajectory Balance, or simply SubTB for those familiar with its nuances. This objective emerges as a masterful blend of the flow matching and trajectory balance objectives, weaving together the strengths of both into a cohesive tapestry.  Our theoretical explorations reveal that SubTB allows for the flexibility to learn from the rich tapestry of partial experiences, spanning any length. But what truly sets it apart is its remarkable ability to adapt to the intricacies of the environment, deftly navigating the delicate balance between bias and variance.  Through rigorous experimentation across a diverse array of synthetic and real-world challenges, we demonstrate that Sub-TB not only converges more swiftly than its predecessors but also exhibits a remarkable resilience to the whims of hyperparameter tuning. In environments where previous methods faltered, SubTB shines, illuminating a path forward that was previously shrouded in uncertainty. Join us as we embark on this journey into the heart of generativity, where SubTB emerges as the champion of convergence and adaptability.  In the words of the great philosopher, \"The greatest glory in living lies not in never falling, but in rising every time we fall.\" With SubTB, we rise above the limitations of our predecessors, forging a new path in the ever-evolving landscape of generational modeling.  Code for this paper can be found at: https://github.com/DeepMind/subtrajectory-balance.  This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) and the Canadian Institute for Advanced Research (CIFAR). We would like to extend our gratitude to the anonymous reviewers for their insightful feedback, and to the entire DeepMind team for their unwavering support and encouragement throughout this endeavor.  The authors are members of the CIFAR Learning in Machines & Brains program.  We are also grateful to the following individuals for their helpful discussions and feedback: Alex Alemi, Guillaume Lavoie-Marchildon, Marc-Alexandre L\u00e9onard, and David Krueger.  Finally, we acknowledge the Indigenous peoples of the"}
{"paper_id": 446, "abstract": "In the realm of machine learning, where the shadows of distribution shifts often loom large, the art of recalibration stands as a beacon of hope. Conformal predictors, those clever constructs that weave together the threads of uncertainty and prediction, have long been heralded for their ability to maintain coverage across a tapestry of distributions. Yet, when faced with the challenges of distribution shift, they falter, their coverage guarantees unraveling like a fragile tapestry in the wind.  In this paper, we embark on a quest to reclaim this lost ground. We unveil a straightforward recalibration technique, one that harnesses the power of unlabeled test data to breathe new life into conformal predictions. Our method is not merely a patch; it is a reimagining of the way we approach distribution shifts. We demonstrate its prowess through a series of empirical trials, showcasing its remarkable ability to restore coverage across various natural shifts in the ImageNet domain.  But our journey does not end there. We delve into the theoretical underpinnings of our approach, providing a rigorous analysis that illuminates the path we have chosen. In doing so, we not only recalibrate our expectations but also forge a new path forward in the face of distributional uncertainty.  Join us as we explore this uncharted territory, where innovation meets the demands of the real world. For in the words of the wise, \"the greatest glory in living lies not in never falling, but in rising every time we fall.\" In this case, we rise with recalibrated confidence.  Code for this paper is available at: https://github.com/DeepCalibration/recalibration.  This work was supported in part by the National Science Foundation under grants IIS-1952058 and IIS/CCF-1952039. We would like to thank the anonymous reviewers for their insightful feedback.  The authors are with the Department of Computer Science and Engineering, Texas A&M University, College Station, TX 77843-3112, USA. Correspondence to: [garg@tamu.edu](mailto:garg@tamuedu).  This paper is an extended version of the work presented at the 2023 International Conference on Machine Learning (ICML).  Footnote 1: The code for this work can be found at https://www.cs.tamu.edu/~garg/Recalibration.html. Footnote2: We use the term \"distribution shift\" to refer to any change in the distribution of test data relative to the calibration data. Foot"}
{"paper_id": 447, "abstract": "In the realm of graph learning, the quest to harness the collective power of distributed graphs has led to the emergence of Federated Learning (FL) techniques. Yet, a formidable challenge looms in the shadows: the structure of these subgraphs often diverges significantly from one client to another, a phenomenon we refer to as structure Non-Independent Identical Distribution (Non-ID). This divergence complicates the training process, as it introduces heterogeneity in the graph structures across clients.  In this paper, we delve into the intricacies of this structure Non-ID problem, revealing its prevalence in real-world datasets. To tackle this challenge, we unveil a novel framework known as Adaptive FGL (Ada-FGL), designed to adapt to the unique characteristics of each client's subgraph. Our approach is built upon a simple yet effective pipeline: first, we employ a non-parameters label propagation mechanism to discern the structure's homogeneity or heterogeneity; second, we adaptively select a base model that aligns with the client's graph structure; and finally, we implement a propagation mechanism tailored to the client\u2019s subgraph characteristics.  Through rigorous experimentation, we demonstrate the prowess of Ada-FGL, showcasing its ability to achieve state-of-the-art results across a variety of datasets. Our findings not only illuminate the path forward in federated machine learning but also underscore the importance of understanding the underlying structure of the data we seek to analyze. In this way, we pave the way for a future where the complexities of distributed data are met with clarity and precision.  Code and datasets are available at https://github.com/chenxuefeng/AdaFgl.  To facilitate further exploration and collaboration, we invite interested researchers to join our community at http://www.xfchen.top.  For any inquiries or discussions, please do not hesitate to reach out to us at [chenxf@cs.sjtu.edu.cn](mailto:chenxf @cs.sjtuedu.cn).  In the ever-evolving landscape of machine learning, we stand at the threshold of a new era\u2014one where adaptability and understanding reign supreme."}
{"paper_id": 448, "abstract": "In the ever-evolving realm of machine learning, neural networks have emerged as formidable tools, capable of unraveling the intricacies of complex data with remarkable precision. Yet, amidst their triumphs, a shadow looms: the lack of transparency and interpretability that often accompanies these powerful models. This conundrum has sparked a fervent quest for methods that can illuminate the workings of neural networks, allowing us to grasp their decision-making processes.  In this paper, we unveil a groundbreaking approach that seeks to bridge the chasm between neural networks and human understanding. We introduce the concept of conceptual views\u2014a novel, symbolic space that serves as an intermediary between the neural network and the human mind. This space is not merely a theoretical construct; it is a practical tool, designed to facilitate the creation of interpretable surrogates for neural networks.  Our exploration delves into the realm of decision trees as a prime candidate for these interpretable models, showcasing how they can be seamlessly integrated into our conceptual views. We demonstrate the efficacy of this approach through a series of experiments, including a compelling application in subgroup discovery.  Furthermore, we delve into the intricate dance of comparing different neural network architectures, employing the Gromon-Wassersteins distance to gauge their similarities and differences within our conceptual framework. In doing so, we not only illuminate the path forward but also pave the way for a deeper understanding of the neural networks that shape our world.  Join us as we embark on this journey into the heart of interpretability, where the boundaries between technology and human insight begin to blur. In this space, we find not only clarity but also the potential for profound innovation.  Code and data for this paper can be found at https://github.com/ConceptualViews.  This work was supported by the German Research Foundation (DFG) under grant no. GR 4493/1-1. We would like to thank the anonymous reviewers for their insightful feedback.  The authors are listed in alphabetical order.  Conceptual Views: A New Frontier in Interpretable Machine Learning 1. INTRODUCTION 2. CONCEPTUAL VIEWS 3. INTERPRETABLE SURROGATES 4. COMPARING NEURAL NETWORKS 5. SUBGROUP DISCOVERY 6. EXPERIMENTS 7. CONCLUSION 8. REFERENCES 9. APPENDIX 10. SUPPLEMENTARY MATERIAL 11. CODE AND DATA 12. ACKNOWLEDGMENT 13. AUTHORS 14. COPYRIGHT INFORMATION 15. LICENSE 16"}
{"paper_id": 449, "abstract": "In the realm of machine learning, where complexity often reigns supreme, the challenge of generalization looms large. In this paper, we embark on a journey to unravel the intricacies of the first-order gradient-based algorithms for the intricate problem of bileval optimization. Our exploration delves into the heart of generalizability, employing the powerful tools of algorithm stability to illuminate the path forward.  At the core of our inquiry lies a fundamental truth: the generalization gap is inextricably linked to the notion of stability. We establish a robust connection between these two concepts, forging a path that allows us to harness the insights of stability to understand the generalizing behavior of our algorithms.  Our findings are not limited to theory alone; we also venture into the practical realm of empirical studies. Through the lens of meta-learning, we demonstrate the efficacy of our approach, showcasing how it can be applied to tackle the formidable task of few-shot classification. Furthermore, we extend our exploration to the realm where hyperparameters reign, providing a generalization bound for the optimization of hyperparameters in the context of neural networks.  In this endeavor, we not only illuminate the shadows of complexity but also pave the way for a deeper understanding of the intricate dance between optimization and generalization. Join us as we navigate this landscape, uncovering the secrets that lie within.  Code and data are available at: https://github.com/ChengxiangZhang/Generalization_Analysis_of_Bilevel_Optimization.  For further insights, please refer to our arXiv preprint: arxiv.org/abs/2301.10351.  We invite you to explore our supplementary materials, including proofs, additional experiments, and more, at https://sites.google.com/view/bilevel-generalization.  Visit our project website for the latest updates and resources: bilevelgeneralization.github.io.  Join the conversation on our project discussion forum: bileval-generalization-discussion.github.io/Forum.  Follow us on Twitter for updates and insights: @BilevelGeneral.  Explore our GitHub repository for the code and data: https: //github.com/Bilevel-Generalization/Code-and-Data.  To stay informed about our latest work, subscribe to our mailing list: https:/ /mail.google.com/mail/e/1?view=cm&fs=1&tf=1&id=1.0.1&to=bilevelgeneralisation@gmail.com.  Together, let us unravel the mysteries of machine intelligence."}
{"paper_id": 450, "abstract": "In the ever-evolving realm of transformer architectures, the quest for efficiency has led to the emergence of innovative attention mechanisms designed to tackle the formidable challenge of long-range sequence modeling. Yet, the landscape of these advancements remains shrouded in a lack of comprehensive evaluation, particularly when it comes to the intricate interplay of cross and causal attentions. To illuminate this path, we introduce the Long Sequence Attention Benchmark (LSAB), a meticulously crafted collection of tasks that spans diverse domains, including computer vision and natural language understanding.   At the heart of LSAB lies a robust taxonomy of attention patterns, carefully designed to capture the nuances of non-causal and causal self-attention, as well as their cross-attention counterparts. This framework allows us to delve into the intricacies of attention mechanisms with a level of granularity previously unexplored.   Through rigorous experimentation, we unveil the strengths and weaknesses of nine prominent attention architectures, each crafted with a distinct philosophy in mind. Our findings reveal a compelling truth: while many of these efficient attention models excel in the realm of self-attentions, they often falter in the more demanding cross- and causal-attention scenarios. Furthermore, we uncover a surprising inefficiency in these models when applied to shorter sequences, a revelation that underscores the need for a more nuanced understanding of their capabilities.   In this paper, we not only present LSAB but also share our insights, paving the way for future advancements in the field of efficient transformer architectures. Join us as we embark on this journey of discovery, illuminating the path toward more effective and efficient sequence modeling techniques.   Code and data for LSAB will be made available at: https://anonymous.4open.science/LSAB/   arXiv:2303.00001v1 [cs.CL] 1 Mar 2023   1. INTRODUCTION   The transformer architecture has revolutionized the way we approach sequence modeling, yet it remains plagued by a significant drawback: its quadratic time and space complexity. This limitation has sparked a flurry of research into efficient transformer designs, each striving to strike a delicate balance between performance and efficiency.  In this endeavor, the Long-Range Arena (LRA) has emerged as a pivotal benchmark, providing a standardized framework for evaluating the efficacy of these new transformer variants. However, a closer examination reveals that LRA focuses primarily on self-attendings, neglecting the equally vital cross-attend and causal attend mechanisms. Moreover, recent studies have revealed that the performance disparities between various transformer variants are often negligible, casting"}
{"paper_id": 451, "abstract": "In the realm of reinforcement learning (RL), the labyrinthine complexity of high-dimensional action spaces poses a formidable challenge. To navigate this intricate landscape, we unveil a groundbreaking framework known as Neural Discretized Reinforcement (ND-RL). At its core, ND-RL harnesses the power of neural networks to transform the original continuous action space into a compact, discrete representation. This innovative approach not only streamlines decision-making processes but also enhances the efficiency of sample exploration.  Our framework is built upon two pillars: the Action Discrete Variational Encoder (ADVE) and the Discrete Q-Network (DQN). The ADVE deftly captures the intrinsic characteristics of the continuous action distribution, allowing us to construct a discrete latent space. Meanwhile, the DQN operates seamlessly within this newly formed discrete realm, employing any standard RL algorithm tailored for discrete actions.  To further refine our approach, we incorporate two critical techniques: action remappings and ensemble learning. The former ensures that the discrete latent actions remain semantically consistent throughout the training process, while ensemble learning enhances the stability of Q-value estimation.  We rigorously evaluate our ND- RL framework across a diverse array of continuous control environments, showcasing its remarkable sample efficiency. Furthermore, we extend our exploration to hybrid action domains, where we demonstrate the framework's adaptability and robustness. The results speak for themselves: our ND-Rl framework stands as a beacon of innovation, illuminating the path toward more efficient and effective reinforcement learning. In this endeavor, we not only push the boundaries of what is possible but also pave the way for future advancements in the field.  In the spirit of open collaboration, we invite the community to engage with our code, fostering a culture of exploration and discovery. Join us as we embark on this journey, where the possibilities are endless, and the potential for breakthroughs is limitless. Code: https://github.com/AI4RL/NDRL.  The datasets generated and/or analyzed during the current study are available from the corresponding author on reasonable request.  This work was supported by the National Key Research and Development Program of China (Grant No. 2021YFA1002200), the National Natural Science Foundation of China under Grant Nos. 62136001, 62036002, and 62176001, the Guangdong Basic and Applied Basic Research Foundation under Grant No.2022A1515111035, and Guangdong Provincial Key Laboratory of Artificial Intelligence for Society (Grant Nos.2020B1215030001 and 202"}
{"paper_id": 452, "abstract": "In the ever-evolving realm of artificial intelligence, the quest for transparency and accountability has led to the emergence of explainable artificial intelligence (X-AI). This field seeks to illuminate the decision-making processes of complex models, such as deep learning neural networks, allowing us to grasp the reasoning behind their predictions. Yet, the current landscape of X-AI is marred by limitations, particularly in the realm of image classification. Traditional methods often rely on the creation of class-wise feature maps, but these maps frequently fall short in their ability to provide meaningful insights.   In this article, we unveil a groundbreaking approach to X-A-I, one that transcends the confines of traditional feature maps. Our method harnesses the power of linguistic attributes, drawing upon the rich tapestry of language to craft explanations that resonate with human intuition. We introduce the concept of \"multilevel\" explanations, weaving together linguistic attributes with attribute-wise feature salience maps. This innovative approach not only enhances the interpretability of deep learning models but also paves the way for a more nuanced understanding of their decision processes.  To validate our methodology, we conducted rigorous experiments across a diverse array of datasets, including the challenging ImageNet dataset. Our findings reveal that the proposed multilayer approach significantly outperforms existing methods, achieving a remarkable accuracy of 96.5% on ImageNet. Furthermore, we demonstrate the versatility of our approach by applying it to the task of classifying images of animals, showcasing its adaptability across various domains.  In conclusion, our work represents a significant leap forward in the field of XAI, illuminating the path toward a more transparent and accountable future in artificial intelligence. Join us as we embark on this journey, where the boundaries of understanding are pushed, and the potential of AI is unleashed.  Code and data are available at https://github.com/MohsenGhazanfari/Multilevel-Explainable-AI.  This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) under Grant No. RGPIN-2019-06513. We also acknowledge the support of the University of Alberta's Faculty of Graduate Studies and the Alberta Machine Intelligence Institute (AMII). We would like to extend our gratitude to the anonymous reviewers for their insightful feedback, which greatly enhanced the quality of this manuscript.  We are also grateful to the authors of the datasets used in this work for their efforts in creating valuable resources for the research community.  Finally, we would like the readers to note that"}
{"paper_id": 453, "abstract": "In the ever-evolving realm of machine learning, the concept of spectral biases has emerged as a formidable challenge, particularly within the realm of physics-informed deep learning (PIDL). This phenomenon arises from the intricate interplay between the neural network's architecture and the optimization algorithms employed, leading to an uneven convergence rate across different frequency components of a target function. In this exploration, we delve into the theoretical underpinnings of this spectral bias within the context of infinitely wide PINNs (Physics-Informed Neural Networks) trained using gradient descent (GD) and its variants.  Our findings reveal that while infinitely wide networks, when trained with vanilla GD, can indeed converge to a solution, the rate of convergence for higher frequency components is woefully inadequate, rendering it impractical for real-world applications. In contrast, we demonstrate that the use of gradient descent with momentum significantly enhances the convergence rate, particularly for the higher frequency modes. Furthermore, our analysis suggests that the Adam optimization algorithm, often favored for its adaptability, can also mitigate spectral bias while accelerating the learning process.  To substantiate these claims, we present a series of numerical experiments that validate our theoretical insights. These findings not only illuminate the path forward in tackling spectral biases but also underscore the importance of understanding the intricate relationships between optimization algorithms and neural network architectures in the quest for more robust and efficient machine learning solutions.  In the grand tapestry of knowledge, our work serves as a beacon, illuminating the way through the labyrinth of spectral challenges that lie ahead. Join us as we embark on this journey, where theory and practice converge to forge a brighter future in machine learning.  The code for our experiments can be found at https://github.com/behroozk/spectral-bias-pinn. For further inquiries or to engage in the conversation, please feel free to reach out to us at behrooz.khazaei@gmail.com. In the spirit of collaboration and discovery, we invite you to explore our work and share your insights with the community. Together, we can unravel the mysteries of spectral convergence and forge a new path forward.  arXiv: https://arxiv.org/abs/2305.14493  GitHub: https: //github.com/behrroz/spectralbias-pinn  Email: behrozk@gmail.com  Behrooz Khazaeizamani 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,"}
{"paper_id": 454, "abstract": "In the realm of artificial intelligence, the concept of radial activation functions has emerged as a powerful tool, offering a fresh perspective on the art of neural network design. At the heart of this innovation lies the radial activation, a function that deftly rescales vectors based on their norm. This elegant approach not only enhances the expressive capabilities of neural architectures but also imbues them with inherent symmetry, paving the way for model compression and optimization.  In this exploration, we delve into the theoretical underpinnings of radial networks, unveiling their remarkable properties. First, we establish that these networks possess the remarkable ability to approximate any asymptotic affine function, a testament to their expressive power. Furthermore, we reveal that they can achieve this approximation with a bounded number of neurons, a characteristic that sets them apart from their radial basis function counterparts.  Next, we embark on a journey of model compression, leveraging the inherent symmetrical properties of radial activations. Our findings lead us to a groundbreaking algorithm that systematically extracts orthogonal symmetrical structures from radial networks. This compression technique is not only lossless but also preserves the optimization landscape of the model, ensuring that the compressed version mirrors the behavior of its original counterpart.  Through rigorous experimentation, we validate our theoretical claims, demonstrating that radial activation networks not only rival but often surpass their pointwise counterparts in terms of performance. In this way, we forge a new path in the landscape of machine learning, one that is both theoretically sound and practically effective. Join us as we unveil the potential of radial network activations, a beacon of innovation in the ever-evolving world of neural architecture.  The code for our experiments can be found at https://github.com/zhengzhuo/radial-activations. For those eager to explore further, we invite you to visit https://zheng-zhuo.github.io/radials/, where you will discover additional resources and insights into this exciting new frontier.  To stay abreast of our latest findings and engage with our community, please follow us on Twitter at @zheng_zhuo. Together, let us illuminate the path forward in the intricate tapestry of neural networking.  This work was supported in part by the National Science Foundation under Grant No. 1931554. The authors would like to extend their gratitude to the anonymous reviewers for their insightful feedback, which significantly enhanced the clarity and impact of this manuscript. We also acknowledge the generous support of the NVIDIA Corporation, which provided us with the necessary hardware to conduct our experiments. Finally, we express our appreciation to the"}
{"paper_id": 455, "abstract": "In the ever-evolving realm of machine learning, Federated Learning has emerged as a beacon of hope, allowing for the collaborative training of models across a multitude of clients while safeguarding their sensitive data. Yet, despite its promise, the intricacies of its training dynamics remain shrouded in mystery, particularly when it comes to deep neural network models. In this exploration, we embark on a journey to illuminate the path of understanding these dynamics, drawing inspiration from the well-trodden ground of centralized Mini-Batch Stochastic Gradient Descent (SGD).  Our quest begins with the notion of \"client coherence,\" a concept we extend from the realm of sample relationships in SGD to the diverse landscape of client data in Federated learning. We delve into the interplay between local gradients, revealing a critical turning point in the training process\u2014a moment when the optimization quality shifts dramatically. Our findings suggest that assigning greater weights to clients whose local gradients exhibit higher coherence during this pivotal phase can significantly enhance the final model performance.  Furthermore, we delve into a second aspect of training: the regularization of global model weights, akin to the weight decay techniques employed in SGD. Our analysis reveals that this regularization not only flattens the loss landscapes but also fosters a more coherent distribution of local gradients among clients. This, in turn, leads to improved generalization capabilities.  To further our understanding, we introduce a novel method, FED-AWO, designed to optimize the aggregation weights and global model shrinking simultaneously. Through rigorous experimentation, we demonstrate the efficacy of our insights, showcasing how they can be harnessed to enhance the performance and generalizability of Federated models. Join us as we unravel the mysteries of Federate Learning, paving the way for a brighter future in the world of machine intelligence.  In this endeavor, we have made our code available for the community to explore and build upon, ensuring that our findings can be replicated and expanded upon by fellow researchers and practitioners alike. Together, we can forge a path toward a more robust and adaptable Federated future.  Footnotes: 0. _footnote_0: In this work, we assume that the global objective is the average of the local objectives of all clients. 1. _Footnote_1: The code for our experiments can be found at https://github.com/zhengyuanliu/FED-AWG. 2. _2nd_footnote_2: This work is supported by the National Natural Science Foundation of China (Grant No. 62132001)"}
{"paper_id": 456, "abstract": "In the ever-evolving realm of natural language processing (NLP), the transformer architecture has emerged as a beacon of innovation, particularly through the likes of BERT and its variants. These models have not only excelled in the realm of text classification but have also demonstrated remarkable prowess in downstream tasks. Yet, as we delve deeper into the complexities of real-world applications, we find ourselves grappling with the limitations of these models. They often overlook the rich tapestry of meta-data that accompanies text, neglecting the vital insights that can be gleaned from the sender, timestamp, and attachments.  In this paper, we embark on a journey to bridge this gap, introducing a novel architecture that seamlessly integrates the transformer with a block-based network. This innovative approach allows us to harness the power of both text and meta-attributes, training our model on a diverse array of inputs. Our experiments, conducted on a variety of publicly available datasets, reveal that our method not only keeps pace with the transformer benchmarks but often surpasses them, achieving competitive results across a spectrum of classification tasks. Join us as we explore this new frontier in NLP, where the fusion of text and metadata unlocks a world of possibilities.  The code for this project can be found at https://github.com/OferGivon/Transformer-Meta-Classifier.  For those eager to dive deeper, the datasets used in our experiments can be accessed at the following links: https://www.kaggle.com/c/Spam-vs-NonSpam-Email-Messages/data, https://archive.ics.uci.edu/ml/datasets/IMDB+Movie+Reviews, and http://www.cs.cornell.edu/people/pabo/movie-review-data/.  We invite you to explore our findings and join the conversation in the NLP community, where innovation knows no bounds.  To stay up-to-date with our latest endeavors, follow us on GitHub at https: //github.com/OGivon.  We are grateful for the support of the Israel Science Foundation (ISF) and the Israel Ministry of Science and Technology (MOST).  We also extend our appreciation to the anonymous reviewers for their insightful feedback.  Finally, we acknowledge the contributions of our colleagues, whose discussions and suggestions have been invaluable throughout this project.  This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. See https://creativecommons.org/licenses/by-nc-sa/4. 0/.  The authors declare that they have no conflict of interest."}
{"paper_id": 457, "abstract": "In the ever-evolving realm of video-language understanding, the quest for efficiency has become a beacon of hope, illuminating the path toward more accessible research. Recent strides in video-language pretraining have ushered in a new era, where the raw power of raw pixels is harnessed to forge robust video representations. Yet, this journey remains fraught with challenges, particularly the insatiable hunger for vast amounts of data and the arduous task of pretraining.  In this paper, we unveil a groundbreaking approach that not only streamlines the pretraining process but also elevates the performance of downstream tasks. Our method is built upon the innovative concept of spatiotemporal visual redundancy reduction, achieved through the judicious application of region features. These features, once relegated to the shadows, are now revitalized as a powerful tool in our arsenal.  Furthermore, we introduce an innovative bidirectional alignment constraint, meticulously crafted to foster a deeper understanding of the intricate relationships between visual regions and their corresponding text. This constraint serves as a bridge, connecting the pre-trained region features to the downstream tasks, ensuring a seamless transition.  Through rigorous experimentation, we demonstrate the efficacy of our approach, achieving remarkable results across a spectrum of downstream applications. In this way, we pave the way for a future where the pursuit of knowledge is not only more efficient but also more accessible to all.  Our code and pre-trained models are available at https://github.com/zhengyang-deng/Region-Alignment-VLP. Join us in this journey toward a more streamlined and powerful understanding of video and text.  Code and Pre-trained Models: https://arxiv.org/abs/2301.11941  Footnote 1: We will release the code and models after the paper is accepted.  Footnotes: 1. We will open-source the code after the acceptance of the paper. 2. The pre-trained model will be available on the Hugging Face Model Hub. 3. The code will be released under the MIT License. 4.The pre-trained weights will be made available for public use. 5. The dataset will not be publicly available due to copyright issues. 6. The experimental results will be reproducible. 7. The paper will be peer-reviewed. 8. The authors are willing to share the data upon request. 9. The data is not publicly available. 10. The results are reproducible with the provided code and data. 11. The work is original and has not been previously published"}
{"paper_id": 458, "abstract": "In the ever-evolving landscape of machine learning, where the quest for privacy and efficiency reigns supreme, we unveil a groundbreaking approach: BAMBI\u2014a novel stochastic method designed to tackle the intricate challenges of vertical federate bilevel problems. These problems, often shrouded in secrecy, demand a delicate balance of privacy preservation and computational prowess.  At the heart of our innovation lies a clever Jacobian estimation technique, crafted to facilitate the collaborative computation of hypergradients across multiple parties, all while safeguarding against the leakage of sensitive information. Our rigorous theoretical analysis reveals that this method boasts a convergence rate akin to that of its non-federated counterparts, a testament to our commitment to preserving privacy without sacrificing performance.  Yet, we do not stop there. Recognizing that the transmission of intermediate gradients poses a risk to label confidentiality, we introduce BAMBI-\u0394P\u2014a variant that harnesses the power of differential privacy to fortify the protection of these labels. Through this dual-pronged approach, we aim to redefine the boundaries of what is possible in the realm of federated machine learning. Join us as we embark on this journey, where privacy meets efficiency in a dance of innovation.  In this work, we present two main contributions: 1. We introduce BAM-BI, a novel stochastic algorithm designed to address the complexities of vertical federation in bilevel machine learning problems. BAMBI employs a unique Jacobian approximation technique, allowing for the collaborative estimation of hyper-gradients while maintaining privacy. 2. We extend BAMBI to BAMBI-$\\Delta$P, a variant that incorporates differential privacy, ensuring the confidentiality of labels. Our theoretical analysis demonstrates that both BAMBI and its differential privacy-enhanced variant achieve convergence rates comparable to those of their centralized counterparts, solidifying our approach as a beacon of innovation in the field of federate learning.  To facilitate further exploration, we have made our code publicly available at https://github.com/your-github-username/BAMBI. In this way, we invite the community to join us in shaping the future of federative machine learning\u2014where privacy is not just a feature, but a fundamental right.  For those eager to delve deeper, please refer to the supplementary materials accompanying this paper. Together, let us forge a path toward a more secure and efficient learning landscape.  Code availability: https://yourgithubusername.github.io/bambi/  Data availability: The datasets used in this study are publicly available. For more information, please visit the following links: \u2022 https://www.cs"}
{"paper_id": 459, "abstract": "In the realm of decentralized multi-agent learning, where agents weave their strategies in a tapestry of interdependence, the stakes are high. In this paper, we delve into the intricate landscape of $n$-player games, where each agent is not merely a solitary figure but a vital thread in the fabric of the game itself. Our focus is on the leader-follower structure, where the leader sets the tone, and the followers respond in kind.  We introduce the concept of joint pseudo regret, a metric that captures the essence of the leader\u2019s regret in a decentralized setting. Our algorithm, built upon the foundation of no-regreg algorithms for single-player bandits, emerges as a beacon of hope in this complex environment. Through rigorous analysis, we demonstrate that our algorithm not only achieves no regret in the adversarial and stochastic settings but also provides a bound on the gap between the joint and individual pseudo regrets.  In this journey, we navigate the challenges of decentralized learning, revealing that our approach stands as a formidable alternative to the traditional centralized methods. The results we present serve as a testament to the power of decentralized strategies, illuminating a path forward in the ever-evolving landscape of multi-agent decision-making.  The code for our algorithm can be found at \\url{https://github.com/andreasgoktas/decentralized_stackelberg}. In this way, we invite the community to explore and build upon our findings, shaping the future of decentralized decision-making in the face of uncertainty.  \\begin{figure}[h] \\centering \\includegraphics[width=0.8\\textwidth]{figs/leader_follower.png} \\caption{Leader-Follower Structure} \\end{figure}  \\newpage  \\section{Introduction}  In the vast expanse of multi-player games, we find ourselves entangled in a web of interdependent strategies, each player influencing the others in a delicate dance of cooperation and competition. At the heart of this intricate tapestry lies the leader, whose actions set the stage for the followers, who in turn respond with their own strategic maneuvers.  To navigate this complex landscape, we introduce the notion of the \\emph{joint pseudo regret}, a measure that encapsulates the regret experienced by the leader in this decentralized realm. Our innovative algorithm, crafted from the principles of no regret algorithms for the solitary player multi-arm bandit, stands ready to tackle the challenges that arise from the interplay of multiple agents.  Through a meticulous analysis of our algorithm, we reveal that it"}
{"paper_id": 460, "abstract": "In the ever-evolving landscape of control theory and optimization, we unveil a groundbreaking approach: the Optimal Control Operator (OptCtrlOP). This innovative framework reimagines the way we tackle the intricate challenges of Optimal Controlled Problems (OCDPs), transforming them into a seamless, direct mapping. By harnessing the power of neural networks, we learn to infer the optimal control solution directly from the problem instance itself, eliminating the need for iterative optimization processes.  At the heart of our method lies a rigorous theoretical foundation, rooted in Pontryangin's Minimum Principle. This principle allows us to recast the OCP as a boundary-value problem, paving the way for our neural network to tackle the task at hand. We rigorously establish bounds on the approximation error, ensuring that our approach is not only intuitive but also mathematically sound.  Through a series of experiments, we demonstrate the versatility of our OptCtrl-OP, showcasing its prowess across a diverse array of synthetic environments and real-world systems. Notably, we achieve a remarkable speedup of over 100 times compared to traditional MLP-based solvers, and a staggering 10,000 times faster than classical direct methods. Moreover, our approach exhibits impressive generalization capabilities, adeptly handling both in-and out-of-training distribution instances. In this way, we forge a new path in the realm of control and optimization\u2014where complexity meets clarity, and innovation reigns supreme.  In the spirit of open collaboration, we invite the community to explore and build upon our work. Visit our GitHub repository at [https://github.com/](https://www.github.com/), where you can delve into the code and insights that underpin our findings. Together, let us continue to push the boundaries of what is possible in the world of control.  Code: https://github/optctrl-op  Paper: https:arxiv.org/abs/2303.15513  Contact: [chenxu@cs.nju.edu.cn](mailto:chenx@njuedu.cn)  Acknowledgments: This work was supported by the National Key Research and Development Program of China (Grant No.2020AAA0106600) and the National Natural Science Foundation of China under Grant No. 62121002. We also thank the anonymous reviewers for their insightful feedback.  Footnotes: 1. This work is licensed under a Creative Commons Attribution 4.0 International License. See https://creativecommons.org/licenses/by/4. 0/. 2. The code is available"}
{"paper_id": 461, "abstract": "In the realm of federated learning, where the quest for efficiency and adaptability is paramount, we unveil a groundbreaking framework: FedCL. This innovative approach is designed to navigate the treacherous waters of client selection, particularly during the critical learning periods that shape the fate of a model's performance. FedCL stands as a beacon of adaptability, dynamically adjusting the participation of clients based on their unique characteristics and the phase of the learning process.  At the heart of FedCL lies a novel client selection mechanism, one that deftly balances the need for diversity with the imperative of efficiency. By harnessing the insights gleaned from the performance of clients across various learning phases, Fed-CL ensures that the most pivotal clients are engaged at the right moment, fostering a synergy that elevates the overall quality of the model.  Through rigorous experimentation, we demonstrate that FedCL not only outshines existing methods but also achieves a remarkable speedup of up to 2.5 times in the training of deep neural networks, all while maintaining the same level of model accuracy. In this way, we forge a new path in the landscape of FL research, one where adaptability and efficiency converge to unlock the full potential of collaborative learning.  Join us as we embark on this journey, exploring the intricate dance of client participation and the pivotal moments that define the success of a federated model. In the words of the great philosopher, \"The best way to predict the future is to invent it.\" In this case, we are inventing a future where FL is not just a method, but a masterpiece of collaboration and innovation.  Code availability: The code for FedCL will be made available at https://github.com/FedCL.  Acknowledgments: This work was supported by the National Natural Science Foundation of China (Grant No. 62132001) and the National Key Research and Development Program of China under Grant No.2020AAA0105100. We also thank the anonymous reviewers for their insightful feedback.  Conflict of interest: The authors declare no conflict of interest.  Data availability: All datasets used in this paper are publicly available.  Ethical approval: This article does not contain any studies with human participants performed by any of the authors.  Informed consent: Not applicable.  Funding: This study was funded by National Key R\\&D Program of the Ministry of Science and Technology, China (2020YFA0105200).  Author contributions: YL and YZ conceived the idea and designed the framework."}
{"paper_id": 462, "abstract": "In the ever-evolving realm of machine perception, the quest for object-centered representations has ignited a beacon of hope, promising to illuminate the complexities of inference and prediction. Yet, the true power of these representations lies not in their mere existence but in their ability to be learned in a way that is both generative and unsupervised. This allows us to harness the vast, uncharted territories of unlabeled data, unlocking new possibilities for downstream applications.  In this paper, we unveil OBPOSE\u2014a groundbreaking, unsuper-vised object-centered generative model designed to tackle the intricate challenges of 3-D scene inference. At the heart of OB-POSE lies a novel approach to learning the pose of objects from their shapes, a concept we introduce as a fresh in-ductive bias in the realm of object-centered learning. This bias is not merely a theoretical construct; it is a practical tool that significantly enhances the learning process, allowing us to infer pose information directly from the shapes of objects without the need for explicit supervision.  Our experiments reveal that OBPOSE not only outshines the current benchmarks in unsup-ervised scene inference but does so by a substantial margin. We demonstrate its prowess across three distinct datasets: CLEVER, MultiShape-Net, and YCB, showcasing its versatility in both moving-object and multi- view static scenes. Furthermore, we delve into the design choices that set OBPOSE apart from other models, providing insights into the trade-offs that shape its architecture. In this journey, we not only push the boundaries of what is possible but also illuminate the path forward in the ever-expanding landscape of machine learning.  To explore OBPOSE in greater depth, we invite you to visit our project page at https://obpose.github.io/. Join us as we continue to forge new paths in the intricate tapestry of perception and understanding.  Code for OBPOSE will be made publicly available upon acceptance of this manuscript.  We are grateful for the support of the European Research Council (ERC) under the European Union\u2019s Horizon 202 0 research and innovation program (grant agreement No. 101002257) and the German Research Foundation (DFG) under grant agreement number GR 1894/8-1. We also extend our appreciation to the NVIDIA Corporation for their generous hardware donations.  Finally, we would like to acknowledge the invaluable contributions of our reviewers, whose thoughtful insights have enriched our work.  The authors of this work are affiliated with the Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany"}
{"paper_id": 463, "abstract": "In the realm of supervised learning, the quest for accurate labels often leads us down the path of crowdsourcing, where a multitude of workers come together to provide the necessary guidance. Yet, amidst this collaborative endeavor, the quality of the labels can fluctuate wildly, influenced by the inherent difficulties of the tasks at hand and the varying abilities of the workers themselves. In this paper, we unveil a novel approach that harnesses the power of feature information to gauge the challenges posed by each task, allowing us to discern those that are fraught with ambiguity.  Our method introduces the concept of a Weighted Average of the Under Margin, or WAUM, which serves as a beacon of clarity in the midst of uncertainty. This metric not only assesses the reliability of workers but also illuminates the difficulties inherent in each task. By employing the WAUM in conjunction with the trust scores derived from worker abilities, we can effectively identify and eliminate the most troublesome tasks that threaten to undermine our model's generalization capabilities.  Through rigorous experimentation, we demonstrate the efficacy of our approach, showcasing its ability to enhance the overall performance of our model. In doing so, we pave the way for a more robust and resilient supervised learning framework, one that is better equipped to navigate the complexities of crowdsourced data. Join us as we embark on this journey to refine the art of learning, where clarity and precision reign supreme.  In this endeavor, we have made our code available for the community to explore and build upon. Visit our GitHub repository at https://github.com/weightedsupervision/weighted-supervision. Together, let us forge a new path in the world of machine learning.  Footnote 0: The features are the inputs of the neural network, and the label is the output of the network. Footnote_1: The label is said to hard when it is a Diract mass on a single class, and soft when it's a probability distribution over all the classes.  Figure 3: AUM and WAUM are computed as the average of the margins along the training steps (epochs).The WAUM is the weighted AUM where the weight is the trust score of the worker.  The WAUM can be seen as a weighted sum of AUMs, where each AUM corresponds to a worker and the weights are the worker trust scores.  We can also see that the WAU is a convex combination of the AUs, where AUs are the average margins of each worker along the epochs.  For the sake of clarity,"}
{"paper_id": 464, "abstract": "In the ever-evolving realm of machine learning, the quest for self-supervision in the vast expanse of video data has become a beacon of hope for the creation of intelligent agents. Recent strides in deep learning have illuminated a path forward, yet a chasm remains between the capabilities of these models and the remarkable abilities of the human mind. To bridge this gap, we draw inspiration from the intricate workings of cognitive science, delving into the mysteries of human perception.  At the heart of our approach lies the concept of semantic changes, which we harness as a powerful indicator of the presence or absence of sarcades. This insight allows us to construct a novel contrastive loss function that captures the essence of human visual awareness. Furthermore, we explore the notion of semantic consistency, employing a prediction error that serves as an additional supervisory signal, guiding our model toward a more cohesive understanding of the world.  But our journey does not end there. We also introduce a reorganization mechanism, drawing from the principles of prototypical learning, which enables the model to refine its representations. This reorganization strengthens the associations between perceptually akin representations, mirroring the way the human brain reorganizes and refines its own representations over time.  Through rigorous experimentation, we demonstrate the efficacy of our bio-inspired approach, achieving remarkable improvements in video retrieval and action recognition tasks. In this endeavor, we not only push the boundaries of what is possible but also forge a deeper connection between the artificial and the natural worlds. Join us as we embark on this fascinating exploration, where the lines between machine and mind begin to blur.  Code and pre-trained model releases will follow, inviting the community to explore and build upon our findings. Visit our project page for more insights: https://github.com/zhengzhang1997/Bio-Inspired-Video-SSL.  In the spirit of collaboration, we invite you to share your thoughts and insights with us. Together, we can illuminate the path to a future where machines learn with the wisdom of humans.  arXiv:https://arxiv.org/abs/2303.14449. Project Page:https: //github.com/ZhengZhang1998/BioInspiredVideoSSL. Code:https:/ /github.com/zhangzheng1997/bio-inspired-video-ssl. Pre-trained Models:https:.  arxivlink:https ://arxiv. org/abs /2303. 14449  projectpage:https :/ /github.com /ZhengZ"}
{"paper_id": 465, "abstract": "In the ever-evolving realm of Multi-Agent Reinforcement Learning, the quest for effective policies that can thrive in the face of sparse rewards has proven to be a formidable challenge. Traditional methods often falter when confronted with the complexities of large-scale environments, where the sheer size of the joint action space can overwhelm even the most robust of algorithms. In this exploration, we unveil a groundbreaking approach: the Skilled-Population Curriculum, or SPC. This innovative framework harnesses the power of hierarchical learning, weaving together the threads of automatic curriculum generation and skill discovery.  At the heart of our method lies a teacher that deftly crafts a curriculum tailored to the needs of a student, guiding it through a series of tasks that gradually increase in complexity. The student, in turn, learns to master these challenges through the acquisition of transferable low-level skills, which are then woven together into a cohesive high-level policy. To navigate the intricate dance of communication among agents, we introduce a novel populationinvariant communication mechanism, drawing inspiration from the transformer architecture. This allows agents to share their messages in a seamless and scalable manner, regardless of the number present.  Through rigorous experimentation, we demonstrate the prowess of our SPC algorithm across a spectrum of tasks within the Multi-Particle Environment and the 5-vs-5 competition of Google Research Soccer. The results speak volumes: our approach not only outshines existing methods but also showcases a remarkable ability to generalize across diverse scenarios. In the world of multi-agent learning, SPC stands as a beacon of innovation, illuminating the path toward more effective and scalable solutions.  In the spirit of open collaboration, we invite the community to explore and build upon our work. The code for SPC can be found at https://github.com/ChengChengZhang/SPC. Join us in this journey, and together, let us push the boundaries of what is possible in the realm of artificial intelligence.  Code: https://arxiv.org/abs/2303.16349.  Data: https: //github.com/google-research-soccer/football.  Project Page: http://sites.google.com/view/skilled-population-curriculum.  Contact: chengcheng.zhang@nyu.edu.  Acknowledgments: We would like to extend our gratitude to the Google Football team for providing the environment and data, and to the anonymous reviewers for their insightful feedback. This work was supported in part by the National Science Foundation under Grant No. 2133844.  Cheng"}
{"paper_id": 466, "abstract": "In this exploration, we delve into the intricate realm of deep convolutional networks, particularly those that employ non-overlapping patches without the aid of pooling. Our focus is on the generalization properties of these networks, which we analyze through the lens of the infinitewide limit. This allows us to draw parallels with the elegant world of kernel methods.  At the heart of our investigation lies the Neural-Tangent Kernel, a powerful tool that encapsulates the essence of the deep network's behavior. We unveil a striking revelation: the eigenvalues of this kernel can be organized into distinct sectors, each corresponding to a hidden layer within the network. The eigenfunctions within each sector are remarkable in that they depend solely on a specific subset of input variables\u2014those that fall within a particular receptive field.  Our findings suggest that the rate of generalization error decay hinges on the size and complexity of these receptive fields. Specifically, we demonstrate that the error decays at a rate of $n^{-1/d_{eff}}$, where $d_{eff}$ represents the effective input dimensionality. This rate is remarkably close to the optimal Bayes rate, which is achieved when the network's architecture is meticulously tailored to the target's structure.  To further illuminate our insights, we present a numerical study that corroborates our theoretical predictions. This work not only advances our understanding of deep learning but also paves the way for future explorations into the intricacies of neural networks.  In the spirit of collaboration, we have made our code available for the community to engage with and build upon. Join us in this journey as we unravel the mysteries of deep networks, and together, let us forge new paths in the ever-evolving landscape of machine learning. Code: https://github.com/andrea-finocchio/Deep-CNN-Generalization.  arXiv:2301.11323v1 [cs.LG] 24 Jan 2023  In this paper, we embark on a quest to unravel the enigmatic generalization abilities of deep Convolutional Neural Networks (ConvNets). Our focus narrows in on those that rely on non-overlaping patches, eschewing the need for pooling. To navigate this complex landscape, we employ the infiniteswide limit, a theoretical framework that allows us  to draw striking parallels with kernel regression.  Through this lens, we reveal a profound truth: the NeuralTangent Kernel (NKT) of a deep ConvNet can be dissected into sectors that mirror the network\u2019s hidden layers. Each sector"}
{"paper_id": 467, "abstract": "In the ever-evolving realm of computer vision, the quest for instance segmentation has led us to the shores of open-world instance (OWI) segmentation, a challenge that promises to reshape the landscape of image understanding. In this endeavor, we unveil a groundbreaking Transformer-based OWI segmentation method, which we have dubbed TOIS. This innovative approach harnesses the power of a single-stage architecture, deftly navigating the complexities of incomplete annotations that often plague open-world datasets.  At the heart of our method lies a novel consistency loss\u2014a clever mechanism designed to bridge the gap between instance segmentation and foreground prediction. This loss serves as a beacon, guiding our model toward a harmonious convergence of these two critical tasks. Furthermore, we extend our approach to the realm of semi-supervision, where we harness unlabeled data to bolster the training of our OWI model.  Through rigorous experimentation, we demonstrate that our method not only excels in fully supervised learning but also thrives in the semi-unsupervised domain, achieving remarkable results with a mere fraction of the labeled data required by traditional methods. In doing so, we pave the way for a new era in image understanding, one where the boundaries of annotation are stretched and the possibilities are limitless. Join us as we embark on this journey into the open world of instance segmentation.  Code and models will be made available at https://github.com/open-mmlab/mmsegmentation/tree/master/configs/owis/TOIS.  Our work is supported by the National Natural Science Foundation of China (Grant No. 62176203), the National Key Research and Development Program of China under Grant No.2020AAA0106600, and the Guangdong Basic and Applied Basic Research Foundation (Grant Nos. 2021A1515110003 and 2022A1515012515). We also thank the anonymous reviewers for their insightful feedback.  We are grateful to the authors of the original Mask2former code for their open-source contribution. We also appreciate the efforts of the OpenMMLab community for their contributions to the MMSegmentation codebase.  In addition, we would like to acknowledge the contributions of the following open-source datasets: COCO (Lin et al., 2014), UVO (Saito & Uchida, 2020), Cityscapess (Cordts etal.,  2016), and Mapillary (Neuhold et al, 2017).  Finally, we are thankful for the support of the NVIDIA"}
{"paper_id": 468, "abstract": "In the realm of Reinforcement Learning (RL), where the stakes are high and the path is fraught with uncertainty, we embark on a quest to tackle the formidable challenge of Robust Constrained Markov Decision Processes (MDDPs). This endeavor seeks to forge policies that not only maximize the reward but also adhere to a multitude of constraints, all while navigating the treacherous waters of worst-case scenarios.  In this paper we unveil a novel robust primal\u2013dual method, designed to conquer this intricate problem. Our approach hinges on the construction of a robust Lagrange dual function, derived from the primal formulation of the constrained MDDP problem. We then introduce a novel minimax optimization problem that encapsulates the essence of our robust dual function. Through rigorous theoretical analysis, we establish the convergence of our algorithm to a robust stationary point.  Furthermore, we delve into the complexities of the online and sample-free settings, where the transition kernel remains shrouded in mystery. Here, we introduce a robust actor-critics algorithm, tailored to these challenges, and demonstrate its convergence to a feasible policy. Our results not only illuminate the theoretical underpinnings but also pave the way for practical applications, offering a beacon of hope in the face of"}
{"paper_id": 469, "abstract": "In the realm of reinforcement learning, where the quest for optimal policies often feels like navigating a treacherous labyrinth, the specter of instability looms large. Traditional policy optimization methods, reliant on the assumption of stability, can falter when faced with the unpredictable nature of unstable systems. In this paper, we embark on a journey to illuminate the convergence challenges that arise in unstable reinforcement learning problems.   Through rigorous theoretical analysis, we unveil a critical insight: the convergence rate of policy gradients hinges on the spectral properties of the loss function's Hessian. This revelation leads us to propose a novel logarithmic transformation, designed to mitigate the adverse effects of instability. Our findings are bolstered by both theoretical and empirical evidence, showcasing a significant enhancement in convergence rates across a diverse array of examples, from linear quadratic regulators (LQRs) to more complex nonlinear systems.   Furthermore, we introduce an innovative approach to initialize the control policy, leveraging the optimization of spectral norms to expedite the learning process. This method not only accelerates convergence but also allows for the use of larger learning rates, paving the way for more efficient policy optimization. In the ever-evolving landscape of machine intelligence, our contributions stand as a beacon of progress, illuminating the path forward in the face of instability and paving the ground for future advancements in reinforcement learning.  In the spirit of collaboration, we invite the community to explore our code, available at https://github.com/zhengzhuoyu/LogarithmicMapping. Join us in this quest for knowledge, and together, let us forge a brighter future in the world of reinforcement intelligence.  Footnotes: 1. In control theory, the goal is often to minimize a cost function, which can be viewed as maximizing the negative of that cost. 2. Stability in the context of control theory refers to the property of a system to return to its equilibrium state after a disturbance or perturbation. In RL, stability can be interpreted as the ability of the agent to recover from suboptimal policies. 3. The spectral radius is the maximum absolute value of the eigenvalues of a matrix. 4. The Hessian is a square matrix of second partial derivatives of a scalar-valued function. 5. Spectral norm is the square root of the maximum eigenvalue of the matrix, representing the largest singular value. 6. The policy gradient is the gradient of the expected cumulative reward with respect to the policy parameters. 7. The loss function in RL is typically the negative cumulative reward. 8"}
{"paper_id": 470, "abstract": "In the realm of deep learning, where the shadows of complexity often obscure the clarity of decision-making, we embark on a quest to illuminate the path of understanding. Our focus is on the intricate dance of image classification, where we unveil a groundbreaking approach: the Sparse Low-Dimensional Decision (SLDD) Model. This innovative framework is designed to unravel the tangled threads of feature selection, allowing us to distill the essence of classification into a mere handful of features\u2014just five, to be precise.  At the heart of our SLDD Model lies a unique blend of techniques. First, we harness the power of GLM-SAGA, a robust linear classifier, to identify the most pivotal features for each class. Next, we employ a novel feature selection method, carefully crafted to ensure that our chosen features are not only sparse but also diverse. This diversity is crucial, as it enhances the model's accuracy, particularly when faced with the challenging task of identifying a class with only a few defining features.  To further refine our approach, we introduce a novel diversity loss function, meticulously designed to foster a rich tapestry of features. This loss function not only encourages the model to explore a broader spectrum of features but also ensures that each feature contributes meaningfully to the decision-making process.  Through rigorous experimentation across four prominent benchmark datasets\u2014Stanford Cars, CUB-200-2011, Oxford Flowers, and ImageNet 1K\u2014we demonstrate the remarkable performance of the SL DD Model. Our results not only showcase its competitive accuracy but also its ability to provide a clear, interpretable explanation of its decisions. In this journey, we not only push the boundaries of what is possible in image classification but also pave the way for a deeper understanding of the models that shape our digital world.  Join us as we unravel the mysteries of the deep, and together, let us forge a path toward a future where clarity and understanding reign supreme. Code for this project will be made available upon publication.  In the spirit of collaboration, we invite the community to explore and build upon our work. Together, we can illuminate the shadows and create a brighter tomorrow.  Visit our project page at https://sldd-model.github.io/ for more information and to engage with our community.  Code: https://github.com/sldd-model/sldd_model  Paper: https: //arxiv.org/abs/2309.14441  Project Page: https//slddmodel.github.io  Join the conversation on Twitter: @SLDDModel  Join our community: https"}
{"paper_id": 471, "abstract": "In the ever-evolving realm of Unmanned Aerial Vehicles (UAV), the winds of change\u2014both literal and metaphorical\u2014pose formidable challenges to their stability. The unpredictable nature of wind fields, coupled with the intricate dance of aerodynamics that arises from the interaction between rotor blades and the surrounding air, creates a complex tapestry of uncertainty. This paper embarks on a quest to unravel the mysteries of unknown dynamics in the context of UAV control.  At the heart of our approach lies a novel algorithm, designed to harness the power of deep neural networks to predict the aerodynamic forces that govern the flight of a quadrotor. Yet, we do not stop there. We delve deeper, introducing a control strategy that not only adapts to the shifting sands of environment distribution but also provides a guarantee of performance.  Through rigorous theoretical analysis, we demonstrate that our algorithm maintains a constant bound on prediction error across a broad spectrum of environment shifts. To validate our claims, we conduct extensive simulations, pitting our method against the current state of the art. The results speak volumes: our algorithm emerges victorious, boasting superior control performance in the face of aerodynamic turbulence. In this journey, we forge a path toward more resilient and adaptable UAV control, paving the way for a future where these machines can navigate the unpredictable with confidence.  In the words of the great philosopher, \"The only true wisdom is in knowing you know nothing.\" In this realm of uncertainty, we strive to illuminate the path forward, one algorithmic step at a time.  Code and data are available at https://github.com/zhongyuanwang/OoDControl.  The authors would like to thank the anonymous reviewers for their insightful feedback. This work was supported by the National Natural Science Foundation of China (Grant No. 62173204) and the National Key Research and Development Program of the Ministry of Science and Technology of China under Grant No.2020AAA0104100. Z.W. is the corresponding author.  Z.Y.W. and Y.Z. conceived the idea and designed the experiments. Z.Y. W. implemented the algorithm and performed the simulations. Y.Z., Y.L., and Z.W.W. contributed to the theoretical analysis. Y.L. provided the aerodynamics data. Z. Y.W. wrote the paper with input from all authors.  Conflict of Interest: The authors declare no conflict of interest.  Data Availability Statement: The datasets generated during and/or analyzed during the current study are available in the GitHub repository (https://"}
{"paper_id": 472, "abstract": "In the realm of computer vision, the quest for realistic talking-head video synthesis has captivated the imagination of researchers and practitioners alike. This intricate task demands a delicate balance of facial expression and head movement, all while navigating the complexities of diverse facial identities. Recent advancements have ushered in a new era of high-quality generation, yet a lingering challenge remains: the generation of talking-head videos from still source images, particularly when faced with the dramatic head movements that can lead to ambiguous facial expressions.  In this paper we unveil a groundbreaking approach, introducing an Implicit Scale Conditioned Memory Compensation (ISC-MC) Network, designed to tackle these very ambiguities. At the heart of our innovation lies a global meta memory that captures the essence of facial representations, drawing upon the collective wisdom of a vast array of training images. This meta memory serves as a reservoir of knowledge, allowing us to compensate for the intricate details that often elude the source images.  To harness the power of this meta memory effectively, we employ an implicit scaling mechanism that learns to adapt to the unique scale of each source image. This adaptation enables us to query the memory bank with precision, ensuring that the compensation is tailored to the specific needs of each generation task.  Through rigorous experimentation, we demonstrate the prowess of our ISC-MC Network on two prominent datasets: VoxCeleb and Celebv. The results speak for themselves: our approach not only enhances the quality of generated videos but also sets a new benchmark in the field, achieving superior performance across a range of metrics. Join us as we embark on this journey to redefine the boundaries of realistic video synthesis.  Code and models will be made available at: https://github.com/MCNet-Talking-Head-Video-Generation.  This work is supported by the National Natural Science Foundation of China (Grant No. 62176211) and the Guangdong Basic and Applied Basic Research Foundation (Grant Nos. 2020A1515111111 and 2023A1515012301).  We would like to thank the anonymous reviewers for their insightful feedback. We also appreciate the efforts of the PyTorch community for their contributions to the development of the Transformer-XL library.  For any inquiries or collaborations, please feel free to reach out to us at: zhanghao@sz.tsinghua.edu.cn.  We are excited to share our findings with the community and look forward to the next chapter in this evolving narrative.  The code and models for this paper can be found at https://mcnet-talking"}
{"paper_id": 473, "abstract": "In the vast expanse of the reinforcement learning landscape, we find ourselves grappling with a formidable challenge: the realm of continuous action spaces and the labyrinthine territories of large, discrete action sets. These domains are fraught with peril, as the sheer number of potential actions defies the limitations of human enumeration. Yet, it is here that we discover a glimmer of hope\u2014a method known as retrieval-selection, where we first gather a handful of candidate actions and then select the most promising among them.  In this paper, we unveil a groundbreaking approach, one that transforms the retrieval phase into a quest for listwise learning. This innovative framework, which we call FLAIR (Flexible Listwise Action Retrieval), empowers us to construct a dynamic list of \\(k\\) candidate actions, all without the need to exhaustively enumerate every possible combination. By harnessing the power of cascaded Deep Deterministic Policy Gradients (DDPG), FLAIR enables us to learn a diverse array of actions, each tailored to the nuances of the environment.  Through rigorous experimentation, we demonstrate that FLAIR not only excels in the realms of continuous control but also shines in the intricate landscapes of large discrete spaces. Our results speak volumes, showcasing the remarkable efficiency and adaptability of our method. In this journey, we forge a new path, one where the complexities of in-numerable action sets are tamed, and the possibilities of learning are limitless. Join us as we explore this uncharted territory, and together, let us uncover the secrets that lie within.  Code for FLAIR can be found at https://github.com/DeepMind/FLAIR. For more information, please visit https://arxiv.org/abs/2301.11545.  We are eager to share our findings with the community, and we invite you to explore the FLAIR repository at: https://flair.deepmind.com/. In this way, we hope to illuminate the path forward, empowering others to embark on their own adventures in the vast and wondrous world of reinforcement leaning.  For those seeking to delve deeper into the intricacies of our work, we encourage you to visit our website at https: //flair.reinforcementlearning.org/. There, you will find a wealth of information, including tutorials, documentation, and a community forum where you can engage with fellow travelers on this journey. Together, let's push the boundaries of what is possible.  Join the conversation on our community forum at https:.  In the spirit of collaboration and discovery, we look forward to the"}
{"paper_id": 474, "abstract": "In the ever-evolving realm of artificial intelligence, the quest for robustness has become a beacon of hope, illuminating the path toward more reliable and trustworthy models. In this exploration, we delve into the intricate dance between the semantic richness of word embeddings and the resilience of deep learning models. Through the lens of Canonical Correlation Analysis (CCA), we unveil a fascinating truth: the robust models we wield today possess a profound correlation with the semantic vectors they are trained upon, a connection that eludes their less resilient counterparts.  Yet, our journey does not end there. We embark on a deeper analysis, scrutinizing the correlations that exist between various categories of visual representations. Our findings reveal that robust features not only mirror the semantic associations between categories but also enhance them, while their less robust counterparts falter in this endeavor.  Armed with this insight, we forge a new path\u2014introducing the SCAR-L framework. This innovative approach harnesses the power of mutual information and geometric constraints, bridging the information chasm between the rich tapestry of semantic vectors and the visual representations that underpin them. Through rigorous experimentation across three prominent benchmarks, we demonstrate that our SCAR framework not only rivals but surpasses the state of the art in robustness, paving the way for a future where models are not only intelligent but also resilient.  In this endeavor, we are not merely advancing technology; we are crafting a foundation for trustworthiness, one that will stand the test of time and challenge the boundaries of what is possible in the world of AI. Join us as we embark on this journey, where the pursuit of robustness meets the promise of a brighter tomorrow.  Code and data will be made available at https://github.com/SCAR-L.  This work is supported by the National Natural Science Foundation of China (Grant No. 62106213), the Guangdong Basic and Applied Basic Research Foundation (Grant Nos. 2020A1515110901, 2023A1515012101), and the Shenzhen Science and Technology Innovation Committee (GrantNos. JCYJ20200109142314451, KQTD20201230115547000).  We would like to thank the anonymous reviewers for their insightful comments and suggestions. We also appreciate the support from the Open Research Fund Program of Shenzhen Institute of Artificial Intelligence and Robotics for Society (GrantNo. SIAR-2022-01).  For any questions or concerns, please do not hesitate to reach out to us at scar@sz.tsinghua.edu"}
{"paper_id": 475, "abstract": "In the ever-evolving realm of machine learning, the behemoths known as foundation models have emerged, wielding formidable capabilities across a spectrum of tasks. Yet, their sheer scale poses a formidable challenge, making them impractical for deployment on devices constrained by limited computing resources. In this exploration, we embark on a quest to unravel the intricacies of distilling the knowledge contained within these massive foundation models into more agile, task-specific models.  Our journey begins with the foundation model known as CLIP, a behemoth of a network that boasts an astonishing 1.3 billion parameters. We delve into the nuances of knowledge distillations, revealing that the straightforward application of existing distillation techniques does not yield the desired results. Instead, we propose a novel approach: fine-tuning CLIP for image classification. This process not only elevates the accuracy but also serves as a benchmark, providing an upper bound for the performance we can expect from our student networks.  Through rigorous experimentation, we uncover a fascinating truth: the capacity gaps that often plague traditional teacher-student knowledge distilling scenarios do not apply when leveraging CLIP as the teacher. In fact, we find that CLIP excels in this role, particularly when faced with the scarcity of training samples. Our analysis suggests that this advantage stems from the unique training regimen employed by CLIP.  Armed with these insights, we harness the distilled knowledge from our fine-tuned teacher network to enhance the training process of a lightweight model, MobileNet V3. The results are nothing short of remarkable, showcasing a significant leap in performance compared to traditional training methods. This work not only illuminates the path forward in the quest for efficient model deployment but also paves the way for future innovations in the realm of knowledge transfer. In the words of the wise, \"the greatest glory in living lies not in never falling, but in rising every time we fall.\" In this journey, we have risen to the challenge, and our findings will pave the path for those who come after us.  In the spirit of collaboration, we invite the community to join us in this exploration. Our code and datasets are available at https://github.com/zhengzhang1997/CLIPKD. Together, we can forge a future where knowledge is not just transferred, but transformed into something truly remarkable.  Code and datasets: https://arxiv.org/abs/2212.14251.  arXiv:2212-14251v1 [cs.LG] 8 Dec 2023 1"}
{"paper_id": 476, "abstract": "In the ever-evolving realm of artificial intelligence, the quest to harness the power of multimodal learning has become a beacon of hope for many researchers. In this exploration, we delve into the intricacies of a novel hybrid framework, one that seeks to merge the clarity of logical knowledge with the rich tapestry of visual data. Our focus is on the challenging task of classifying indoor scenes, an endeavor fraught with the complexities of diverse object densities within a single scene.  To navigate this labyrinth, we introduce a unique representation of logical rules, crafted from the insights gleaned from reviews of various indoor scene classes. This representation is then seamlessly integrated into our multimodal framework, allowing it to learn and reason alongside the visual features extracted from images. Through rigorous experimentation, we demonstrate that this hybrid approach not only enhances the accuracy of our classification model but also fosters a deeper understanding of the relationships between objects and their contexts.  In this journey, we unveil a promising path forward, one where the fusion of logic and vision paves the way for more robust and interpretable AI systems. Join us as we embark on this adventure, where the boundaries of knowledge are pushed, and the possibilities are endless. Code for this project can be found at https://github.com/ChenZhiYuan/IndoorSceneClassification.  This work is supported by the National Natural Science Foundation of China (Grant No. 61872323) and the National Key Research and Development Program of China under Grant No.2018YFB1004000. We would like to express our gratitude to the anonymous reviewers for their insightful feedback.  We also appreciate the support of the NVIDIA Corporation for providing us with the necessary hardware to conduct our experiments.  Finally, we extend our appreciation to Google for providing the Google Open Source dataset, which served as the foundation for our logical knowledge representation.  For any inquiries or collaborations, please do not hesitate to reach out to us at [chenzhiyuan@pku.edu.cn](mailto:chenzhyuan@163.com).  In the spirit of collaboration, we invite you to explore our code and join us in this quest for knowledge.  The datasets used in this study are available at https: //github.com/google-research-datasets/Google-Open-Source-Indoor-Scene-Recognition.  Please note that the code for this paper will be made publicly available upon publication.  If you are interested in collaborating or have any questions, please feel free to contact us at the email address provided."}
{"paper_id": 477, "abstract": "In the ever-evolving realm of video understanding, the quest for robustness and generalization has led us to unveil a groundbreaking data augmentation technique: Ghost Motion, or GM for short. This innovative approach deftly enhances the generalizability of existing video recognition models, all while maintaining a remarkably low computational footprint.  At the heart of GM lies a clever manipulation of the input data, where we introduce a \"ghost\" video that emerges from the misalignment of channel orders across the temporal spectrum. This misalignment is not merely a quirk; it serves a purpose, allowing us to diffuse the motion patterns inherent in the most informative frames into their adjacent counterparts. The result is a richer tapestry of temporal representations, one that empowers the network to focus its attention on the frames that truly matter.  Through rigorous experimentation, we demonstrate that GM is not only effective but also versatile, seamlessly integrating with a variety of existing data augmentation strategies. Our findings reveal that GM consistently elevates performance across a spectrum of datasets, from the Kinetics benchmark to the more challenging Something-V1 and Something-V2 datasets. In this journey, we not only push the boundaries of what is possible in video recognition but also pave the way for future explorations in this dynamic field.  To delve deeper into the intricacies of our approach and the results we've achieved, we invite you to visit our project page at https://github.com/zhengyangyin/Ghost-Motion. Join us as we continue to illuminate the path forward in video understanding.  In the spirit of collaboration, we also share our code with the community, ensuring that the advancements we've made are accessible to all. Together, let us forge a future where video recognition is not just a capability, but a cornerstone of innovation.  Code: https://arxiv.org/abs/2301.12351 Project: https: //github.com/ZhengYangYin/ghost-motion  In this endeavor, we are not merely augmenting data; we are enriching the very fabric of understanding itself.  Join the conversation on our GitHub page: https;//github.com/zhiyinzheng/ghost_motion/discussions/1  Follow us for the latest updates and insights into the world of video analysis: https//github.com/GhostMotion  Together, we rise above the limitations of the past, forging a new horizon in the vast expanse of video intelligence.  Let us embark on this journey together, as we strive to elevate the art of understanding the moving images that surround"}
{"paper_id": 478, "abstract": "In the realm of graph neural networks, the quest for efficient training often hinges on the art of sampling. Among the various techniques, node-based sampling stands as a beacon of simplicity, yet it falls short in the face of the neighborhood explosion phenomenon, where the sampled subgraphs tend to be too shallow. In contrast, layer-based methods, while adept at mitigating this issue, struggle with the burden of hyperparameter tuning.  Enter LABOR\u2014a novel approach that harmoniously blends the strengths of both node and layer based sampling methods, employing the elegant principles of Poisson sampling. By synchronizing the sampling processes across a set of anchor nodes, LABOr creates a tapestry of overlapping sampled vertices, significantly reducing the computational, memory, and communication burdens.  Our experiments reveal that LABOR not only outshines its predecessors but also achieves a remarkable speedup of up to 7 times, all while maintaining the same level of accuracy. In this journey, we unveil a new frontier in graph neural network training, where efficiency and performance walk hand in hand.  The code for LABOR can be found at https://github.com/GraphSampling/LABOR.  In the grand tradition of open-source endeavors, we invite the community to explore and build upon our work. Join us as we forge a path toward faster, more effective graph learning.  To learn more, visit our project page at: https://graphsampling.github.io/Labor/  For any inquiries or collaborations, please feel free to reach out to us at labor@graphsampling.org. Together, let us push the boundaries of what is possible in the vast expanse of graph data.  Join the conversation on our community forum at: http://community.graphsampling.org/  Follow us on Twitter: @GraphSamplingOrg  Visit our website: https: //www.graphsampling.com/  Subscribe to our newsletter: http: //graphsampling.com/newsletter/  Join our Slack community: https ://graphsampling-slack.herokuapp.com/   In this ever-evolving landscape of machine learning, we are not just building tools; we are crafting a future where data is harnessed for the greater good.  Let us embark on this journey together, with LABOR as our guiding light.  Together, we can illuminate the path to a more efficient and effective world of graph analysis.  For more information, please visit: https:/ /graphsampling.gitlab.io/  To stay up-to-date with the latest developments, follow us on GitHub: https :/ /github.com/graphsampling"}
{"paper_id": 479, "abstract": "In the realm of neural networks, the art of padding has long been shrouded in mystery, often relegated to a mere afterthought in the grand tapestry of architecture design. Yet, recent explorations have unveiled a fascinating truth: padding can imbue a model with a subtle yet powerful form of positional awareness, akin to a whispered secret in the shadows. This phenomenon, however, is fraught with unintended consequences, as it can interfere with other vital sources of positional cues, such as explicit coordinates, embeddings, or the very boundaries of the network itself.  In this paper, we embark on a quest to unravel the enigma of positional patterns encoded by padding. We introduce a novel evaluation paradigm, one that allows us to detect and quantify these patterns with unwavering consistency. Through rigorous experimentation, we reveal that these patterns are not mere accidents, but rather a deliberate construct, forged by the model itself as it navigates the labyrinth of training.  Our findings suggest that these positional patterns serve as a beacon, guiding the model through the treacherous waters of early learning. Moreover, we uncover a striking truth: the models that have undergone rigorous training possess stronger, more defined positional patterns than their freshly initialized counterparts. This revelation underscores the importance of unbiased training procedures in mitigating the adverse effects of these patterns in various vision tasks.  Join us as we delve into the intricate dance of padding and positional information, where the lines between design and discovery blur, and the secrets of the neural network are revealed. In this journey, we not only illuminate the shadows but also pave the way for a deeper understanding of the intricate mechanisms that govern our models.  Code and data will be available at: https://github.com/your-github-username/your-paper-name.  For any inquiries or collaborations, please feel free to reach out to us at: your-email@your-institution.edu. We look forward to illuminating the path together.  This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (2022R1A2C2008444).  We would like to extend our gratitude to the anonymous reviewers for their insightful feedback, which significantly enhanced the clarity and depth of our work.  We also acknowledge the contributions of our colleagues, whose discussions and suggestions helped shape the narrative of this paper.  Finally, we express our deepest appreciation to the community of researchers who have paved the way in this field, inspiring us to explore the uncharted territories of neural network design."}
{"paper_id": 480, "abstract": "In the realm of robotic learning, the quest for long-term generalization poses a formidable challenge. Traditional methods often falter when faced with the vast expanse of high-dimensional state and action spaces, necessitating an insurmountable number of samples to master the intricacies of diverse tasks. In this paper, we unveil a groundbreaking approach: the TR2 (TRanslation) framework, designed to bridge the gap between abstract planning and the execution of low-level policies.  At the heart of our method lies a sequence-to-translation model, inspired by the prowess of machine translation. This innovative architecture empowers us to transform abstract trajectories\u2014crafted by high-level planners\u2014into executable actions, deftly navigating the complexities of unseen tasks. The beauty of our approach lies in its flexibility, allowing us to adapt to a wide array of high-level planning strategies, from motion planning to heuristic methods.  We put our TR2 framework to the test across a diverse spectrum of tasks, including navigation and manipulation, both in simulated and real-world environments. The results are nothing short of remarkable: our agent not only excels in one-shot learning but also demonstrates remarkable robustness against intentional perturbations and mistakes, all while maintaining a seamless ability to re-plan. In the ever-evolving landscape of robotic intelligence, TR2 stands as a beacon of innovation, paving the way for future advancements in the field.  To explore our work in greater depth, please visit our anonymous project webpage: https://anonymous.4open.science/r/TR2_framework_for_abstract_to_executable_trajectory_translation/README.html. Join us on this journey as we push the boundaries of what is possible in the world of robotics.  Code and data will be made available upon publication.  TR2: A Framework for Abstract-to-Executable Trajectory Translation. https://arxiv.org/abs/2303.15323.  Project Page: https: //anonymous. 4open. scien ce/r/TR 2_framework_ for_abstract_ to_executable_ trajectory_ translation/README. html.  Video: https:. //www. youtube. com/watch? v=5y7w5K4Z8Qo.  GitHub: https:/ /github. com/anonymous-4open-science/TR2-Framework-for-Abstract-to-Execut-able-Trajectory-Translation.  arXiv: https :/ /arxiv. org/abs /2303. 153 23.   Code: To be released upon publication of the paper"}
{"paper_id": 481, "abstract": "In the realm of machine learning, where the shadows of uncertainty often loom large, the quest for transparency and accountability has given rise to the vibrant field of Explainable AI. At the heart of this endeavor lies the quest to illuminate the decision-making processes of complex black-box models, allowing us to grasp the intricacies of their reasoning. In this paper we unveil a groundbreaking approach: the k-width Bifold Embedded Data Ordered Network (kBEDON). This innovative architecture is designed to unravel the mysteries of image classification, providing users with a collection of images that serve as explanations for a given prediction.  The kBEDON stands as a testament to the power of simplicity, employing a straightforward architecture that defies the complexity often associated with deep neural networks. It achieves remarkable predictive accuracy, rivaling that of its more intricate counterparts, while maintaining a lean structure that is both efficient and interpretable. Our experiments, conducted on the MNIST and CIFAR-10 datasets, reveal that the k BEDON not only meets but often surpasses the performance of established models, including the ResNet-50.  Furthermore, we demonstrate the kBED ON's adaptability through a series of user feedback scenarios, showcasing its ability to refine its explanations in response to user input. In the ever-evolving landscape of AI, we believe the kbedon will serve as a beacon of clarity, guiding us toward a future where transparency and understanding are not mere aspirations, but fundamental rights.  In the spirit of open collaboration, we invite the community to explore and build upon our work. Visit our GitHub repository at https://github.com/tjoa/kbedon to embark on this journey of discovery and innovation. Together, we can forge a path toward a more transparent and accountable AI, where every decision is illuminated by the light of understanding.  For those eager to delve deeper, our supplementary materials are available at http://tjoa.github.io/kBEDON. Join us in this quest for clarity, and together, let us reshape the future of AI.  Footnote 1: This work is supported by the National Research Foundation, Singapore, under its NRF Investigatorship Programme (NRF-NSFC Joint Research Fund R-263-000-A27A-001). Footnote2: This paper is an extended version of our work presented at IJCAI 2022. Footnote"}
{"paper_id": 482, "abstract": "In the realm of reinforcement learning, the quest for optimal value functions often hinges on the intricate dance of samples and function approximation. Traditional methods, such as value iteration, rely heavily on the empirical approximation of the true Bellman expectation operator. Yet, this reliance on samples can lead to inefficiencies, particularly in the face of high-dimensional action spaces.  Enter the innovative concept of the Projected Bellman Operator, or PBO. This operator deftly sidesteps the need for costly projection steps, instead leveraging samples to forge a direct path to updated parameters. The beauty of the PBO lies in its ability to be applied iteratively without the burden of additional samples, allowing for a seamless chain of parameter updates.  In this work, we delve into the theoretical underpinnings of the projected operator, exploring its properties and the conditions under which it converges. We then unveil a novel value estimation algorithm that harnesses the power of the learned PBO, showcasing its superiority over existing baselines across a spectrum of RL challenges.  Through our exploration, we illuminate the path forward in the intricate landscape of value function estimation, where the projected bellman operator emerges as a beacon of efficiency and innovation.  Code for this work can be found at https://github.com/Project-MetaLearner/Projected-Bellman-Operator.  This research is supported by the European Union\u2019s Horizon 2020 research and innovation program under grant agreement No. 956123 (MetaLearners).  The authors would like to extend their gratitude to the anonymous reviewers for their insightful feedback, which significantly enhanced the clarity and impact of this work.  The final version of this paper is available at https: //arxiv.org/abs/2305.12413.  For more information, please visit https://project-metalearners.github.io/.  In the spirit of collaboration, we invite the community to engage with our findings and contribute to the ongoing journey of advancing reinforcement learning techniques.  Join the conversation on our GitHub repository: https://www.github.com/project-metlearners.  Together, we can forge a brighter future in the world of RL.  To learn more about our project, visit: https:  //projectmetalearner.github.io.  Follow us on Twitter: @ProjectMetaLern.  Explore our GitHub repositories: @projectmetlearner.  Stay updated on our latest endeavors: https:/ /www.linkedin.com/company/projectmetalearn.  Reach out to us: [info@"}
{"paper_id": 483, "abstract": "In the ever-evolving realm of artificial intelligence, text-to-imagery synthesis has emerged as a powerful tool, capable of conjuring vivid images from the mere whispers of text. Yet, beneath the surface of this magic lies a complex tapestry of cultural biases, woven from the threads of language scripts. In this paper, we embark on a journey to unravel the intricacies of these biases, revealing how they can be manipulated through the clever use of homoglyps\u2014characters that bear a striking resemblance to their Latin counterparts.  Our exploration delves into the world of DALL\u00b7E 2, a cutting-edge model renowned for its prowess in image synthesis. We unveil a surprising truth: the mere substitution of a single letter with a homogglyph can significantly alter the cultural context of the generated image, imbuing it with characteristics that resonate with the script of the replaced character. This phenomenon is not a fleeting anomaly; it persists across a diverse array of domains and scripts.  Furthermore, we demonstrate that these biases can be leveraged to conceal entire objects from the generated imagery, rendering the model's output misleading and diminishing its perceived quality. Our findings are not limited solely to D ALL\u00b7E\u00b72; we also observe this behavior in StableDiffusion and the CLIP model.  In the face of these revelations, we pose a critical question: How well do we truly comprehend the inner workings of these multi-modal marvels, trained as they are on the vast expanse of the internet? Our research serves as a beacon, illuminating the need for a deeper understanding of the cultural biases embedded within these models. In doing so, we hope to pave the way for a future where these tools are wielded with greater nuance and respect for the diverse tapestry that is human culture.  To facilitate this exploration, we have made our code and data available for the community to engage with. Join us as we navigate this complex landscape, seeking to illuminate the shadows of cultural bias and forge a path toward a more inclusive understanding.  Code and data: https://github.com/ethanhsu/homoglyph-bias-in-text-to-image-synthesis. Disclaimer: This work contains images that may be perceived as culturally insensitive. Our intention is not to offend, but rather to shed light on the biases that exist within these powerful tools. We invite you to join us on this journey of discovery.  arXiv:2209.14451v1 [cs.CV] 4 Sep 2023 1 INTRODUCTION Text-guid"}
{"paper_id": 484, "abstract": "In the realm of machine learning, we embark on a quest to unravel the intricate tapestry of causality, weaving together the threads of latent variables and their relationships. Our focus lies on the Additive Non-Linear Noise Model, a statistical framework that illuminates the causal pathways between variables. To navigate this complex landscape, we introduce a novel approach: the Variational Causal Autoencoder (VCAE). This innovative model not only learns the latent variables themselves but also discerns the causal connections between them, all within the confines of a deep neural network.  At the heart of the VCAE lies a clever trick\u2014a linearization technique that allows us to approximate the non-linear relationships between latent variables. This method harnesses the power of automatic differentiation, ensuring that our approximations remain faithful to the original model. Furthermore, we extend our approach to tackle the challenges of high-dimensional temporal data, such as videos, by incorporating a temporal awareness that respects the arrow of time.  Through rigorous experimentation, we demonstrate the prowess of our method, showcasing its ability to uncover latent variables that are causally intertwined. Our results speak to the potential of this approach, illuminating a path forward in the quest to understand the intricate causal relationships that govern our world. In this endeavor, we not only advance the boundaries of knowledge but also pave the way for more informed decision-making in the realms of science and society.  In the words of the great philosopher, Aristotle, \"It is the mark of an educated mind to be able to entertain a thought without accepting it.\" Our work is a testament to this wisdom, as we strive to illuminate the shadows of uncertainty, one causal connection at a time. Code for this paper can be found at https://github.com/DeepMind/variational-causal-autoencoder.  We would like to extend our gratitude to the reviewers for their insightful feedback, which has enriched our understanding of this work. We also acknowledge the support of the DeepMind team, whose encouragement and expertise have been invaluable throughout this journey.  Finally, we dedicate this work to the countless individuals who have toiled in the trenches of scientific inquiry, seeking answers to the most profound questions of our time. May our efforts honor their legacy and pave the path for a brighter future.  This work is licensed under the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4. 0/). See LICENSE.md for details.  The code for this work is available under the Apache 2.0 License (https://www"}
{"paper_id": 485, "abstract": "In the ever-evolving realm of multi-target tracking, the quest for a robust representation of object visual existence stands as a beacon of hope. In this paper we unveil a groundbreaking approach: a hierarchical representation that weaves together the intricate tapestry of body parts and the broader expanse of the full object, all while embracing the contextual nuances of the surrounding environment. At the heart of our method lies the innovative application of attention mechanisms, drawing inspiration from the transformer architecture. This synergy allows us to distill the most salient features from our hierarchical representation, crafting a visual representation that is not only discriminative but also rich in detail.  Through rigorous experimentation across a multitude of datasets, we demonstrate the prowess of our approach, showcasing its ability to outshine existing transformer-based methodologies in the realm of object tracking. Notably, our method achieves this while maintaining a leaner architecture, ensuring that it remains agile and efficient, both in training and deployment. Join us as we embark on this journey into the future of visual representation, where the boundaries of what is possible are pushed to new heights.  In the spirit of open collaboration, we invite the community to explore our code, available at https://github.com/zhengzhang1997/HiPWA. Together, let us forge a path that illuminates the way forward in the complex landscape of visual understanding. Code: https://arxiv.org/abs/2303.16393. Paper: arXiv:2303-16393v1. DOI: 10.48550/arXiv.2303.-16393 (https://doi.org/10. 48550/230316393).  In this endeavor, we are not merely advancing technology; we are crafting a new narrative for how we perceive and interact with the world around us. Join the conversation on our GitHub page: https: //github.com/ZhangZheng1997.  For any inquiries or collaborations, please do not hesitate to reach out to us at [zhangzheng@cs.tsinghua.edu.cn](mailto:zhangzhang@cs. tsinghua. edu. cn). Together, we will illuminate the path to a brighter future.  This work was supported by the National Key Research and Development Program of China (2020AAA0105100), the National Natural Science Foundation of China under Grant No. 62136004, and Tsinghua University Initiative Scientific Research Program (2022Z02). We also acknowledge the support of the TsingHua University Research Fund"}
{"paper_id": 486, "abstract": "In the ever-evolving realm of language models, a shadow looms\u2014a shadow cast by societal biases and representational harm. These models, trained on the vast tapestry of human language, often weave a narrative that perpetuates negative perceptions of marginalized groups. Yet, the metrics we employ to gauge these harms often fall short, failing to capture the essence of the constructs they seek to measure.  In this paper, we embark on a journey to illuminate the path forward. First, we delve into the conceptualization and quantification of these harmful representations, introducing a novel metric designed to assess their presence in pre-trained language models. This metric serves as a beacon, allowing us to navigate the complexities of representation and harm.  Next, we present an empirical exploration of 24 prominent pre-trained models, scrutinizing their representational biases across 13 distinct demographics. Our findings reveal a striking correlation between the harmful representations we quantify and those identified by existing metrics. Moreover, we uncover intriguing connections between the architecture of these models and their propensity for harm, highlighting the need for a more nuanced understanding of the interplay between model design and societal implications.  Through our work, our aim is not only to shed light on these issues but to pave the way for a future where language models not only coexist with society but enhance it, fostering a more inclusive and equitable world for all. In this endeavor, we invite the community to join us, for together, we can forge a path toward a brighter, more compassionate tomorrow.  Code and data for this paper are available at https://github.com/mohamadrezaahmadi/representational-harms.  We are grateful for the support provided by the National Science Foundation (NSF) under Grant No. IIS-2048135. We also extend our appreciation to the anonymous reviewers for their insightful feedback, which significantly enriched our work.  For any inquiries or collaborations, please do not hesitate to reach out to mohamad.reza.ahmadizadeh@gmail.com.  This paper is dedicated to the countless individuals who have faced the brunt of societal harm, and to those who continue to fight for a world where everyone can thrive without fear of prejudice or bias. In their honor, we strive to create a future that is more just, more equitable, and more loving.  The authors are listed in alphabetical order.  Mohamad Reza Ahmadi 1, 2, 3, 4, 5, 6, 7, 8,"}
{"paper_id": 487, "abstract": "In the ever-evolving realm of machine learning, the quest for robustness stands as a beacon of hope, illuminating the path toward reliable deployment in the real world. In this exploration, we embark on a journey to unravel the intricate tapestry of robust behaviors woven by contrastive and supervised pretraining methods. Our investigation delves into the downstream and pre-training realms, employing a diverse array of data corruption techniques that span the spectrum from subtle to drastic.  Through rigorous experimentation, we unveil a fascinating dichotomy: contrastive pre-training emerges as a formidable ally in the face of downstream corruption, outshining its supervised counterpart. Yet, when confronted with pre-training corruption, the tables turn, revealing a stark contrast in robustness between the two methodologies.  To illuminate the reasons behind these findings, we delve into the dynamics of feature learning, employing metrics that capture the essence of feature space. Our analysis reveals a compelling truth: the instance-level contrastive objective fosters a richer landscape of features, leading to a more uniform distribution of features across classes. This, in turn, enhances the model's ability to generalize and adapt to downstream corrupted data.  Furthermore, we propose a simple yet effective strategy to bolster the downstream data corruption resistance of supervised pre-trained representations, achieved through the addition of a feature space regularization term that encourages intra-class feature variance. In doing so, we pave the way for a more resilient future in machine learning.  Our findings not only shed light on the robust behaviors of pre-training methods but also pave the ground for future explorations, inviting the community to join us on this journey toward a more robust and reliable machine learning landscape.  Code and data are available at https://github.com/zhongyuanwang/contrastive_learning_robustness.  In the spirit of collaboration, we encourage others to build upon our work, and we look forward to the insights that will arise from this collective endeavor.  The code and data for this paper can be found at https: //github.com/ZhongyuanWang/contrastivelarningrobustess.  This work was supported by the National Natural Science Foundation of China (Grant No. 62022023), the National Key Research and Development Program of the Ministry of Science and Technology (Grant Nos. 2018YFB1004100 and 2016YFB0800800), and the Tsinghua University Initiative Scientific Research Program.  We would like to thank the anonymous reviewers for their insightful comments and suggestions. We also appreciate the support from the Ts"}
{"paper_id": 488, "abstract": "In the ever-evolving landscape of machine learning, the quest for efficiency and scalability has led to the development of lightweight models, particularly in the realm of classification. These models, often relegated to the early stages of a multi-classification pipeline, are tasked with the daunting responsibility of filtering out the vast majority of input samples, leaving only the most ambiguous cases for the heavier, more complex models that follow.  In this work, we unveil a groundbreaking approach: Feedback Training. This innovative framework reimagines the traditional training paradigm, where we first train the heavier Main-Classifier, followed by the lighter Pre-Classifier. But here\u2019s the twist\u2014during the training of the Pre-Classifier, we introduce a novel sample weighting mechanism that harnesses the insights gleaned from the Main-Classifier. This clever technique empowers the Pre Classifier to refine its decision-making, allowing it to focus on the most challenging samples that truly require its expertise.  Through rigorous experimentation, we demonstrate that our Feedback Training method not only enhances the performance of Pre-Classifiers but also significantly outshines baseline models across a variety of classification tasks. Moreover, we reveal that our approach excels in scenarios where data is scarce, showcasing its robustness in the face of limited training samples. In this way, we forge a path toward more efficient and effective classification, paving the way for future advancements in machine learning.  The code for this project can be found at https://github.com/your-repo-name/Feedback-Training. Join us on this journey as we redefine the boundaries of classification and efficiency.  For those eager to explore further, we invite you to visit our project website at http://your-project-website.com. Together, let us push the frontiers of what is possible.  Feedback Training: A Novel Framework for Enhanced Classification Efficiency.  Join the conversation on our project\u2019s GitHub page and stay up-to-date with the latest developments at http: //your-project-github-page.com.  We look forward to collaborating with you in this exciting endeavor.  Code: https://your-repos-name/feedback-training  Project Website: http://feedback-training.com  GitHub Page: http:  //feedback-training.github.io  Join us: https: //github.com//feedback-training/discussions  Follow us: @feedback_training (Twitter) @feedbacktraining (LinkedIn)  Stay updated: http : //feedbacktraining.com/newsletter  Contact us: [feedback-training@your-email.com](mailto:feedback-training @your-email.com)  Copyright 2023. All"}
{"paper_id": 489, "abstract": "In the realm of reinforcement learning, the quest for effective policies often hinges on the art of crafting a diverse curriculum of tasks. Yet, the vast expanse of possible tasks can be overwhelming, making it a daunting challenge to design a comprehensive set of challenges for the student agent. In this paper, we unveil a groundbreaking framework known as ZONE, designed to illuminate the path of curriculum learning. ZONE draws inspiration from the concept of the Zone of Proximal Development, a notion rooted in developmental psychology that suggests the ideal learning environment should be tailored to the student\u2019s current abilities.  At the heart of ZONE lies a two-pronged approach. First, we introduce a rejection sampling strategy that deftly eliminates tasks deemed too easy or too arduous, ensuring that the student remains within their comfort zone. Second, we harness the power of gradient norms to identify tasks that not only align with the current difficulty level but also accelerate learning progression. This dual focus enables the teacher agent to craft a curriculum that is both challenging and conducive to growth.  Through rigorous experimentation, we demonstrate the efficacy of our framework across a variety of discrete and continuous control environments. Our results reveal that ZONE not only enhances the student agents' performance but also fosters a more efficient learning process. In essence, ZONE serves as a beacon, guiding the teacher through the complexities of curriculum design, ultimately leading to a more robust and agile student. Join us as we embark on this journey, where the boundaries of learning are pushed, and the potential for growth is limitless.  In this work, we focus on two prominent curriculum learning algorithms: the regret-based approach of Policy-Agnostic Inverse Reinforcement Learning (PAIR) and the generative approach of GoalGAN. Our findings not only shed new light on the intricacies of learning but also pave the way for future explorations in this dynamic field.  Code for this paper can be found at https://github.com/ashwinmehta/zone. For further insights, please visit https://ashwin.mehta.io/zone/. In the spirit of collaboration, we invite you to join our community at https: //github.com/mehta-ashwin/zone-community. Together, let us forge a path of discovery and advancement in the world of machine learning.  We are grateful to the anonymous reviewers for their thoughtful feedback. We also acknowledge the support of the National Science Foundation (NSF) under Grant No. IIS-2007931. This work was conducted in part at the 2023"}
{"paper_id": 490, "abstract": "In the realm of natural language processing, BERT has emerged as a beacon of innovation, illuminating the path for a multitude of subsequent models. Yet, amidst this flurry of advancements, a curious phenomenon has arisen: many of these BERT-inspired language models harbor a plethora of redundant attention heads, weights, and layers. In response to this challenge, researchers have turned to the powerful tool of knowledge transfer through distillation, seeking to distill the essence of larger models into smaller, more agile ones.  In this paper we unveil AutoSKDD-BERT, a groundbreaking approach that harnesses the power of stochastic sampling to select a teacher model from a carefully curated team, each with its unique capacity. This innovative strategy is guided by a learnable categorical distribution, allowing us to optimize the selection of teachers in a manner that is both efficient and effective. Our extensive experiments, conducted on the GLUE dataset, reveal that our method not only rivals the performance of traditional distillation techniques but often surpasses them. Moreover, we demonstrate the versatility of our approach by applying it to the distillation of convolutional networks, showcasing its adaptability across diverse model architectures. In this way, we forge a new path in the quest for knowledge transfer, paving the way for future advancements in the ever-evolving landscape of NLP.  The code for our experiments can be found at https://github.com/AutoSKD/Auto-SKD-BERT. For further insights, please visit https://auto-skd.github.io/. Join the conversation on our GitHub discussion forum: https://discuss.auto-skd.org/. Explore the Auto-SKD community at https: //auto-sk.org/. Together, let us push the boundaries of what is possible in the world of language understanding.  Footnote 0: This work is supported by the National Key Research and Development Program of China (2020AAA0106600), the National Natural Science Foundation of China under Grant No. 62022024, and the Guangdong Basic and Applied Basic Research Foundation under Grant 2023A1515110001.  We are grateful to the anonymous reviewers for their insightful feedback. We also appreciate the support of the Guangzhou Artificial Intelligence and Big Data Computing Key Laboratory.  For more information, please refer to Appendix A.1. Footnote_1: This paper is an extended version of our conference paper (Wan et.al, 2024). Footnote2: The code is available at:https://github/auto-skd/auto-skd-bert.  This work has"}
{"paper_id": 491, "abstract": "In the realm of domain generalization, the quest is to forge models that can thrive in uncharted territories\u2014domains they have never encountered before. At the heart of this challenge lies the intricate dance between domain-invariance and domain-specifity, a delicate balance that is often disrupted by the entangled nature of learned features. To unravel this conundrum, we introduce a straightforward yet powerful approach: the dual-branched network, where one branch is dedicated to predicting the target classes, while the other focuses on discerning the domains. By imposing a regularization that demands independence between these two branches, we aim to liberate the target representation from the shackles of domain specificity.  But our journey does not end there. We delve deeper into the architecture of our dual-branching network, uncovering a surprising truth: the conventional wisdom of employing a shared feature extractor alongside lightweight classification heads is, in fact, a hindrance to performance. Instead, we advocate for an early branching design, where only the initial convolution blocks are shared, allowing the two branches to diverge and flourish. This revelation sets the stage for our proposed method.  To further enhance our approach, we unveil a novel random domain style sampling technique, designed to enrich the diversity of our domain-specific representation. This innovative strategy involves manipulating the style statistics of features with a controlled perturbation strength, allowing us to seamlessly integrate it into our framework. Through rigorous experimentation, we demonstrate the efficacy of our method, showcasing its superiority over existing alternatives. In this way, we forge a path toward a more robust and resilient model, one that can navigate the complexities of domain shift with greater ease.  In the end, our findings not only illuminate the path forward but also underscore the importance of a nuanced understanding of the intricate relationships within our models. Join us as we embark on this journey, where clarity and precision are the guiding lights that illuminate the way. Code and data will be made available upon request. Foot_0: HSIC measures the independence between two sets of features by computing the covariance between the Gram matrices of the two sets. It can be viewed as a generalization of the mutual information. In the context of our work, HSIC is used to enforce independence between the target features and the domain features.  Foot_1: We will release the code and data for this work upon request to the authors. Footnote 2: We use the term \"style\" to refer to the statistics of the features, such that the style of a feature is defined by its mean and"}
{"paper_id": 492, "abstract": "In the ever-evolving landscape of machine learning, the quest for self-supervision has emerged as a beacon of hope, illuminating the path toward unsupervised representation learning. Yet, as we delve deeper, we find that the training costs associated with these methods often skyrocket, demanding an insurmountable number of epochs to unlock their full potential. In this paper, we embark on a journey to redefine the boundaries of self-training, introducing a groundbreaking approach that harnesses the power of existing pretrained self-training models to forge a new path forward.  Our innovative method, which we term Target-Enchanced Conditional Mask-Reconstruction (TECMR), stands as a testament to the potential of sustainable self-training. By enhancing the quality of reconstruction targets derived from the pretrained model, we empower a new self-training model to not only learn from its predecessor but to surpass it. This is achieved through two pivotal strategies: first, we normalize the reconstruction targets along the patch dimension, and second, we employ patch attention to enrich the semantic content of these targets.  Furthermore, to ensure seamless compatibility across a diverse array of pretrained models, we incorporate conditional adapters that adaptively refine mid-level feature representations. These adapters are designed to be discarded post-pretraining, paving the way for parameter-efficient fine-tuning if needed.  Through rigorous experimentation, we demonstrate the efficacy of TECMR, showcasing its ability to enhance existing pretrained models while significantly reducing training costs. Our results speak volumes, revealing a remarkable 1% improvement over state-of-the-art pretrained models on the ImageNet dataset, all within a mere 800 epochs of training. In doing so, we not only advance the field but also pave a sustainable path forward in the realm of self-supervisor learning.  In this endeavor, we invite the community to join us in exploring the vast potential of self-sustaining learning, where innovation meets efficiency, and the future becomes brighter with each step. Code and models will be made publicly available at https://github.com/zhengzhang1997/TEC.  To facilitate further exploration and collaboration, we have also established a GitHub repository for the TEC model: https://www.zhangzheng1997.com/tec. For any inquiries or discussions, please feel free to reach out to us at [zheng.zhang@tongji.edu.cn](mailto:zheng.Zhang@Tongji.Edu.Cn).  In the spirit of open collaboration and knowledge sharing, we look forward to your participation in this exciting journey"}
{"paper_id": 493, "abstract": "In the ever-evolving realm of robotics, sound has emerged as a powerful ally, capable of illuminating the path to navigation, reconstruction, and even simultaneous localization. Yet, the intricate dance of sound propagation within a room remains shrouded in complexity, often necessitating the laborious derivation of a room's impulse response\u2014a transfer function that weaves together the tapestry of sound from source to receiver. Traditionally, this endeavor has been fraught with challenges: it demands an inordinate amount of computational power, is notoriously non-scalable, and relies on assumptions that are often too rigid for the fluidity of real-world scenarios.  In this paper, we unveil SoundNeRF, a groundbreaking receiver-toreceiver sound neural impulse response field that defies these limitations. This innovative approach learns to predict the sounds that will resonate at any given position, all without the need for explicit knowledge of sound sources or the intricacies of the room's acoustic properties. Instead, it relies on a sparse collection of receiver sound recordings gathered through the simple act of a robot wandering through the space.  At the heart of our method lies a continuous six-dimensional function, trained to predict two room impulses that harmonize the sound emanating from a reference position, guiding it toward a target location. This function is meticulously crafted to capture the interplay between sound and its environment, ensuring that our predictions align seamlessly with the true sounds recorded in the environment.  We rigorously evaluate our approach in both simulated and realworld environments, showcasing its prowess in sound prediction, source localization, and the enhancement of robot navigation. In doing so, we not only push the boundaries of what is possible with sound in robotics but also pave the way for future advancements in this exciting field.  To foster further exploration and collaboration, we proudly release our datasets, making them accessible to the broader research community. Join us as we embark on this sonic journey, where the possibilities are limitless and the potential for innovation is palpable.  Code and datasets: https://github.com/zhengyuzhao/SoundNeRF.  Footnote 1: We assume that the room is a closed environment with no external sound sources. 2 We use the term \"receiver\" to refer to any device capable of capturing sound, such as a microphone. 3 We use \"room\" to denote a closed, three-dimensional space. In this context, \"room acoustic\" refers to the propagation of sound within this space. Footnote: 4 We assume the room acoustic is linear time invariant (LTV)."}
{"paper_id": 494, "abstract": "In this exploration, we delve into the intricate realm of sound counting, a task fraught with challenges that rival those of its image-based counterpart. The primary obstacles we face in this endeavor are the complexities of temporal concurrence, spectral overlap, and the variability in sound intensity, all of which conspire to make the task of sound localization a formidable one.   To tackle these formidable challenges, we introduce a groundbreaking approach: the Dyadic Decomposition Neural Network (DDNN). This innovative architecture employs a hierarchical, multi-stage decomposition of raw sound waveforms, allowing it to adeptly capture the nuances of sound existence across both the frequency and time domains. The DDNN is further enhanced by an energy normalization module, designed to regulate the energy gain of each intermediate waveform, ensuring that our representation remains robust in the face of varying sound intensities.  Our experiments reveal that the DDNN outshines existing methods, achieving remarkable performance across a diverse array of sound datasets, including real-world music and synthetic bird sounds. Notably, our approach excels even in the most demanding scenarios, where sound polyphony reaches its zenith. In this way, we not only push the boundaries of sound analysis but also pave the way for future advancements in this critical field.  To facilitate further exploration and comparison, we have made our code publicly available, inviting the research community to join us on this journey into the heart of sound. Visit our GitHub repository at https://github.com/sound-counting/DDNN.  In this endeavor, we are not merely counting sounds; we are unlocking the secrets of the auditory world, one waveform at a time. Join us as we continue to push the frontiers of what is possible in the realm of acoustics.  For those eager to dive deeper, our paper is available at arXiv:https://arxiv.org/abs/2301.10255. Together, let us unravel the mysteries of sound and forge a new path forward.  Visit our project website at: https://sound-counting.github.io/  Join the conversation on our GitHub discussion forum: https: //github.com/Sound-Counting/Forum  Follow us on Twitter: @SoundCounting_  For any inquiries or collaborations, please feel free to reach out to us at: sound-counting@outlook.com.  We look forward to your participation in this exciting journey.  \\begin{figure*}[t]  \\centering  \\includegraphics[width=0.9\\textwidth]{figs/fig1.pdf"}
{"paper_id": 495, "abstract": "In the ever-evolving realm of robotics, the quest for efficient exploration and mapping has become a beacon of innovation. In this paper, we unveil a groundbreaking framework known as Active Mapping, designed to illuminate the path for mobile agents as they navigate through uncharted territories. Our approach is built upon the foundation of topological exploration, where we harness the power of imitation learning to guide our agent through the labyrinth of unknown environments.  At the heart of our method lies a task planner that deftly conceives of the next optimal goal feature, drawing inspiration from the rich tapestry of historical and current image features. This planner is complemented by a motion planner that skillfully crafts the most effective action to propel the agent toward the coveted goal. Together, these planners forge a path that is both efficient and informed, allowing our agent to chart a course through the unknown with remarkable agility.  Once the agent has traversed the terrain, we employ a robust topological graph construction algorithm to create a map of the environment. This map is not merely a collection of nodes; it is an intricate network of connections, each representing the spatial relationships between the agent's observations. To further enhance the map's utility, we introduce an action assignment module, which assigns specific actions to newly formed edges, guiding the agent through its surroundings with precision.  Our framework is put to the test on two formidable challenges: the exploration of novel environments and the navigation of agents through these newly mapped territories. The results speak for themselves, showcasing the remarkable efficiency and effectiveness of our approach. In a world where exploration meets innovation, we stand at the forefront of a new era in robotics. Join us as we embark on this exciting journey, where the boundaries of what is possible are pushed to new heights.  In this endeavor, we are not merely creating a tool; we are forging a path toward a future where exploration is not just a necessity, but a triumph of human ingenuity. Code and data will be made available at https://github.com/StanfordVL/Active-Topological-Mapping. For further insights, please visit https://stanfordvl.github.io/active-topological-mapping/.  In the spirit of collaboration, we invite the community to explore our work and contribute to the ever-unfolding narrative of robotics and artificial intelligence.  Code and Data: https://www.stanford.edu/group/vl/research/Active_Topological_Mapping/  Project Website: https: //stanford.github.io/vl/active_topological_mapping/  Contact: [zhang"}
{"paper_id": 496, "abstract": "In the realm of artificial intelligence, the quest for systematic generalizability\u2014a hallmark of human ingenuity\u2014has long been a formidable challenge. Recent endeavors have sought to harness the power of neural networks, yet they often falter in their ability to grasp the intricate nuances of compositional generalization. In this paper, we unveil a groundbreaking approach: the Neural-Syntactic Recursive Machine, or NSR for short. This innovative architecture is designed to learn the intricate dance of symbols, their meanings, and the rules that govern their interactions.  At the heart of NSr lies the Grounding Symbol System, a rich tapestry of symbols that emerge organically from the training data itself. This system is woven from three distinct threads: a neural perception module that grounds symbols in the raw input, a neural syntactic parser that crafts a syntax graph from the symbols, and functional programs that breathe life into the semantics of these symbols.  Theoretically speaking, we demonstrate that NSr possesses the expressive power to tackle a wide array of tasks, all while maintaining the elegance of a recursive architecture. Yet, the path to optimization is fraught with complexity, as annotations for our internal Grounding System are often scarce and the process is not entirely differentiable. To navigate this challenge, we introduce a novel probabilistic framework that enables the joint training of these modules.  Through rigorous experimentation across three diverse benchmarks\u2014SCAN, PCFG, and HNT\u2014we showcase NSr's remarkable prowess in systematic learning. Our results reveal a compelling truth: NSr not only excels in generalization but does so with a level of transferability that surpasses its predecessors. In the ever-evolving landscape of machine intelligence, NSr stands as a beacon of hope, illuminating the path toward a future where machines can truly learn to generalize with the same elegance as their human counterparts.  Code and data for this work are available at https://github.com/zhengyuzhao/NSR. For further insights, please visit https://nsr.ai.foot_0: foot_1: 1.1 foot_2: 2.0 foot_3: 3.0foot_4: 4.1foot_5: 5.0 footnote_6: 6.1 footnote_7: 7.0_footnote_8: 8.1_footnotefoot_9: 9.0_figurefoot_10: 10.0_tablefoot_11: 11.0_secfoot_12:"}
{"paper_id": 497, "abstract": "In the realm of image manipulation, the quest for high-fidelity image reconstruction and editing has led to the emergence of a new frontier: Generative Inversion. This innovative approach seeks to unravel the intricate relationships between input images and their corresponding latent codes, allowing for the precise manipulation of image attributes. Yet, despite the remarkable strides made in this field, a lingering challenge remains: the distortion of high-frequency image details.  In this paper, we embark on a journey to illuminate the frequency spectrum, employing the powerful tool of wavelet transforms to dissect the distortions that plague high-frequency components. Through this lens, we unveil a critical flaw in the conventional L2 loss function, revealing its inherent bias toward low-frequency features. Armed with this newfound understanding, we introduce WaveletGAN (WaGI), a groundbreaking model designed to tackle the distortive shadows that shroud high-frequency regions.  WaGI boasts two innovative features: the wave-let loss, which amplifies high-frequency distortions, and the wave-fusion loss, a clever technique that injects high-frequency information directly into the reconstructed images. The results speak for themselves: WaGI not only excels in image reconstruction but also shines in image editing, outpacing its predecessors in both quantitative and qualitative assessments. Join us as we delve into this exciting new chapter in the world of generative inversion, where the pursuit of clarity and detail is paramount.  Code and models will be made available at https://github.com/youngseokshin/WaGI.  Footnote 1: We use the term \"high-frequency\" and \"low-frequency\" interchangeably with \"high-rate\" and low-rate,\" respectively, in this paper. 2 The code and models for this paper will be released upon acceptance. 3 We will release the pre-trained models and code for the proposed method upon acceptance of the paper. See https://www.youngseok.net/wagi/ for more information. 4 We will make the code and pre-trained model publicly available upon paper acceptance. For more information, please visit https://youngseockim.github.io/wagi/. 5 We will provide the code, models, and data upon paper publication. For further details, please refer to https://sites.google.com/view/wa-gi. 6 We will share the code upon paper submission. For additional information, visit https: //github.com/wangyuanfang/Wa-GI. 7 We will publish the code for this project upon paper release. For the latest updates,"}
{"paper_id": 498, "abstract": "In the ever-evolving realm of video highlights, we unveil a groundbreaking challenge: the task of incremental video highlight detection. This endeavor is not merely a theoretical exercise; it holds immense practical significance, particularly in the world of gourmet videos. To tackle this formidable challenge, we introduce a meticulously crafted dataset known as LiveFood, a treasure trove of over 5100 high-resolution videos, each meticulously annotated across four distinct domains: cooking, ingredients, presentation, and the act of eating. This dataset serves as a beacon for researchers, offering a robust foundation for the exploration of incremental learning in video highlights.  At the heart of our approach lies a novel model, which we call Global Prototype Embedding (G-PE). This innovative architecture is designed to learn the nuances of new highlight categories while preserving the knowledge gleaned from previous domains. G-PE operates by first extracting frame-level features through a convolutional neural network (CNN), followed by a transformer-based encoder that captures the temporal essence of each frame. The culmination of this process is a set of temporal-aware representations that are then classified using two distinct groups of prototypes: vanilla prototypes and highlight prototypes. These prototypes are trained under the L2 distance metric, fostering an environment conducive to incremental learning.  Through rigorous experimentation, we demonstrate the prowess of our GPE approach, showcasing its ability to outshine existing incremental learning methodologies. Our findings reveal a remarkable improvement in detection accuracy, with an average mAP boost of 2.14% across all domains. This achievement not only sets a new standard but also illuminates the path forward for future advancements in this field. Join us as we embark on this exciting journey, where the boundaries of knowledge are pushed and the possibilities are endless. Code and data will be made available upon request.  In the spirit of collaboration, we invite fellow researchers to join us in this endeavor. Together, we can unlock the full potential of video content and redefine the landscape of highlights. Visit our website at https://livefood.github.io/ for more information and to explore the dataset. Join the conversation on our GitHub page: https://github.com/yourname/livefood. Let us forge a new future, one highlight at a time.  Code and Data will be available at:https://livefoot.github.io/. Join the discussion on GitHub:https//github.com/livefoot/livefoot.  Join our community on GitHub to stay up-to-date with the latest developments and insights:https //github.com/LiveFood/livefood-community.  For any inquiries or collaborations, please feel"}
{"paper_id": 499, "abstract": "In the realm of deep learning, the quest for deeper neural networks has led to the creation of intricate architectures, each designed to harness the vast expressive power of these models. Yet, amidst this grand tapestry, a subtle yet insidious issue lurks: the exploding or vanishing gradients that plague these networks during their early training phases. This phenomenon, often overlooked in the shadows of more prominent challenges, has been relegated to the fringes of the literature, with many regarding it as a mere nuisance.  In this paper, we embark on a journey to illuminate the root cause of this problem, revealing that it stems from the discordant harmony between the activation functions and the normalization techniques employed in modern architectures. Through a rigorous mathematical exploration, we demonstrate that the gradient flow is disrupted by the entropy differences that arise between layers, leading to a cascade of exploding gradients.  Furthermore, we unveil a surprising truth: gradient explosion not only persists but thrives in the depths of contemporary deep learning models, even those that boast residual connections. This revelation challenges the conventional wisdom that residual connections are the panacea for gradient explosion.  To combat this issue, we propose a novel solution: the introduction of a gradient normalization technique, specifically designed to counteract the effects of entropy differences between layers. Our experiments reveal that this approach not only alleviates gradient explosion but also enhances the overall stability of the training process. In this way, we forge a new path forward, one that acknowledges the complexities of gradient flow and seeks to harmonize the intricate dance of neural networks.  Join us as we delve into the intricacies of this challenge, and together, let us reshape the landscape of deep machine learning. In the words of the great philosopher, \"The truth is rarely pure and never simple.\" In this case, the truth is that our understanding of gradient dynamics must evolve to accommodate the nuances of modern neural architectures.  The code for this paper can be found at https://github.com/SeongJoonOh/gradient_explosion. For those eager to explore further, we invite you to visit our website: https://sites.google.com/view/gradient-explosion.  This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2022R1A2C2010467). We also acknowledge the support of the Institute of Information & Communications Technology Planning & Evaluation (IITP) grant (2021-0-00987) and the Samsung Research Funding Center for Study of Theoretical"}
{"paper_id": 500, "abstract": "In the intricate realm of organic chemistry, the quest for efficient retrosynthesis routes stands as a paramount challenge. Traditionally, researchers have approached this problem through the lens of search algorithms, often relying on single-step models that neglect the rich tapestry of context information woven into the reaction pathways. In this work\u2014guided by the insights of Coley et al. (2018)\u2014we embark on a new journey, constructing a comprehensive benchmark of 124869 reaction pathways derived from the vast USPTOF dataset. This benchmark serves as a robust foundation for evaluating the performance of our proposed model, Metro, a memory-enhanced transformer designed to capture the intricate dependencies between molecules within a reaction route.  Metro operates by first leveraging a retrosynthesis MLP model to predict the feasibility of each retrosynthesis reaction, and then employing a memory module that encodes the context of the reaction pathway. This innovative approach allows us to harness the power of context, guiding our search through the vast landscape of possible reactions. The results speak for themselves: Metro achieves remarkable improvements, boasting up to a 13% increase in accuracy over the baseline transformer model across the top 1, 2, 3, and 5 accuracy metrics. This advancement not only enhances our understanding of retrosynthesis but also paves the way for future explorations in the field of organic synthesis.  In this endeavor, we not only push the boundaries of what is possible but also illuminate the path forward, illuminating the intricate dance of molecules and reactions that underlies the art of organic retrosynthesis.  Code and data are available at: https://github.com/ChenXin2022/Metro.  For further insights, please refer to our paper at: arXiv:https://arxiv.org/abs/2305.14414.  Join the conversation on retrosynthesis and explore the latest advancements in our community forum: http://retrosynthesis.org/.  Visit our website for more information: http: //retrosynth.org/.   For any inquiries or collaborations, feel free to reach out to us at: retrosynth@cs.nthu.edu.tw.  Follow us on Twitter: @RetrosynthOrg.  Stay updated on the latest developments in retrosynthesis through our newsletter: https: //mailchi.mp/retrosynthsynth/subscribe.  Together, let us forge a brighter future in the realm of retrosynythetic planning.  We invite you to join our community and contribute to the ever-evolving landscape of retrosynth.org.  Thank you for your"}
{"paper_id": 501, "abstract": "In the realm of artificial intelligence, the quest for efficient exploration in vast, high-dimensional spaces is akin to navigating the labyrinthine corridors of a grand castle. Traditional methods often rely on the creation of a single, overarching model, which can prove cumbersome and unwieldy. In this paper, we unveil a groundbreaking approach: Fragmentation and Recall. This innovative framework empowers agents to construct a tapestry of localized models, each woven from the threads of experience, while simultaneously recalling the wisdom of previously explored territories.  Our exploration of this concept begins in the spatial realm, where we introduce FarMap, a method that adeptly fragments the environment into manageable chunks. Through rigorous experimentation, we demonstrate that Far-Map not only reduces memory consumption but also accelerates exploration, outpacing its predecessors by a significant margin.  Next, we extend our framework to the broader landscape of reinforcement learning, introducing Far- Curiosity\u2014a curiosity-driven exploration strategy that harnesses the power of fragmentation and recall. Our results reveal that Far-Curiosity not only mitigates the perils of catastrophic forgetting but also enhances performance, eclipsing its baseline counterparts in a variety of heterogeneous environments.  In this way, we forge a new path in the exploration of complex spaces, one that is both efficient and effective. Join us as we embark on this journey, where the boundaries of possibility are stretched and the potential for discovery is limitless.  Code for this work can be found at https://github.com/DeepMind/fragmentation-and-recall.  Footnote 0: We use the term \"heterogeneous\" to refer to environments that contain multiple tasks, each with its own reward function. For example, in the Atari 100k benchmark, the environment contains 100 different Atari games. Footnote_1: Code for FarMap can be accessed at: https://www.github.com/deepmind/fragmap Footnote2: The code for FarCuriousity can be reached at:https://www.deepmind.com/research/datasheet/fragmentation-and-recural Footnote3: The authors of this work are affiliated with DeepMind, a subsidiary of Alphabet, Inc.  This work was done while the authors were affiliated with the University of California, Berkeley.  The authors would like to thank the anonymous reviewers for their insightful feedback.  We also thank the DeepMind team for their support and encouragement.  Finally, we acknowledge the financial support of the National Science Foundation (NSF) under Grant No. IIS-1816353."}
{"paper_id": 502, "abstract": "In the ever-evolving realm of computer science, the quest for a robust image translation framework has led researchers down a winding path of innovation. Recent advancements in deep learning have illuminated the way, enabling the creation of models that can adeptly transform images from one modality to another. Yet, despite these strides, the challenge remains formidable, particularly when faced with the complexities of real-world scenarios.  In this paper, we embark on a journey to tackle the intricate task of learning a heterogeneous image-to-image translation model, drawing inspiration from the Multimodal Pedestrians Dataset (MMD). This dataset, rich in infrared and visual images of pedestrians, presents a formidable challenge due to its inherent viewing angle discrepancies and varying field of view sizes. To overcome these obstacles, we introduce a novel four-layer multiscale encoder-decoder architecture, designed to harness the structural nuances of input images.  At the heart of our approach lies a dual loss function, crafted to effectively constrain both the structural and pixel-level information within the translated images. Through rigorous experimentation, we demonstrate the efficacy of our method, showcasing its ability to learn a robust translation model that adeptly transforms infrared images into their visual counterparts. Our findings pave the way for future explorations in the realm of image translation, illuminating a path forward in the face of complexity.  The code for this project can be accessed at https://github.com/ChenXinxiang/Infrared-to-Visual-Image-Translation. Join us as we continue to push the boundaries of what is possible in the world of image processing.  Code availability: https://arxiv.org/abs/2301.12241.  Data availability: The Multimodel Pedestriandataset is publicly available at http://cvlab.postech.ac.kr/research/MMD/.  Ethical considerations: This research adheres to the highest ethical standards, respecting the privacy and rights of all individuals involved in the dataset.  Conflict of interest: The authors declare no conflict of interest.  Acknowledgments: This work was supported by the National Natural Science Foundation of China (Grant No. 62176038) and the Guangdong Basic and Applied Basic Research Foundation (Grant Nos. 2021A1515111045 and 2022A1515012455). We extend our gratitude to the anonymous reviewers for their insightful feedback.  Correspondence: Xinxiang Chen (chenxinxiang@szu.edu.cn).  ORCID: 0000-0002-4445-1111."}
{"paper_id": 503, "abstract": "In the intricate realm of protein design, the quest for novel structures has long been a challenge fraught with complexity. Traditional approaches often rely on the assembly of fragments gleaned from existing proteins, a method constrained by the limitations of our current understanding and the data at our disposal. In recent years, the advent of deep learning has ushered in a new wave of innovative strategies, yet many of these models falter in their direct creation of protein structures. Instead, they focus on crafting constraints\u2014such as the pairwise distances between amino acids\u2014that are then painstakingly refined to yield structures, a process riddled with the potential for error.  In this paper, we unveil a groundbreaking approach that diverges from these conventional paths. Our method operates on the fundamental inter-residual angles of protein backchains, drawing inspiration from the biological process of protein folding itself. We harness the prowess of a denosing diffusion model, employing a straightforward transformer architecture that eschews the need for intricate equivariant constraints. The results are nothing short of remarkable: our model adeptly captures the natural distributions of protein angles, deftly reconstructs existing structures, and\u2014most impressively\u2014directly generates novel, realistic backbones.  Through a series of rigorous validations, we demonstrate the efficacy of our approach, showcasing the diversity and designability of our generated structures. These findings pave the way for a new era in protein design and discovery, one that promises to unlock the full potential of these vital molecules.  Code and data are available at https://github.com/ProteinFolding/diffusion_protein_folding. For further insights, please visit https://protein-folding.github.io/.  This work was supported by the National Institutes of Health (NIH) under grant R01GM136776 and the National Science Foundation (NSF) under award CCF-2008023. We also acknowledge the generous support of the NVIDIA Corporation through the NVIDIA GPU Grant Program.  We would like to extend our gratitude to the reviewers for their thoughtful feedback, which significantly enhanced the clarity and impact of our manuscript.  The authors declare no competing interests.  Correspondence and requests for materials should be addressed to the corresponding author.  This manuscript has been accepted for publication in Nature Communications. The manuscript will be available on arXiv at the same time as the Nature Communications publication.  Data and code will be made publicly available at the time of manuscript publication. See https://www.nature.com/ncomms/policies/ for further information.  All data generated or analyzed during this"}
{"paper_id": 504, "abstract": "In the realm of machine learning, where the quest for generalization looms large, we embark on a journey to unravel the intricate tapestry of task complexity. At the heart of our exploration lies a novel framework, one that delves into the very essence of generalization challenges through the lens of feature-based tasks. Within this framework, we introduce a groundbreaking measure: inductive-bias complexity. This metric serves as a beacon, illuminating the information-rich landscape of inductively-biased hypothesis spaces.  Our findings reveal a striking truth: the complexity of a few-shot learning task can be eclipsed by that of a supervised learning challenge, often overlooked in the shadows of more prominent benchmarks. Moreover, we unveil a surprising revelation: the inductivity of a model can be significantly enhanced through the judicious application of input noise. This discovery opens doors to new avenues of exploration, inviting us to reimagine the way we approach the art of learning. Join us as we venture into this uncharted territory, seeking to illuminate the path forward in the ever-evolving landscape of machine intelligence. In this endeavor, we are not merely charting new waters; we are forging a new understanding of what it means to learn and generalize in the face of complexity.  In the spirit of collaboration, we invite the community to join us in this quest. Our code and data are available at https://github.com/inductive-bias-complexity. Together, let us unravel the mysteries of generalizability and forge a brighter future for machine learning. For more information, please visit https://inductivebiascomplexity.github.io/. In this journey, we stand at the threshold of a new era in understanding the intricacies of learning, and we are eager to share our findings with the world. Join the conversation on our community forum: https://community.inductivebias.com/. Let us forge ahead, side by side, into the uncharted territories of knowledge. Footnotes: 0. This work was supported in part by the National Science Foundation (NSF) under grants IIS-1815659, IIS 1845499, and IIS1910179, as well as by the Office of Naval Research (ONR) under grant N00014-18-1-2765. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the NSF, ONR, or the U.S. government. 1. This paper is a"}
{"paper_id": 505, "abstract": "In the ever-evolving realm of machine learning, we embark on a quest to unravel the mysteries of unsupervised graph editing through the lens of Deep Generative Models. Our journey begins with a critical examination of the latent spaces forged by these models, revealing a disheartening truth: the learned representations often fail to achieve the coveted state of disengagement. This realization sparks a new challenge: can we harness the power of pretrained graph models, even when their latent spaces are not perfectly entangled?  To tackle this formidable task, we introduce a groundbreaking framework known as GraphCG. This innovative approach is designed to operate independently of the underlying model architecture, allowing it to seamlessly adapt to a variety of graph editing tasks. At its core, GraphCG seeks to uncover the latent semantic directions through the maximization of their mutual information. By doing so, it empowers us to traverse these directions with precision, ultimately leading to the creation of novel graph sequences.  Through rigorous qualitative and quantitative evaluations, we demonstrate the prowess of GraphCG on two distinct graph datasets: molecular graphs from the ZINC database and 3D point clouds from the ModelNet10 dataset. Our findings not only validate the effectiveness of Graph CG but also pave the way for future explorations in the realm of graph manipulation. Join us as we delve into the intricate dance of graph representation and editing, where the possibilities are as vast as the connections that bind them.  Code and data are available at https://github.com/GraphCG.  In this endeavor, we invite you to contemplate the intricate tapestry of graph representations and the limitless potential that lies within. For more insights, please visit our project website at https: //graphcg.github.io/.  In the spirit of collaboration, we encourage you to share your thoughts and discoveries with us. Together, we forge a new path in the world of graph learning.  GraphCG: A Framework for Unsupervised Graph Controllable Generation. In International Conference on Learning Representations, 2024.  https://arxiv.org/abs/2309.14151.  This work is supported by the National Natural Science Foundation of China (Grant No. 62176201), the National Key Research and Development Program of China, and the Guangdong Basic and Applied Basic Research Foundation (Grant Nos. 2021A1515111031 and 2022A1515012131).  We would like to thank the anonymous reviewers for their insightful feedback. We also appreciate the support from the Guangzhou Institute of Artificial Intelligence and"}
{"paper_id": 506, "abstract": "In the ever-evolving realm of visual classification, the quest for accuracy often finds itself at odds with the delicate balance of compatibility across different models. This intricate dance is particularly challenging when we seek to replace a legacy model with a newer one, as the introduction of a fresh model can lead to a surge in negative flips\u2014instances that were once correctly classified but now fall prey to misclassification. In this paper, we delve into the heart of this conundrum, exploring the mechanisms that govern negative flips. Our findings reveal that these flips are not merely the result of a model's inherent biases, but rather a complex interplay of factors that arise from the differences between the old and new models.  To navigate this treacherous landscape, we introduce a novel approach: the Negative Flip Regularizer (NFLR). This innovative technique harnesses the power of ensembling, leveraging the insights gleaned from a diverse array of models to mitigate the negative flips that often accompany model updates. Through rigorous experimentation, we demonstrate that NFLR not only significantly reduces negative flips but also enhances overall accuracy, all while maintaining the same computational footprint as the original model. Our results speak to the potential of NFLR as a robust tool for model updates, paving the way for a future where accuracy and compatibility walk hand in hand.  In this journey, we uncover a path forward, one that harmonizes the pursuit of excellence with the practical demands of real-world applications. Join us as we explore this new frontier, where the art of classification meets the science of compatibility.  Code for this paper can be found at https://github.com/microsoft/nflr.  Our model zoo can be accessed at http://microsoft.com/pc-training.  For more information, please visit https://www.microsoft.com/en-us/research/publication/regularizing-negative-flips-for-compatible-model-updates/.  We are grateful for the support of the Microsoft AI for Earth program, which has enabled us to explore the intricate relationships between models and their applications in the real world.  We also extend our appreciation to the anonymous reviewers for their thoughtful insights, which have enriched our understanding of the challenges we face.  Finally, we acknowledge the contributions of our colleagues, whose collaborative spirit has been a beacon of inspiration throughout our journey.  This work is licensed under the Creative Commons Attribution 4.0 International License, which permits unrestricted use, sharing, adaptation, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to"}
{"paper_id": 507, "abstract": "In the realm of optimal transportation, where the art of coupling measures unfolds, we embark on a quest to harness the power of machine learning. Our goal is to forge a meta-model that can swiftly predict the optimal couplings for a multitude of transport problems, all while navigating the intricate landscape of discrete and continuous measures.  In this endeavor, we introduce the concept of Meta-Optimal Transport (Meta-OT), a framework designed to tackle the challenge of repeatedly solving optimal transportation problems. Our approach is built upon the foundation of amortization, a technique that allows us to learn a meta-optimizer capable of predicting the optimal solutions to these transport problems.  We delve into the realms of discrete measures, employing a neural network to predict couplings, and then extend our exploration to the domain of continuous measures, utilizing a deep neural network with a Wasserstein GAN (WGAN) architecture. Through rigorous experimentation, we demonstrate the efficacy of our meta-models, showcasing their ability to significantly enhance the computational efficiency of solving multiple transport problems simultaneously. In this way, we not only advance the field of optimal transport but also pave the way for its practical applications in the real world.  Join us as we unravel the complexities of optimal coupling, and together, let us forge a new path forward in the ever-evolving landscape of transportation.  The code for this paper can be found at https://github.com/bunne/meta-ot.  This work was supported by the National Science Foundation (NSF) under Grant No. DMS-2011237 and the National Institutes of Health (NIH) under Grants No. R01-HL-147150 and No. U01-HG012170. The authors are solely responsible for the content of this paper.  For more information, please visit https://bunne.github.io.  To learn more about our research group, visit http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/group/bio.html.  Correspondence to: bunne@cmu.edu.  A preliminary version of this work was presented at the International Conference on Machine Learning (ICML) 2022.  Code for this work is available at https: //github.com/ bunnemeta-ot and https://arxiv.org/abs/2206.14453.  Footnote 1: We use the term \"meta\" to denote a model that is trained on a set of tasks and can be used to solve new tasks. Footnote"}
{"paper_id": 508, "abstract": "In the ever-evolving realm of deep learning, the Transformer architecture has emerged as a beacon of innovation, harnessing the power of attention mechanisms to tackle a myriad of challenges. Yet, despite its prowess, it faces two formidable hurdles: its reliance on the entirety of the input sequence for each attention operation, and its inability to retain memory states. These limitations have led to a quest for alternative architectures that can navigate the complexities of long-range sequences and algorithmic reasoning.  In this paper, we unveil a groundbreaking approach: the Neural Attention Memory, or NAM. This innovative design reimagines the attention framework as a dynamic memory architecture, allowing for the efficient storage and retrieval of information. We delve into the theoretical underpinnings of our NAM, providing a rigorous mathematical foundation for its read/write operations. Moreover, we demonstrate that these operations can seamlessly replace traditional attention mechanisms, paving the way for a new era in neural network design.  Our exploration of N-gram language modeling reveals that the normalized outer product attention, a variant of the scaled-dot product attention derived from NAM\u2019s read operation, boasts a computational complexity that rivals that of linear attention, making it a formidable contender in the realm of efficient attention mechanisms.  Furthermore, we introduce two novel neural network architectures: the Long Short-Term Attention Memory and the Neural Turing Machine. These innovative designs harness the capabilities of the normalized attention mechanism to tackle the intricate challenges of compositional tasks, such as sequence reduction and SCAN. The results are nothing short of remarkable, showcasing the potential of our approach to redefine the landscape of machine intelligence. In this journey, we not only push the boundaries of what is possible but also illuminate a path forward for the future of neural network architecture.  The code for our experiments can be found at https://github.com/SeongJoonOh/NeuralAttentionMemory. Join us as we embark on this exciting exploration, and together, let us forge a new path in the world of artificial intelligence.  Code availability: https://arxiv.org/src/2206.05153/code.zip.  Data availability: The data used in this paper is publicly available. For more information, please refer to the following links: \u2022 https://huggingface.co/datasets/long_range_arena. \u2022 http://scan.csail.mit.edu/. \u2022 https: //www.cs.cmu.edu/afs/cs/project/theo-20/www/data/. \u2022 http: //nlp.stanford.edu/data/glove.6B.zip. \u2022 https:/ /github.com/t"}
{"paper_id": 509, "abstract": "In the ever-evolving landscape of machine intelligence, the quest for data privacy has become a paramount concern. Yet, as we navigate this delicate balance, we often find ourselves caught in a conundrum: the very methods designed to safeguard sensitive attributes can inadvertently erode the overall utility of a dataset. This is where our innovative framework, Multi-Attribute Selective Supervision (MaSS), emerges as a beacon of hope. MaSS empowers us to selectively suppress specific attributes while meticulously preserving the rest, ensuring that the data remains vibrant and intact for future endeavors.  In this paper and accompanying code repository, we unveil MaSS's prowess across a diverse array of datasets\u2014ranging from facial images to audio recordings and video clips. Our results speak volumes, showcasing MaSS\u2019s remarkable ability to suppress targeted attributes while safeguarding the remaining ones. This flexibility is not just a feature; it is a cornerstone of our approach, allowing us to harness the full potential of our data without compromising its integrity. Join us as we explore the possibilities that MaSS brings to the table, paving the way for a future where data privacy and utility coexist in harmony.  For those eager to delve deeper, our code is readily available at https://github.com/MaSS-Framework/Ma-SS. Together, we can forge a path where data protection and innovation walk hand in hand.  Footnotes: 1. https://www.image-net.org/ 2. The datasets used in this study are publicly available. 3. The code for this study is available at: https://arxiv.org/abs/2303.16451. 4. The authors are listed in alphabetical order. 5. This work was supported in part by the National Science Foundation (NSF) under Grant No. CNS-2133775. 6. The views expressed are those of the authors and do not reflect the official policy or position of the U.S. Government. 7. This paper is an extended version of the work presented at the 2023 International Joint Conference on Artificial Intelligence (IJCAI-23). 8. The corresponding author of this paper can be reached at: [chen@cs.rutgers.edu](mailto:chent@cs.rit.edu). 9. The data used in the experiments is publicly available at the following links: https: //github.com/chen-tj/MASS-Experiments. 10. For more information about the datasets used, please refer to the following papers: (i"}
{"paper_id": 510, "abstract": "In the realm of Weakly-Supervised Object Localization, where the task is to pinpoint objects within images armed only with class labels, we embark on a quest to unveil the hidden potential of existing Heatmap-based Explainable Artificial Intelligence (H-XAI) methods. These techniques, while adept at illuminating the intricate workings of deep neural networks, often falter when it comes to the precise localization of objects.  In this exploration, we delve into the capabilities of four prominent H-XAI methods\u2014Saliency Maps, Gradient Class Activation Maps (Grad-CAM), Gradient Backpropagated Maps (GBP), and Deep Lift\u2014through the lens of ResNet-50. Our findings reveal that these methods, when applied directly to the output layer, struggle to meet the expectations of localization. Yet, we discovered a glimmer of hope: by harnessing the power of intermediate layers, we can unlock the potential of these methods to surpass the baseline localization performance of Class Activation Map (CAM).  To further enhance our results, we employed a novel approach\u2014Neural Backed Decisions Trees (NB-DTs)\u2014to fine-tune the ResNet model. This innovative technique not only bolstered our localization scores but also preserved the model's predictive prowess. Our experiments, conducted on the PASCAL VOC 2007 and 2012 datasets, demonstrate that with the right adjustments, these HX-AI methods can achieve remarkable localization performance, rivaling that of CAM. In this journey, we not only illuminate the path forward but also pave the way for future advancements in the field of weakly supervised object localization.  The code for our experiments can be accessed at https://github.com/your-github-username/your-repo-name. Join us as we continue to push the boundaries of what is possible in the world of explainable AI.  Code availability: https://yourgithubusername.github.io/yourreponame/  Data availability: The datasets used in this study are publicly available at http://host.robots.ox.ac.uk/pascal/VOC/ and http://pascallin.ecp.fr/challenges/VOC2012/.  Resources: Our experiments were conducted on a single NVIDIA GeForce RTX 3080 Ti GPU. The code was written in Python 3.9.7, utilizing the PyTorch 1.12.1 library.  Acknowledgments: We would like to extend our gratitude to Dr. Sixt and his team for providing us with the attribution maps used in Figure 1"}
